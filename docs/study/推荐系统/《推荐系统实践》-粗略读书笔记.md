# 《推荐系统实践》-粗略读书笔记

> 为推荐系统的搭建做准备，时间比较紧迫，暂时不细读了。
> 下面关于公式、代码的部分，没有找到现成的图，手敲麻烦意义不大，需要时看书、上网查找即可。

# 1. 第1章 好的推荐

## 1.1 什么是推荐系统

+ 推荐系统的基本任务是联系用户和物品，解决信息过载的问题

+ 从物品的角度出发，推荐系统可以更好地发掘物品的长尾（long tail）。主流商品代表绝大多数用户的需求，而长尾商品代表**少数人的个性化需求**。推荐系统通过发掘用户的行为，找到用户的个性化需求，从而将长尾商品准确地推荐给需要它的用户，帮助用户发现那些他们感兴趣但很难发现的商品。

+ 常见的几种推荐方式

  + 社会化推荐（social recommendation）

    用户间推荐

  + 基于内容的推荐 （content-based filtering）

    根据用户历史兴趣推荐类似内容

  + 基于协同过滤的推荐（collaborative filtering）

    给用户推荐兴趣相似的用户所感兴趣的内容

## 1.2 个性化推荐系统的应用

​	个性化推荐系统通过**分析大量用户行为日志**，给不同用户提供不同的个性化页面展示，来提高网站的点击率和转化率。

​	几乎所有的推荐系统应用都是由三部分构成：

+ **前台的展示页面**
+ **后台的日志系统**
+ **推荐算法系统**

### 1.2.1 电子商务

1. 亚马逊个性化推荐系统列表

   **基于物品推荐**

   + 推荐结果的标题、缩略图以及其他内容属性
   + 推荐结果的平均分
   + 推荐理由

### 1.2.2 电影和视频网站

1. Netflix电影推荐界面

   **基于物品推荐**

   + 电影的标题和海报
   + 用户反馈模块——包括Play（播放）、评分和Not Interested（不感兴趣）3种
   + 推荐理由——因为用户曾经喜欢过别的电影

### 1.2.3 个性化音乐网络电台

个性化推荐的成功应用需要两个条件：

1. 信息过载。因为如果用户可以很容易地从所有物品中找到喜欢的物品，就不需要个性化推荐了。
2. 用户大部分时候没有特别明确的需求。用户如果有明确的需求，可直接通过搜索引擎找到感兴趣的物品。

著名个性化音乐推荐产品：Pandora、Last.fm、豆瓣电台

Last.fm记录了所有用户的听歌记录以及用户对歌曲的反馈，在这一基础上计算出不同用户在歌曲上的喜好相似度，从而给用户推荐和他有相似听歌爱好的其他用户喜欢的歌曲。

​	音乐推荐是推荐系统里非常特殊的领域。2011年的Recsys大会专门邀请了Pandora的研究人员对音乐推荐进行了演讲。演讲人总结了音乐推荐的如下特点。

+ 物品空间大 物品数很多，物品空间很大，这主要是相对于书和电影而言。

+ 消费每首歌的代价很小 对于在线音乐来说，音乐都是免费的，不需要付费。

+ 物品种类丰富 音乐种类丰富，有很多的流派。

+ 听一首歌耗时很少 听一首音乐的时间成本很低，不太浪费用户的时间，而且用户大都把音乐作为背景声音，同时进行其他工作。

+ 物品重用率很高 每首歌用户会听很多遍，这和其他物品不同，比如用户不会反复看一个电影，不会反复买一本书。

+ 用户充满激情 用户很有激情，一个用户会听很多首歌。

+ 上下文相关 用户的口味很受当时上下文的影响，这里的上下文主要包括用户当时的心情（比如沮丧的时候喜欢听励志的歌曲）和所处情境（比如睡觉前喜欢听轻音乐）。

+ 次序很重要 用户听音乐一般是按照一定的次序一首一首地听。

+ 很多播放列表资源 很多用户都会创建很多个人播放列表。

+ 不需要用户全神贯注 音乐不需要用户全神贯注地听，很多用户将音乐作为背景声音。

+ 高度社会化

### 1.2.4 社交网络

代表：Twitter、FaceBook

社交网络中的个性化推荐技术主要应用在3个方面：

+ 利用用户的社交网络信息对用户进行个性化的物品推荐；

+ 信息流的会话推荐；

+ 给用户推荐好友。

### 1.2.5 个性化阅读

​	目前互联网上的个性化阅读工具很多，国际知名的有Google Reader，国内有鲜果网等。

+ Google Reader是一款流行的社会化阅读工具。它允许用户关注自己感兴趣的人，然后看到所关注用户分享的文章。
+ 个性化阅读工具Zite则是收集用户对文章的偏好信息。
+ Digg首先根据用户的Digg历史计算用户之间的兴趣相似度，然后给用户推荐和他兴趣相似的用户喜欢的文章。

### 1.2.6 基于位置的服务

+ Foursquare推出了探索功能，给用户推荐好友在附近的情况

### 1.2.7 个性化邮件

+ 推荐系统Tapestry，协同过滤筛选信息，通过分析用户阅读邮件的历史行为和习惯对新邮件进行重新排序，从而提高用户的工作效率。
+ 谷歌的研究人员在这个问题上也进行了深入研究，于2010年推出了优先级收件箱功能。该产品通过分析用户对邮件的历史行为，找到用户感兴趣的邮件，展示在一个专门的收件箱里。用户每天可以先浏览这个邮箱里的邮件，再浏览其他邮件。

### 1.2.8 个性化广告

> [网络广告中，CPC、CPA、CPM 的定义各是怎样的？](https://www.zhihu.com/question/20416888)
>
> 1. CPM（Cost Per Mille） ：展现成本，或者叫千人展现成本
> 2. CPC（Cost Per Click） 点击成本，即每产生一次点击所花费的成本
> 3. CPA（Cost Per Action）：每行动成本。即按行动收费

​	广告是互联网公司生存的根本。很多互联网公司的盈利模式都是基于广告的，而广告的CPC、CPM直接决定了很多互联网公司的收入。

​	个性化广告投放和狭义个性化推荐的区别是，个性化推荐着重于帮助用户找到可能令他们感兴趣的物品，而**广告推荐着重于帮助广告找到可能对它们感兴趣的用户**，即一个是以用户为核心，而另一个以广告为核心。目前的个性化广告投放技术主要分为3种。

+  上下文广告 通过分析用户正在浏览的网页内容，投放和网页内容相关的广告。代表系统是谷歌的Adsense。

+  搜索广告 通过分析用户在当前会话中的搜索记录，判断用户的搜索目的，投放和用户目的相关的广告。

+  个性化展示广告 我们经常在很多网站看到大量展示广告（就是那些大的横幅图片），它们是根据用户的兴趣，对不同用户投放不同的展示广告。雅虎是这方面研究的代表。

## 1.3 推荐系统评测

> 看到这就想到最近美团爆出杀熟的操作。三方共赢这种美好的愿望还是想想就好，哈哈。

​	一个完整的推荐系统一般存在3个参与方：

+ 用户
+ 物品提供者
+ 提供推荐系统的网站

​	在评测一个推荐算法时，需要同时考虑三方的利益，一个好的推荐系统是能够令三方共赢的系统。

### 1.3.1 推荐系统实验方法

在推荐系统中，主要有3种评测推荐效果的实验方法：

+ 离线实验（offline experiment）
+ 用户调查（user study）
+ 在线实验（online experiment）

#### 1. 离线实验

离线实验的方法一般由如下几个步骤构成：

1. 通过日志系统获得用户行为数据，并按照一定格式生成一个标准的数据集；

2. 将数据集按照一定的规则分成训练集和测试集；

3. 在训练集上训练用户兴趣模型，在测试集上进行预测；

4. 通过事先定义的离线指标评测算法在测试集上的预测结果。

从上面的步骤可以看到，**推荐系统的离线实验都是在数据集上完成的**，也就是说它不需要一个实际的系统来供它实验，而只要有一个从实际系统日志中提取的数据集即可。这种实验方法的好处是不需要真实用户参与，可以直接快速地计算出来，从而方便、快速地测试大量不同的算法。

它的**主要缺点是无法获得很多商业上关注的指标，如点击率、转化率等**，而找到和商业指标非常相关的离线指标也是很困难的事情。

| 优点                     | 缺点                             |
| ------------------------ | -------------------------------- |
| 不需要对实际系统的控制权 | 无法计算商业上关心的指标         |
| 不需要用户参与实验       | 离线实验的指标和商业指标存在差异 |
| 速度快，可以测试大量算法 |                                  |

#### 2. 用户调查

​	注意，离线实验的指标和实际的商业指标存在差距，比如预测准确率和用户满意度之间就存在很大差别，**高预测准确率不等于高用户满意度**。

​	用户调查的优缺点也很明显。它的优点是可以获得很多体现用户主观感受的指标，相对在线实验风险很低，出现错误后很容易弥补。缺点是招募测试用户代价较大，很难组织大规模的测试用户，因此会使测试结果的统计意义不足。此外，在很多时候设计双盲实验非常困难，而且用户在测试环境下的行为和真实环境下的行为可能有所不同，因而在测试环境下收集的测试指标可能在真实环境下无法重现。

#### 3. 在线实验

> [黄一能：什么是科学的AB测试？谈谈分层实验和流量正交 ](https://www.sohu.com/a/343208894_713733)
>
> 科学的AB实验要求保证每次实验只有一个变量，各组其他所有元素都必须保持一致。如果每个变量都独立切分流量会大大制约实验的效率，一是实验流量变少，得出显著结果的时间会拉长。二是可以并行的实验量受到了制约。如果不切分流量实验，无法验证效果的变化究竟是那个改动带来的。
>
> [AB测试中两个常见的问题，谈谈流量分层和置信度](https://zhuanlan.zhihu.com/p/108317075)

​	在完成离线实验和必要的用户调查后，可以将推荐系统上线做**AB测试**，将它和旧的算法进行比较。

​	AB测试是一种很常用的在线评测算法的实验方法。它通过一定的规则将用户随机分成几组，并对不同组的用户采用不同的算法，然后通过统计不同组用户的各种不同的评测指标比较不同算法，比如可以统计不同组用户的点击率，通过点击率比较不同算法的性能。

​	网站http://www.abtests.com/，给出了很多通过实际AB测试提高网站用户满意度的例子，从中我们可以学习到如何进行合理的AB测试。

​	**AB测试的优点是可以公平获得不同算法实际在线时的性能指标**，包括商业上关注的指标。AB测试的**缺点主要是周期比较长**，必须进行长期的实验才能得到可靠的结果。因此一般不会用AB测试测试所有的算法，而只是用它测试那些在离线实验和用户调查中表现很好的算法。

​	切分流量是AB测试中的关键，不同的层以及控制这些层的团队需要从一个统一的地方获得自己AB测试的流量，而不同层之间的流量应该是正交的。

​	<small>下图是一个简单的AB测试系统。用户进入网站后，流量分配系统决定用户是否需要被进行AB测试，如果需要的话，流量分配系统会给用户打上在测试中属于什么分组的标签。然后用户浏览网页，而用户在浏览网页时的行为都会被通过日志系统发回后台的日志数据库。此时，如果用户有测试分组的标签，那么该标签也会被发回后台数据库。在后台，实验人员的工作首先是配置流量分配系统，决定满足什么条件的用户参加什么样的测试。其次，实验人员需要统计日志数据库中的数据，通过评测系统生成不同分组用户的实验报告，并比较和评测实验结果。</small>

![img](http://www.ituring.com.cn/figures/2012/tuijinxitongshijian/05.D%2001%20Z/image23.png)



----

一般来说，一个新的推荐算法最终上线，需要完成上面所说的3个实验。

+ 首先，需要通过离线实验证明它在很多离线指标上优于现有的算法。
+ 然后，需要通过用户调查确定它的用户满意度不低于现有的算法。

+ 最后，通过在线的AB测试确定它在我们关心的指标上优于现有的算法。

### 1.3.2 评测指标

#### 1. 用户满意度

​	用户满意度没有办法离线计算，只能通过用户调查或者在线实验获得。

​	用户调查获得用户满意度主要是通过调查问卷的形式。而在线系统中，用户满意度主要通过一些对用户行为的统计得到。更一般的情况下，我们可以用点击率、用户停留时间和转化率等指标度量用户的满意度。

#### 2. 预测准确度

​	预测准确度度量一个推荐系统或者推荐算法预测用户行为的能力。该指标可以通过离线实验计算。

​	在计算该指标时需要有一个离线的数据集，该数据集包含用户的历史行为记录。然后，将该数据集通过时间分成训练集和测试集。最后，通过在训练集上建立用户的行为和兴趣模型预测用户在测试集上的行为，并计算预测行为和测试集上实际行为的重合度作为预测准确度。

##### 评分预测

​	预测用户对物品评分的行为称为评分预测。

##### TopN推荐

​	网站在提供推荐服务时，一般是给用户一个个性化的推荐列表，这种推荐叫做**TopN推荐**。TopN推荐的预测准确率一般通过准确率（precision）/召回率（recall）度量。

​	有的时候，为了全面评测TopN推荐的准确率和召回率，一般会选取不同的推荐列表长度N，计算出一组准确率/召回率，然后画出准确率/召回率曲线（precision/recall curve）。

##### 关于评分预测和TopN推荐的讨论

​	评分预测一直是推荐系统研究的热点，绝大多数推荐系统的研究都是基于用户评分数据的评分预测。

#### 3. 覆盖率

> [请问什么是基尼系数，怎样计算出来的？](https://zhidao.baidu.com/question/1797381608016293707.html)

​	覆盖率（coverage）描述一个推荐系统对物品长尾的发掘能力。覆盖率是一个内容提供商会关心的指标。

​	以图书推荐为例，出版社可能会很关心他们的书有没有被推荐给用户。覆盖率为100%的推荐系统可以将每个物品都推荐给至少一个用户。此外，从上面的定义也可以看到，热门排行榜的推荐覆盖率是很低的，它只会推荐那些热门的物品，这些物品在总物品中占的比例很小。一个好的推荐系统不仅需要有比较高的用户满意度，也要有较高的覆盖率。

​	可以通过研究物品在推荐列表中出现次数的分布描述推荐系统挖掘长尾的能力。如果这个分布比较平，那么说明推荐系统的覆盖率较高，而如果这个分布较陡峭，说明推荐系统的覆盖率较低。

​	社会学领域有一个著名的**马太效应，即所谓强者更强，弱者更弱的效应**。如果一个系统会增大热门物品和非热门物品的流行度差距，让热门的物品更加热门，不热门的物品更加不热门，那么这个系统就有马太效应。

​	推荐系统的初衷是希望消除马太效应，使得各种物品都能被展示给对它们感兴趣的某一类人群。但是，很多研究表明现在主流的推荐算法（比如协同过滤算法）是具有马太效应的。**评测推荐系统是否具有马太效应的简单办法就是使用基尼系数**。（如果G1是从初始用户行为中计算出的物品流行度的基尼系数，G2是从推荐列表中计算出的物品流行度的基尼系数，那么如果G2 > G1，就说明推荐算法具有马太效应。）

#### 4. 多样性

​	为了满足用户广泛的兴趣，推荐列表需要能够覆盖用户不同的兴趣领域，即推荐结果需要具有多样性。多样性推荐列表的好处用一句俗话表述就是“不在一棵树上吊死”。

​	**多样性描述了推荐列表中物品两两之间的不相似性。因此，多样性和相似性是对应的**。

#### 5. 新颖性

​	新颖的推荐是指给用户推荐那些他们以前没有听说过的物品。

​	O’scar Celma在博士论文“Music Recommendation and Discovery in the Long Tail”①中研究了新颖度的评测。评测新颖度的最简单方法是利用推荐结果的平均流行度，因为越不热门的物品越可能让用户觉得新颖。因此，**如果推荐结果中物品的平均热门程度较低，那么推荐结果就可能有比较高的新颖性**。

​	通过牺牲精度来提高多样性和新颖性是很容易的，而**困难的是如何在不牺牲精度的情况下提高多样性和新颖性**。

#### 6. 惊喜度

​	**如果推荐结果和用户的历史兴趣不相似，但却让用户觉得满意，那么就可以说推荐结果的惊喜度很高，而推荐的新颖性仅仅取决于用户是否听说过这个推荐结果**。

​	目前并没有什么公认的惊喜度指标定义方式，这里只给出一种定性的度量方式。上面提到，令用户惊喜的推荐结果是和用户历史上喜欢的物品不相似，但用户却觉得满意的推荐。那么，**定义惊喜度需要首先定义推荐结果和用户历史上喜欢的物品的相似度，其次需要定义用户对推荐结果的满意度**。

​	提高推荐惊喜度需要提高推荐结果的用户满意度，同时降低推荐结果和用户历史兴趣的相似度。

> 用户满意度只能通过问卷调查或者在线实验获得，而推荐结果和用户历史上喜欢的物品相似度一般可以用内容相似度定义。也就是说，如果获得了一个用户观看电影的历史，得到这些电影的演员和导演集合A，然后给用户推荐一个不属于集合A的导演和演员创作的电影，而用户表示非常满意，这样就实现了一个惊喜度很高的推荐。

#### 7. 信任度

​	同样的推荐结果，以让用户信任的方式推荐给用户就更能让用户产生购买欲，而以类似广告形式的方法推荐给用户就可能很难让用户产生购买的意愿。

​	提高推荐系统的信任度主要有两种方法。

+ 首先需要增加推荐系统的透明度（transparency），而增加推荐系统透明度的主要办法是提供推荐解释。只有让用户了解推荐系统的运行机制，让用户认同推荐系统的运行机制，才会提高用户对推荐系统的信任度。
+ 其次是考虑用户的社交网络信息，利用用户的好友信息给用户做推荐，并且用好友进行推荐解释。这是因为用户对他们的好友一般都比较信任，因此如果推荐的商品是好友购买过的，那么他们对推荐结果就会相对比较信任。

> Epinion为了防止垃圾评论或者广告评论影响用户的决策，在每条用户评论的右侧都显示了评论作者的信息，并且让用户判断是信任该评论人还是将他加入黑名单。如果网站具有Epinion的用户信任系统，那么可以在给用户做推荐时，尽量推荐他信任的其他用户评论过的物品。

#### 8. 实时性

​	很多推荐系统都会在离线状态每天计算一次用户推荐列表，然后于在线期间将推荐列表展示给用户。这种设计显然是无法满足实时性的。与用户行为相应的实时性，可以通过推荐列表的变化速率来评测。**如果推荐列表在用户有行为后变化不大，或者没有变化，说明推荐系统的实时性不高**。

​	实时性的第二个方面是推荐系统需要能够**将新加入系统的物品推荐给用户**。这主要考验了推荐系统处理物品**冷启动**的能力。

​	对于新物品推荐能力，我们可以利用用户推荐列表中有多大比例的物品是当天新加的来评测。

#### 9. 健壮性

​	任何一个能带来利益的算法系统都会被人攻击，这方面最典型的例子就是搜索引擎。搜索引擎的作弊和反作弊斗争异常激烈，这是因为如果能让自己的商品成为热门搜索词的第一个搜索果，会带来极大的商业利益。推荐系统目前也遇到了同样的作弊问题，而**健壮性（即robust,鲁棒性）指标衡量了一个推荐系统抗击作弊的能力**。

​	**算法健壮性的评测主要利用模拟攻击**。首先，给定一个数据集和一个算法，可以用这个算法给这个数据集中的用户生成推荐列表。然后，用常用的攻击方法向数据集中注入噪声数据，然后利用算法在注入噪声后的数据集上再次给用户生成推荐列表。最后，通过比较攻击前后推荐列表的相似度评测算法的健壮性。如果攻击后的推荐列表相对于攻击前没有发生大的变化，就说明算法比较健壮。

​	在实际系统中，提高系统的健壮性，除了选择健壮性高的算法，还有以下方法。

+ **设计推荐系统时尽量使用代价比较高的用户行为**。比如，如果有用户购买行为和用户浏览行为，那么主要应该使用用户购买行为，因为购买需要付费，所以攻击购买行为的代价远远大于攻击浏览行为。
+ 在使用数据前，进行攻击检测，从而对数据进行清理。

> 众所周知，绝大部分推荐系统都是通过分析用户的行为实现推荐算法的。
>
> 比如，亚马逊有一种推荐叫做“购买商品A的用户也经常购买的其他商品”。它的主要计算方法是统计购买商品A的用户购买其他商品的次数。那么，我们可以很简单地攻击这个算法，让自己的商品在这个推荐列表中获得比较高的排名，比如可以注册很多账号，用这些账号同时购买A和自己的商品。
>
> 还有一种攻击主要针对评分系统，比如豆瓣的电影评分。这种攻击很简单，就是雇用一批人给自己的商品非常高的评分，而评分行为是推荐系统依赖的重要用户行为。

#### 10. 商业目标

​	很多时候，网站评测推荐系统更加注重网站的商业目标是否达成，而商业目标和网站的盈利模式是息息相关的。一般来说，最本质的商业目标就是平均一个用户给公司带来的盈利。不过这种指标不是很难计算，只是计算一次需要比较大的代价。因此，很多公司会根据自己的盈利模式设计不同的商业目标。

​	不同的网站具有不同的商业目标。比如电子商务网站的目标可能是销售额，基于展示广告盈利的网站其商业目标可能是广告展示总数，基于点击广告盈利的网站其商业目标可能是广告点击总数。因此，设计推荐系统时需要考虑最终的商业目标，而网站使用推荐系统的目的除了满足用户发现内容的需求，也需要利用推荐系统加快实现商业上的指标。

#### 11. 总结

​	获取各种评测指标的途径

|            | 离线实验 | 问卷调查 | 在线实验 |
| ---------- | -------- | -------- | -------- |
| 用户满意度 | ✖️        | ☑️        | ⭕️        |
| 预测准确度 | ☑️        | ☑️        | ✖️        |
| 覆盖率     | ☑️        | ☑️        | ☑️        |
| 多样性     | ⭕️        | ☑️        | ⭕️        |
| 新颖性     | ⭕️        | ☑️        | ⭕️        |
| 惊喜度     | ✖️        | ☑️        | ✖️        |

​	对于可以离线优化的指标，书籍作者的建议是应该在给定覆盖率、多样性、新颖性等限制条件下，尽量优化预测准确度。

用一个数学公式表达，离线实验的优化目标是：

```none
最大化预测准确度
使得 覆盖率 > A
		多样性 > B
		新颖性 > C
其中，A、B、C的取值应该视不同的应用而定。
```

### 1.3.3 评测维度

​	增加评测维度的目的就是知道一个算法在什么情况下性能最好。这样可以为融合不同推荐算法取得最好的整体性能带来参考。

​	一般来说，评测维度分为如下3种。

+ 用户维度：主要包括用户的人口统计学信息、活跃度以及是不是新用户等。

+ 物品维度：包括物品的属性信息、流行度、平均分以及是不是新加入的物品等。

+ 时间维度：包括季节，是工作日还是周末，是白天还是晚上等。

​	如果能够在推荐系统评测报告中包含不同维度下的系统评测指标，就能帮我们全面地了解推荐系统性能，找到一个看上去比较弱的算法的优势，发现一个看上去比较强的算法的缺点。

# 2. 第2章 利用用户行为数据

> [数据挖掘中最经典的案例之一-啤酒与尿布是真实的案例吗？](https://www.zhihu.com/question/20567005)

​	实现个性化推荐的最理想情况是用户能在注册的时候主动告诉我们他喜欢什么，但这种方法有３个缺点：

+ 首先，现在的自然语言理解技术很难理解用户用来描述兴趣的自然语言；
+ 其次，用户的兴趣是不断变化的，但用户不会不停地更新兴趣描述；
+ 最后，很多时候用户并不知道自己喜欢什么，或者很难用语言描述自己喜欢什么。

​	因此，我们需要通过算法自动发掘用户行为数据，从用户的行为中推测出用户的兴趣，从而给用户推荐满足他们兴趣的物品。

​	啤酒和尿布的故事在互联网上被发扬光大。电子商务公司通过分析用户的购物车，找出诸如“购买A商品的用户都购买B商品”这种规律，同时在用户浏览A商品时直接为其展示购买A商品的用户都购买的其他商品。

​	基于用户行为分析的推荐算法是个性化推荐系统的重要算法，学术界一般将这种类型的算法称为**协同过滤算法**。顾名思义，协同过滤就是指用户可以齐心协力，通过不断地和网站互动，使自己的推荐列表能够不断过滤掉自己不感兴趣的物品，从而越来越满足自己的需求。

> 当当网在用户浏览《数据挖掘导论》时给用户推荐“购买本商品的顾客还买过”的书

## 2.1 用户行为数据简介

​	本章提到的个性化推荐算法都是基于用户行为数据分析设计的，因此本节将首先介绍用户行为数据。

​	用户行为数据在网站上最简单的存在形式就是日志。网站在运行过程中都产生大量原始日志（raw log），并将其存储在文件系统中。很多互联网业务会把多种原始日志按照用户行为汇总成会话日志（session log），其中每个 会话表示一次用户行为和对应的服务。比如，在搜索引擎和搜索广告系统中，服务会为每次查询生成一个展示日志（impression log），其中记录了查询和返回结果。如果用户点击了某个结果，这个点击信息会被服务器截获并存储在点击日志（click log）中。一个并行程序会周期性地归并展示日志和点击日志，得到的会话日志中每个消息是一个用户提交的查询、得到的结果以及点击。类似地，推荐系统和电子商务网站也会汇总原始日志生成描述用户行为的会话日志。会话日志通常存储在分布式数据仓库中，如支持离线分析的 Hadoop Hive和支持在线分析的Google Dremel。这些日志记录了用户的各种行为，如在电子商务网站中这些行为主要包括网页浏览、购买、点击、评分和评论等。

​	用户行为在个性化推荐系统中一般分两种：

+ 显性反馈行为（explicit feedback）
+ 隐性反馈行为（implicit feedback）

​	**显性反馈行为包括用户明确表示对物品喜好的行为**。

​	**隐性反馈行为指的是那些不能明确反应用户喜好的行为**。最具代表性的隐性反馈行为就是页面浏览行为。用户浏览一个物品的页面并不代表用户一定喜欢这个页面展示的物品，比如可能因为这个页面链接显示在首页，用户更容易点击它而已。相比显性反馈，隐性反馈虽然不明确，但数据量更大。在很多网站中，很多用户甚至只有隐性反馈数据，而没有显性反馈数据。

​	显性反馈数据和隐性反馈数据的比较

|          | 显性反馈数据 | 隐性反馈数据   |
| -------- | ------------ | -------------- |
| 用户兴趣 | 明确         | 不明确         |
| 数量     | 较少         | 庞大           |
| 存储     | 数据库       | 分布式文件系统 |
| 实时读取 | 实时         | 有延迟         |
| 正负反馈 | 都有         | **只有正反馈** |

​	各代表网站中显性反馈数据和隐性反馈数据的例子

|              | 显性反馈                   | 隐性反馈                               |
| ------------ | -------------------------- | -------------------------------------- |
| 视频网站     | 用户对视频的评分           | 用户观看视频的日志、浏览视频页面的日志 |
| 电子商务网站 | 用户对商品的评分           | 购买日志、浏览日志                     |
| 门户网站     | 用户对新闻的评分           | 阅读新闻的日志                         |
| 音乐网站     | 用户对音乐/歌手/专辑的评分 | 听歌的日志                             |

​	用户行为的统一表示

| 符号             | 说明                                                         |
| ---------------- | ------------------------------------------------------------ |
| user id          | 产生行为的用户的唯一标示                                     |
| item id          | 产生行为的用户的唯一标示                                     |
| behavior type    | 行为的种类（比如是购买还是浏览）                             |
| context          | 产生行为的上下文、包括时间和地点等                           |
| behavior weight  | 行为的权重（如果是观看视频的行为，那么这个权重可以是观看视频的时长；如果是打分行为，这个权重可以是分数） |
| behavior content | 行为的内容（如果是评论行为，那么就是评论的文本；如果是打标签的行为，就是标签） |

​	一般来说，不同的数据集包含不同的行为，目前比较有代表性的数据集有下面几个。

+ 无上下文信息的隐性反馈数据集：每一条行为记录仅仅包含用户ID和物品ID。

+ 无上下文信息的显性反馈数据集：每一条记录包含用户ID、物品ID和用户对物品的评分。

+ 有上下文信息的隐性反馈数据集：每一条记录包含用户ID、物品ID和用户对物品产生行为的时间戳。Lastfm数据集就是这种类型的数据集。

+ 有上下文信息的显性反馈数据集：每一条记录包含用户ID、物品ID、用户对物品的评分和评分行为发生的时间戳。Netflix Prize提供的就是这种类型的数据集。

​	本章使用的数据集基本都是第一种数据集，即无上下文信息的隐性反馈数据集。

> YouTube最早是用5分评分系统收集显性反馈的，但后来他们的研究人员统计了不同评分的评分数，结果发现，用户最常用的评分是5分，其次是1分，其他的分数很少有用户打。因此，后来YouTube就把评分系统改成了两档评分系统（喜欢/不喜欢）。
>
> YouTube的用户主要将精力放在看视频上，因此他们只有在特别不满或者特别满意时才会评分，因此二级评分系统就足够了。但如果是评论网站，用户主要将精力放在评论上，这时多级评分系统就是必要的。

## 2.2 用户行为分析

​	首先需要对用户行为数据进行分析，了解数据中蕴含的一般规律，这样才能对算法的设计起到指导作用。

### 2.2.1 用户活跃度和物品流行度的分布

> [什么是「长尾效应」 ？](https://www.zhihu.com/question/20027490/answer/259310914)

​	很多关于互联网数据的研究发现，互联网上的很多数据分布都满足一种称为Power Law的分布，这个分布在互联网领域也称**长尾分布**。

​	用户行为数据也蕴含着这种规律。

### 2.2.2 用户活跃度和物品流行度的关系

​	一般来说，不活跃的用户要么是新用户，要么是只来过网站一两次的老用户。那么，不同活跃度的用户喜欢的物品的流行度是否有差别？**一般认为，新用户倾向于浏览热门的物品**，因为他们对网站还不熟悉，只能点击首页的热门物品，而**老用户会逐渐开始浏览冷门的物品**。

​	**仅仅基于用户行为数据设计的推荐算法一般称为协同过滤算法**。学术界对协同过滤算法进行了深入研究，提出了很多方法，比如：

+ **基于邻域的方法**（neighborhood-based）
+ 隐语义模型（latent factor model）
+ 基于图的随机游走算法（random walk on graph）

​	在这些方法中，最著名的、**在业界得到最广泛应用的算法是基于邻域的方法**，而基于邻域的方法主要包含下面两种算法。

+ **基于用户的协同过滤算法：这种算法给用户推荐和他兴趣相似的其他用户喜欢的物品。**

+ **基于物品的协同过滤算法：这种算法给用户推荐和他之前喜欢的物品相似的物品。**

下面几节将首先介绍上面两种算法，然后再简单介绍隐语义模型和基于图的模型。

## 2.3 实验设计和算法评测

​	前文说过，评测推荐系统有3种方法——离线实验、用户调查和在线实验。本节将通过离线实验方法评测提到的算法。首先介绍用到的数据集，然后介绍采用的实验方法和评测指标。

### 2.3.1 数据集

​	本章采用GroupLens提供的MovieLens数据集介绍和评测各种算法。 MovieLens数据集有3个不同的版本，本章选用中等大小的数据集。该数据集包含6000多用户对4000多部电影的100万条评分。该数据集是一个评分数据集，用户可以给电影评5个不同等级的分数（1～5分）。**本章着重研究隐反馈数据集中的TopN推荐问题，因此忽略了数据集中的评分记录**。也就是说，TopN推荐的任务是预测用户会不会对某部电影评分，而不是预测用户在准备对某部电影评分的前提下会给电影评多少分。

### 2.3.2 实验设计

> [用简单易懂的语言描述「过拟合 overfitting」？](https://www.zhihu.com/question/32246256)

​	协同过滤算法的离线实验一般如下设计。首先，将用户行为数据集按照均匀分布随机分成M份（本章取M=8），挑选一份作为测试集，将剩下的M-1份作为训练集。然后在训练集上建立用户兴趣模型，并在测试集上对用户行为进行预测，统计出相应的评测指标。<u>为了保证评测指标并不是过拟合的结果，需要进行M次实验，并且每次都使用不同的测试集。然后将M次实验测出的评测指标的平均值作为最终的评测指标。</u>

​	下面的Python代码描述了将数据集随机分成训练集和测试集的过程：

```python
def SplitData(data, M, k, seed):
  test = []
  train = []
  random.seed(seed)
  for user, item in data:
    if random.randint(0,M) == k:
      test.append([user,item])
    else:
      train.append([user,item])
  return train, test
```

​	这里，每次实验选取不同的k（0 ≤ k ≤ M-1）和相同的随机数种子seed，进行M次实验就可以得到M个不同的训练集和测试集，然后分别进行实验，用M次实验的平均值作为最后的评测指标。这样做主要是防止某次实验的结果是过拟合的结果（over fitting），**但如果数据集够大，模型够简单，为了快速通过离线实验初步地选择算法，也可以只进行一次实验**。

### 2.3.3 评测指标

> [如何解释召回率与精确率？](https://www.zhihu.com/question/19645541)
>
> 召回率 (Recall)：正样本有多少被找出来了（召回了多少）。
>
> 精确率 (Precision)：你认为的正样本，有多少猜对了（猜的精确性如何）。

​	**召回率描述有多少比例的用户—物品评分记录包含在最终的推荐列表中，而准确率描述最终的推荐列表中有多少比例是发生过的用户—物品评分记录**。下面两段代码给出了召回率和准确率的计算方法。

```python
def Recall(train, test, N):
  hit = 0
  all = 0
  for user in train.keys():
    tu = test[user]
    rank = GetRecommendation(user, N)
    for item, pui in rank:
      if item in tu:
        hit += 1
        all += len(tu)
  return hit / (all * 1.0)
def Precision(train, test, N):
  hit = 0
  all = 0
  for user in train.keys():
    tu = test[user]
    rank = GetRecommendation(user, N)
      for item, pui in rank:
        if item in tu:
          hit += 1
      all += N
  return hit / (all * 1.0)
```

​	除了评测推荐算法的精度，本章还计算了算法的覆盖率，**覆盖率反映了推荐算法发掘长尾的能力**，覆盖率越高，说明推荐算法越能够将长尾中的物品推荐给用户。

​	如果所有的物品都被推荐给至少一个用户，那么覆盖率就是100%。如下代码可以用来计算推荐算法的覆盖率：

```python
def Coverage(train, test, N):
  recommend_items = set()
  all_items = set()
  for user in train.keys():
    for item in train[user].keys():
      all_items.add(item)
    rank = GetRecommendation(user, N)
    for item, pui in rank:
      recommend_items.add(item)
  return len(recommend_items) / (len(all_items) * 1.0)
```

​	最后，我们还需要评测推荐的新颖度，这里用推荐列表中物品的平均流行度度量推荐结果的新颖度。如果推荐出的物品都很热门，说明推荐的新颖度较低，否则说明推荐结果比较新颖。

```python
def Popularity(train, test, N):
  item_popularity = dict()
  for user, items in train.items():
    for item in items.keys()
    	if item not in item_popularity:
      	item_popularity[item] = 0
      item_popularity[item] += 1
  ret = 0
  n = 0
  for user in train.keys():
    rank = GetRecommendation(user, N)
    for item, pui in rank:
      ret += math.log(1 + item_popularity[item])
      n += 1
  ret /= n * 1.0
  return ret
```

​	这里，在计算平均流行度时对每个物品的流行度取对数，这是因为物品的流行度分布满足长尾分布，在取对数后，流行度的平均值更加稳定。

> [在统计学中为什么要对变量取对数？](https://www.zhihu.com/question/22012482)
>
> 要研究A和B的关系，可以先研究 lnA和B的关系，因为令 z=lnA，那么 z和B的关系搞明白了，只要取 A=e^z，则 A和B的关系也出来了。所以如果你要研究A和B的关系，那么研究 “A的变换”和“B的变换”之间的关系也是可以的。
>
> 统计学中你要使用某个方法，就要满足这个方法的条件，如果你所研究的变量不满足条件，但是变量进行变换后就满足条件了，那么就可以进行变换。通常 “对数变换” 使用的最频繁，因为对数变换后你会神奇的发现条件就满足了。
>
> 比如一个右偏非负的数据（最常见的就是工资，财富），不满足正态，但是取对数后就符合正态了。
>
> 取对数还有其他的好处，其中一个就是能把大的数变小。变小的同时数据的方差也变小。比如动物的体重和身高。有老鼠，有大象，有恐龙。数据出来后你会发现恐龙，大象的数据非常大，另外方差也特别大。大象，恐龙的数据看起来就像是异常值，但是它们不是异常值，这种数据分析起来非常不好处理，怎么办？身高体重都取对数，变换后你会发现豁然开朗！
>
> 总的来说，取对数就是为了把不满足的条件变成满足或者让我们分析的结果变得更好一点。

## 2.4 基于邻域的算法

​	基于邻域的算法是推荐系统中最基本的算法，该算法不仅在学术界得到了深入研究，而且在业界得到了广泛应用。基于邻域的算法分为两大类，一类是基于用户的协同过滤算法，另一类是基于物品的协同过滤算法。下面几节将对这两种算法进行深入介绍，对比它们的优缺点并提出改进方案。

### 2.4.1 基于用户的协同过滤算法

​	**基于用户的协同过滤算法是推荐系统中最古老的算法**。可以不夸张地说，这个算法的诞生标志了推荐系统的诞生。该算法在1992年被提出，并应用于邮件过滤系统，1994年被GroupLens用于新闻过滤。在此之后直到200年，该算法都是推荐系统领域最著名的算法。本节将对该算法进行详细介绍，首先介绍最基础的算法，然后在此基础上提出不同的改进方法，并通过真实的数据集进行评测。

#### 1. 基础算法

​	基于用户的协同过滤算法主要包括两个步骤。

1. 找到和目标用户兴趣相似的用户集合。

2. 找到这个集合中的用户喜欢的，且目标用户没有听说过的物品推荐给目标用户。

步骤(1)的关键就是计算两个用户的兴趣相似度。这里，协同过滤算法主要**利用行为的相似度计算兴趣的相似度**。

参数K是UserCF的一个重要参数，它的调整对推荐算法的各种指标都会产生一定的影响。

+ 准确率和召回率：可以看到，推荐系统的精度指标（准确率和召回率）并不和参数K成线性关系。在MovieLens数据集中，选择K=80左右会获得比较高的准确率和召回率。因此选择合适的K对于获得高的推荐系统精度比较重要。当然，推荐结果的精度对K也不是特别敏感，只要选在一定的区域内，就可以获得不错的精度。

+ 流行度：可以看到，在3个数据集上K越大则UserCF推荐结果就越热门。这是因为K决定了UserCF在给你做推荐时参考多少和你兴趣相似的其他用户的兴趣，那么如果K越大，参考的人越多，结果就越来越趋近于全局热门的物品。

+ 覆盖率：可以看到，在3个数据集上，K越大则UserCF推荐结果的覆盖率越低。覆盖率的降低是因为流行度的增加，随着流行度增加，UserCF越来越倾向于推荐热门的物品，从而对长尾物品的推荐越来越少，因此造成了覆盖率的降低。

#### 2. 用户相似度计算的改进

​	上一节介绍了计算用户兴趣相似度的最简单的公式（余弦相似度公式），但这个公式过于粗糙，本节将讨论如何改进该公式来提高UserCF的推荐性能。

​	**两个用户对冷门物品采取过同样的行为更能说明他们兴趣的相似度**。

#### 3. 实际在线系统使用UserCF的例子

​	**相比我们后面要讨论的基于物品的协同过滤算法（ItemCF）， UserCF在目前的实际应用中使用并不多**。

> Digg在博客中公布了使用推荐系统后的效果，主要指标如下所示。
>
> + 用户反馈增加：用户“顶”和“踩”的行为增加了40%。
>
> + 平均每个用户将从34个具相似兴趣的好友那儿获得200条推荐结果。
>
> + 用户和好友的交互活跃度增加了24%。
>
> + 用户评论增加了11%。
>
> 上面只是对比了使用推荐系统后和使用推荐系统前的结果，并非AB测试的结果，因此还不完全具有说服力，但还是部分证明了推荐系统的有效性。

### 2.4.2 基于物品的协同过滤算法

​	**基于物品的协同过滤（item-based collaborative filtering）算法是目前业界应用最多的算法**。无论是亚马逊网，还是Netflix、Hulu、YouTube，其推荐算法的基础都是该算法。本节将从基础的算法开始介绍，然后提出算法的改进方法，并通过实际数据集评测该算法。

#### 1. 基础算法

​	基于用户的协同过滤算法在一些网站（如Digg）中得到了应用，但该算法有一些缺点。

+ 首先，**随着网站的用户数目越来越大，计算用户兴趣相似度矩阵将越来越困难，其运算时间复杂度和空间复杂度的增长和用户数的增长近似于平方关系。**
+ 其次，**基于用户的协同过滤很难对推荐结果作出解释**。

​	因此，著名的电子商务公司亚马逊提出了另一个算法——基于物品的协同过滤算法。

​	**基于物品的协同过滤算法（简称ItemCF）给用户推荐那些和他们之前喜欢的物品相似的物品**。比如，该算法会因为你购买过《数据挖掘导论》而给你推荐《机器学习》。不过，ItemCF算法并不利用物品的内容属性计算物品之间的相似度，它主要通过分析用户的行为记录计算物品之间的相似度。

​	该算法认为，**物品A和物品B具有很大的相似度是因为喜欢物品A的用户大都也喜欢物品B。**

​	基于物品的协同过滤算法可以利用用户的历史行为给推荐结果提供推荐解释，比如给用户推荐《天龙八部》的解释可以是因为用户之前喜欢《射雕英雄传》。

> + 亚马逊在iPhone商品界面上提供的与iPhone相关的商品，而相关商品都是购买iPhone的用户也经常购买的其他商品。
> + Hulu在个性化视频推荐利用ItemCF给每个推荐结果提供了一个推荐解释，而用于解释的视频都是用户之前观看或者收藏过的视频。

基于物品的协同过滤算法主要分为两步。

1. 计算物品之间的相似度。

2. 根据物品的相似度和用户的历史行为给用户生成推荐列表。

​	在协同过滤中两个物品产生相似度是因为它们共同被很多用户喜欢，也就是说每个用户都可以通过他们的历史兴趣列表给物品“贡献”相似度。这里面蕴涵着一个假设，<u>就是每个用户的兴趣都局限在某几个方面，因此如果两个物品属于一个用户的兴趣列表，那么这两个物品可能就属于有限的几个领域，而如果两个物品属于很多用户的兴趣列表，那么它们就可能属于同一个领域，因而有很大的相似度</u>。

​	ItemCF通过公式计算用户对一个物品的兴趣，**和用户历史上感兴趣的物品越相似的物品，越有可能在用户的推荐列表中获得比较高的排名**。

​	**ItemCF的一个优势就是可以提供推荐解释，即利用用户历史上喜欢的物品为现在的推荐结果进行解释**。

​	在MovieLens数据集上ItemCF算法离线实验的各项性能指标的评测结果。

+ 精度（准确率和召回率）：可以看到ItemCF推荐结果的精度也是不和K成正相关或者负相关的，因此选择合适的K对获得最高精度是非常重要的。

+ 流行度：和UserCF不同，参数K对ItemCF推荐结果流行度的影响也不是完全正相关的。随着K的增加，结果流行度会逐渐提高，但当K增加到一定程度，流行度就不会再有明显变化。

+ 覆盖率：K增加会降低系统的覆盖率。

#### 2. 用户活跃度对物品相似度的影响

​	从前面的讨论可以看到，在协同过滤中两个物品产生相似度是因为它们共同出现在很多用户的兴趣列表中。换句话说，每个用户的兴趣列表都对物品的相似度产生贡献。那么，是不是每个用户的贡献都相同呢？

​	假设有这么一个用户，他是开书店的，并且买了当当网上80%的书准备用来自己卖。那么，他的购物车里包含当当网80%的书。假设当当网有100万本书，也就是说他买了80万本。从前面对ItemCF的讨论可以看到，这意味着因为存在这么一个用户，有80万本书两两之间就产生了相似度，也就是说，内存里即将诞生一个80万乘80万的稠密矩阵。

​	另外可以看到，这个用户虽然活跃，但是买这些书并非都是出于自身的兴趣，而且这些书覆盖了当当网图书的很多领域，所以**这个用户对于他所购买书的两两相似度的贡献应该远远小于一个只买了十几本自己喜欢的书的文学青年**。

​	John S. Breese在论文中提出了一个称为IUF（Inverse User Frequence），即用户活跃度对数的倒数的参数，他也认为**活跃用户对物品相似度的贡献应该小于不活跃的用户**。

​	**对于很多过于活跃的用户，比如上面那位买了当当网80%图书的用户，为了避免相似度矩阵过于稠密，我们在实际计算中一般直接忽略他的兴趣列表，而不将其纳入到相似度计算的数据集中**。

#### 3. 物品相似度的归一化

​	Karypis在研究中发现如果将ItemCF的相似度矩阵按最大值归一化，可以提高推荐的准确率。

​	**归一化的好处不仅仅在于增加推荐的准确度，它还可以提高推荐的覆盖率和多样性**。

​	对于两个不同的类，什么样的类其类内物品之间的相似度高，什么样的类其类内物品相似度低呢？**一般来说，热门的类其类内物品相似度一般比较大**。如果不进行归一化，就会推荐比较热门的类里面的物品，而这些物品也是比较热门的。因此，推荐的覆盖率就比较低。相反，如果进行相似度的归一化，则可以提高推荐系统的覆盖率。

> 假设物品分为两类——A和B，A类物品之间的相似度为0.5，B类物品之间的相似度为0.6，而A类物品和B类物品之间的相似度是0.2。在这种情况下，如果一个用户喜欢了5个A类物品和5个B类物品，用ItemCF给他进行推荐，推荐的就都是B类物品，因为B类物品之间的相似度大。但如果归一化之后，A类物品之间的相似度变成了1，B类物品之间的相似度也是1，那么这种情况下，用户如果喜欢5个A类物品和5个B类物品，那么他的推荐列表中A类物品和B类物品的数目也应该是大致相等的。从这个例子可以看出，相似度的归一化可以提高推荐的多样性。

### 2.4.3 UserCF和ItemCF的综合比较

​	UserCF是推荐系统领域较为古老的算法，1992年就已经在电子邮件的个性化推荐系统Tapestry中得到了应用，1994年被GroupLens用来实现新闻的个性化推荐，后来被著名的文章分享网站Digg用来给用户推荐个性化的网络文章。ItemCF则是相对比较新的算法，在著名的电子商务网站亚马逊和DVD租赁网站Netflix中得到了广泛应用。

+ **UserCF给用户推荐那些和他有共同兴趣爱好的用户喜欢的物品**
+ **ItemCF给用户推荐那些和他之前喜欢的物品类似的物品**

​	从这个算法的原理可以看到，UserCF的推荐结果着重于反映和用户兴趣相似的小群体的热点，而ItemCF的推荐结果着重于维系用户的历史兴趣。换句话说，**UserCF的推荐更社会化，反映了用户所在的小型兴趣群体中物品的热门程度，而ItemCF的推荐更加个性化，反映了用户自己的兴趣传承**。

​	UserCF适合用于新闻推荐的另一个原因是从技术角度考量的。因为作为一种物品，新闻的更新非常快，每时每刻都有新内容出现，而ItemCF需要维护一张物品相关度的表，如果物品更新很快，那么这张表也需要很快更新，这在技术上很难实现。**绝大多数物品相关度表都只能做到一天一次更新**，这在新闻领域是不可以接受的。而UserCF只需要用户相似性表，虽然UserCF对于新用户也需要更新相似度表，但**在新闻网站中，物品的更新速度远远快于新用户的加入速度**，而且对于新用户，完全可以给他推荐最热门的新闻，因此UserCF显然是利大于弊。

​	但是，在图书、电子商务和电影网站，比如亚马逊、豆瓣、Netflix中，ItemCF则能极大地发挥优势。首先，在这些网站中，用户的兴趣是比较固定和持久的。一个技术人员可能都是在购买技术方面的书，而且他们对书的热门程度并不是那么敏感，事实上**越是资深的技术人员，他们看的书就越可能不热门**。此外，这些系统中的用户大都不太需要流行度来辅助他们判断一个物品的好坏，而是可以通过自己熟悉领域的知识自己判断物品的质量。因此，这些网站中个性化推荐的任务是**帮助用户发现和他研究领域相关的物品**。因此，ItemCF算法成为了这些网站的首选算法。此外，**这些网站的物品更新速度不会特别快，一天一次更新物品相似度矩阵对它们来说不会造成太大的损失**，是可以接受的。

​	同时，从技术上考虑：

+ **UserCF需要维护一个用户相似度的矩阵**
+ **ItemCF需要维护一个物品相似度矩阵**。

​	从存储的角度说，如果用户很多，那么维护用户兴趣相似度矩阵需要很大的空间，同理，如果物品很多，那么维护物品相似度矩阵代价较大。

​	在早期的研究中，大部分研究人员都是让少量的用户对大量的物品进行评价，然后研究用户兴趣的模式。那么，对于他们来说，因为用户很少，计算用户兴趣相似度是最快也是最简单的方法。但在实际的互联网中，用户数目往往非常庞大，而在图书、电子商务网站中，物品的数目则是比较少的。此外，物品的相似度相对于用户的兴趣一般比较稳定，因此使用ItemCF是比较好的选择。当然，新闻网站是个例外，在那儿，物品的相似度变化很快，物品数目庞大，相反用户兴趣则相对固定（都是喜欢看热门的），所以新闻网站的个性化推荐使用UserCF算法的更多。

​	UserCF和ItemCF优缺点的对比

<table>
  <tr>
    <th></th>
    <th>UserCF</th>
    <th>ItemCF</th>
  </tr>
  <tr>
    <td>性能</td>
    <td>
      <p>
        适用于用户较少的场合，如果用户很多，计算用户相似度矩阵代价很大
      </p>
    </td>
    <td>
      <p>
        适用于物品数明显小于用户数的场合，如果物品很多（网页），计算物品相似度矩阵代价很大
      </p>
    </td>
  </tr>
  <tr>
    <td>领域</td>
    <td>时效性较强，用户个性化兴趣不太明显的领域</td>
    <td>长尾物品丰富，用户个性化需求强烈的领域</td>
  </tr>
  <tr>
    <td>实时性</td>
    <td>用户有新行为，不一定造成推荐结果的立即变化</td>
    <td>用户有新行为，一定会导致推荐结果的实时变化</td>
  </tr>
  <tr>
    <td>冷启动</td>
    <td>
      <p>
        在新用户对很少的物品产生行为后，不能立即对他进行个性化推荐，因为用户相似度表是每隔一段时间离线计算的
        <br/>
        新物品上线后一段时间，一旦有用户对物品产生行为，就可以将新物品推荐给和对它产生行为的用户兴趣相似的其他用户
      </p>
    </td>
    <td>
      <p>
        新用户只要对一个物品产生行为，就可以给他推荐和该物品相关的其他物品
        <br/>
        但没有办法在不离线更新物品相似度表的情况下将新物品推荐给用户
      </p>
    </td>
  </tr>
  <tr>
    <td>推荐理由</td>
    <td>很难提供令用户信服的推荐解释</td>
    <td>利用用户的历史行为给用户做推荐解释，可以令用户比较信服</td>
  </tr>
</table>



​	首先要指出的是，**离线实验的性能在选择推荐算法时并不起决定作用**。

+ 首先应该满足产品的需求，比如如果需要提供推荐解释，那么可能得选择ItemCF算法。
+ 其次，需要看实现代价，比如若用户太多，很难计算用户相似度矩阵，这个时候可能不得不抛弃UserCF算法。
+ 最后，离线指标和点击率等在线指标不一定成正比。

​	 而且，这里对比的是最原始的UserCF和ItemCF算法，这两种算法都可以进行各种各样的改进。**一般来说，这两种算法经过优化后，最终得到的离线性能是近似的**。

​	下一节将分析为什么原始ItemCF算法的覆盖率和新颖度都不高。

#### 哈利波特问题

​	亚马逊网的研究人员在设计ItemCF算法之初发现ItemCF算法计算出的图书相关表存在一个问题，就是很多书都和《哈利波特》相关。也就是说，购买任何一本书的人似乎都会购买《哈利波特》。后来他们研究发现，主要是因为《哈利波特》太热门了，确实是购买任何一本书的人几乎都会购买它。

​	每个用户一般都会在不同的领域喜欢一种物品。以电视为例，看新闻联播是父辈每天的必修课，他们每天基本就看新闻联播，而且每天不看别的新闻，就看这一种新闻。此外，他们很多都是电视剧迷，都会看央视一套8点的电视剧。那么，最终结果就是黄金时间的电视剧都和新闻联播相似，而新闻联播和其他新闻的相似度很低。

​	上面的问题换句话说就是，**两个不同领域的最热门物品之间往往具有比较高的相似度**。<u>这个时候，仅仅靠用户行为数据是不能解决这个问题的，因为用户的行为表示这种物品之间应该相似度很高。此时，我们只能依靠引入物品的内容数据解决这个问题，比如对不同领域的物品降低权重等</u>。这些就不是协同过滤讨论的范畴了。

## 2.5 隐语义模型

> [最小推荐系统：隐语义模型(Latent Factor Model)](https://zhuanlan.zhihu.com/p/150285625)

​	自从Netflix Prize比赛举办以来，LFM（latent factor model）**隐语义模型**逐渐成为推荐系统领域耳熟能详的名词。其实该算法最早在文本挖掘领域被提出，用于找到文本的隐含语义。相关的名词有LSI、pLSA、LDA和Topic Model。本节将对隐含语义模型在Top-N推荐中的应用进行详细介绍，并通过实际的数据评测该模型。

### 2.5.1 基础算法

​	隐语义模型是最近几年推荐系统领域最为热门的研究话题，它的核心思想是**通过隐含特征(latent factor)联系用户兴趣和物品**。

​	通过一个例子来理解一下这个模型。用户A的兴趣涉及侦探小说、科普图书以及一些计算机技术书，而用户B的兴趣比较集中在数学和机器学习方面。

​	如何给A和B推荐图书呢？

+ 对于UserCF，首先需要找到和他们看了同样书的其他用户（兴趣相似的用户），然后给他们推荐那些用户喜欢的其他书。

+ 对于ItemCF，需要给他们推荐和他们已经看的书相似的书，比如作者B看了很多关于数据挖掘的书，可以给他推荐机器学习或者模式识别方面的书。

​	还有一种方法，可以对书和物品的兴趣进行分类。**对于某个用户，首先得到他的兴趣分类，然后从分类中挑选他可能喜欢的物品**。

​	总结一下，这个**基于兴趣分类**的方法大概需要解决3个问题。

+ 如何给物品进行分类？

+ 如何确定用户对哪些类的物品感兴趣，以及感兴趣的程度？

+ 对于一个给定的类，选择哪些属于这个类的物品推荐给用户，以及如何确定这些物品在一个类中的权重？

​	对于第一个问题的简单解决方案是找编辑给物品分类。以图书为例，每本书出版时，编辑都会给书一个分类。为了给图书分类，出版界普遍遵循中国图书分类法。但是，即使有很系统的分类体系，编辑给出的分类仍然具有以下缺点。

+ 编辑的意见<u>不能代表各种用户的意见</u>。比如，对于《具体数学》应该属于什么分类，有人认为应该属于数学，有些人认为应该属于计算机。从内容看，这本书是关于数学的，但从用户看，这本书的读大部分是做计算机出身的。<u>编辑的分类大部分是从书的内容出发，而不是从书的读者群出发</u>。

+ 编辑**很难控制分类的粒度**。我们知道分类是有不同粒度的，《数据挖掘导论》在粗粒度的分类中可能属于计算机技术，但在细粒度的分类中可能属于数据挖掘。**对于不同的用户，我们可能需要不同的粒度。比如对于一位初学者，我们粗粒度地给他做推荐就可以了，而对于一名资深研究人员，我们就需要深入到他的很细分的领域给他做个性化推荐**。

+ 编辑很难给一个物品多个分类。有的书不仅属于一个类，而是**可能属于很多的类**。

+ 编辑很难给出多维度的分类。我们知道，分类是可以有很多维度的，比如按照作者分类、按照译者分类、按照出版社分类。比如不同的用户看《具体数学》原因可能不同，有些人是因为它是数学方面的书所以才看的，而有些人是因为它是大师Knuth的著作所以才去看，因此**在不同人的眼中这本书属于不同的分类**。

+ 编辑很难决定一个物品在某一个**分类中的权重**。比如编辑可以很容易地决定《数据挖掘导论》属于数据挖掘类图书，但这本书在这类书中的定位是什么样的，编辑就很难给出一个准确的数字来表示。

​	为了解决上面的问题，研究人员提出：为什么我们不从数据出发，自动地找到那些类，然后进行个性化推荐？于是，隐含语义分析技术（latent variable analysis）出现了。隐含语义分析技术因为采取**基于用户行为统计的自动聚类**，较好地解决了上面提出的5个问题。

+ 编辑的意见不能代表各种用户的意见，但**隐含语义分析技术的分类来自对用户行为的统计，代表了用户对物品分类的看法**。**隐含语义分析技术和ItemCF在物品分类方面的思想类似，如果两个物品被很多用户同时喜欢，那么这两个物品就很有可能属于同一个类**。

+ 编辑很难控制分类的粒度，但**隐含语义分析技术允许我们指定最终有多少个分类**，这个数字越大，分类的粒度就会越细，反正分类粒度就越粗。

+ 编辑很难给一个物品多个分类，但**隐含语义分析技术会计算出物品属于每个类的权重**，因此每个物品都不是硬性地被分到某一个类中。

+ 编辑很难给出多维度的分类，但**隐含语义分析技术给出的每个分类都不是同一个维度的，它是基于用户的共同兴趣计算出来的**，如果用户的共同兴趣是某一个维度，那么LFM给出的类也是相同的维度。

+ 编辑很难决定一个物品在某一个分类中的权重，但**隐含语义分析技术可以通过统计用户行为决定物品在每个类中的权重**，如果喜欢某个类的用户都会喜欢某个物品，那么这个物品在这个类中的权重就可能比较高。

​	推荐系统的用户行为分为显性反馈和隐性反馈。**LFM在显性反馈数据（也就是评分数据）上解决评分预测问题并达到了很好的精度**。不过本章主要讨论的是隐性反馈数据集，这种数据集的特点是只有正样本（用户喜欢什么物品），而没有负样本（用户对什么物品不感兴趣）。

​	那么，**在隐性反馈数据集上应用LFM解决TopN推荐的第一个关键问题就是如何给每个用户生成负样本**。

​	对于这个问题，Rong Pan在文章中进行了深入探讨。他对比了如下几种方法。

+ 对于一个用户，用他所有没有过行为的物品作为负样本。

+ 对于一个用户，从他没有过行为的物品中均匀采样出一些物品作为负样本。

+ 对于一个用户，从他没有过行为的物品中采样出一些物品作为负样本，但采样时，保证每个用户的正负样本数目相当。

+ 对于一个用户，从他没有过行为的物品中采样出一些物品作为负样本，但采样时，偏重采样不热门的物品。

​	对于第一种方法，它的明显缺点是负样本太多，正负样本数目相差悬殊，因而计算复杂度很高，最终结果的精度也很差。对于另外3种方法，Rong Pan在文章中表示第三种好于第二种，而第二种好于第四种。

​	后来，通过2011年的KDD Cup的Yahoo! Music推荐系统比赛，我们发现对负样本采样时应该遵循以下原则：

+ **对每个用户，要保证正负样本的平衡（数目相似）。**
+ **对每个用户采样负样本时，要选取那些很热门，而用户却没有行为的物品。**

​	**一般认为，很热门而用户却没有行为更加代表用户对这个物品不感兴趣。因为对于冷门的物品，用户可能是压根没在网站中发现这个物品，所以谈不上是否感兴趣**。

​	在LFM中，重要的参数有4个：

+ 隐特征的个数F；

+ 学习速率alpha；

+ 正则化参数lambda；

+ **负样本/正样本比例 ratio。**

​	通过实验发现，**ratio参数对LFM的性能影响最大**。

​	随着负样本数目的增加，LFM的准确率和召回率有明显提高。不过当ratio>10以后，准确率和召回率基本就比较稳定了。同时，随着负样本数目的增加，覆盖率不断降低，而推荐结果的流行度不断增加，说明ratio参数控制了推荐算法发掘长尾的能力。如果将LFM的结果与前面ItemCF和UserCF算法的性能相比，可以发现LFM在所有指标上都优于UserCF和ItemCF。当然，这只是在MovieLens一个数据集上的结果，我们也发现，<u>当数据集非常稀疏时，LFM的性能会明显下降，甚至不如UserCF和ItemCF的性能</u>。

### 2.5.2 基于LFM的实际系统的例子

​	雅虎的研究人员公布过一个使用LFM进行雅虎首页个性化设计的方案①。本节将简单介绍他们的设计并讨论他们的设计方案。

​	雅虎首页的界面，包括不同的模块，比如左侧的分类导航列表、中间的热门新闻列表、右侧的最近热门话题列表。雅虎的研究人员认为这3个模块都可以进行一定的个性化，可以根据用户的兴趣给他们展示不同的内容。

​	当然，雅虎的研究人员在上面的模型基础上进行了一些修改，利用了一些改进的LFM模型。这些模型主要来自Netflix Prize比赛，因此我们会在第8章详细讨论这些模型。

​	但是，**LFM模型在实际使用中有一个困难，那就是它很难实现实时的推荐**。

​	经典的LFM模型每次训练时都**需要扫描所有的用户行为记录**，这样才能计算出用户隐类向量（pu）和物品隐类向量（qi）。而且LFM的训练需要在用户行为记录上**反复迭代才能获得比较好的性能**。因此，LFM的每次训练都很耗时，一般在实际应用中只能每天训练一次，并且计算出所有用户的推荐结果。

​	**LFM模型不能因为用户行为的变化实时地调整推荐结果来满足用户最近的行为**。

​	实时性在雅虎的首页个性化推荐系统中非常重要。为了解决传统LFM不能实时化，而产品需要实时性的矛盾，雅虎的研究人员提出了一个解决方案。

​	他们的解决方案分为两个部分。首先，他们利用新闻链接的内容属性（关键词、类别等）得到链接i的内容特征向量y<sub>i</sub>。其次，他们会实时地收集用户对链接的行为，并且用这些数据得到链接i的隐特征向量q<sub>i</sub>。然后，他们会利用如下公式预测用户u是否会单击链接i：
$$
r_{ui} = x^T_u . y_i + p^T_u . q_i
$$
​	其中，y<sub>i</sub>是根据物品的内容属性直接生成的，x<sub>uk</sub>是用户u对内容特征k的兴趣程度，用户向量x<sub>u</sub>可以根据历史行为记录获得，而且每天只需要计算一次。而p<sub>u</sub>、q<sub>i</sub>是根据实时拿到的用户最近几小时的行为训练LFM获得的。因此，对于一个新加入的物品i，可以通过x<sup>T</sup><sub>u</sub> \* y<sub>i</sub>估计用户u对物品i的兴趣，然后经过几个小时后，就可以通过p<sup>T</sup><sub>u</sub> \* q<sub>i</sub> 得到更加准确的预测值。

​	上面的讨论只是简单阐述了雅虎所用的方法，关于雅虎具体的方法可以参考他们的报告。

### 2.5.3 LFM和基于邻域的方法的比较

​	**LFM是一种基于机器学习的方法**，具有比较好的理论基础。这个方法和基于邻域的方法（比如UserCF、ItemCF）相比，各有优缺点。下面将从不同的方面对比LFM和基于邻域的方法。

+ 理论基础：LFM具有比较好的理论基础，它是一种学习方法，通过优化一个设定的指标
  建立最优的模型。**基于邻域的方法更多的是一种基于统计的方法，并没有学习过程**。

+ 离线计算的空间复杂度：**基于邻域的方法需要维护一张离线的相关表**。在离线计算相关
  表的过程中，如果用户/物品数很多，将会占据很大的内存。假设有M个用户和N个物品，
  在计算相关表的过程中，我们可能会获得一张比较稠密的临时相关表（尽管最终我们对
  每个物品只保留K个最相关的物品，但在中间计算过程中稠密的相关表是不可避免的），
  那么假设是用户相关表，则需要O(M\*M)的空间，而对于物品相关表，则需要O(N\*N)的空
  间。而LFM在建模过程中，如果是F个隐类，那么它需要的存储空间是O(F*(M+N))，这在
  M和N很大时可以很好地节省离线计算的内存。**在Netflix Prize中，因为用户数很庞大**
  **（40多万），很少有人使用UserCF算法（据说需要30 GB左右的内存），而LFM由于大量节**
  **省了训练过程中的内存（只需要4 GB），从而成为Netflix Prize中最流行的算法**。

+ 离线计算的时间复杂度：假设有M个用户、N个物品、K条用户对物品的行为记录。那么，
  UserCF计算用户相关表的时间复杂度是O(N * (K/N)^2)，而ItemCF计算物品相关表的时间
  复杂度是O(M*(K/M)^2)。而对于LFM，如果用F个隐类，迭代S次，那么它的计算复杂度
  是O(K * F * S)。那么，如果K/N > F*S，则代表UserCF的时间复杂度低于LFM，如果
  K/M>F\*S，则说明ItemCF的时间复杂度低于LFM。**在一般情况下，LFM的时间复杂度要**
  **稍微高于UserCF和ItemCF，这主要是因为该算法需要多次迭代**。但总体上，这两种算法
  在时间复杂度上没有质的差别。

+ 在线实时推荐：UserCF和ItemCF在线服务算法需要将相关表缓存在内存中，然后可以在
  线进行实时的预测。以ItemCF算法为例，一旦用户喜欢了新的物品，就可以通过查询内
  存中的相关表将和该物品相似的其他物品推荐给用户。因此，一旦用户有了新的行为，
  而且该行为被实时地记录到后台的数据库系统中，他的推荐列表就会发生变化。而从LFM
  的预测公式可以看到，**LFM在给用户生成推荐列表时，需要计算用户对所有物品的兴趣**
  **权重，然后排名，返回权重最大的N个物品**。那么，在物品数很多时，这一过程的时间
  复杂度非常高，可达O(M\*N\*F)。因此，**LFM不太适合用于物品数非常庞大的系统，如**
  **果要用，我们也需要一个比较快的算法给用户先计算一个比较小的候选列表，然后再用**
  **LFM重新排名。**另一方面，**LFM在生成一个用户推荐列表时速度太慢，因此不能在线实**
  **时计算，而需要离线将所有用户的推荐结果事先计算好存储在数据库中**。因此，**LFM不**
  **能进行在线实时推荐**，也就是说，当用户有了新的行为后，他的推荐列表不会发生变化。

+ 推荐解释：**ItemCF算法支持很好的推荐解释，它可以利用用户的历史行为解释推荐结果。**
  但LFM无法提供这样的解释，它计算出的隐类虽然在语义上确实代表了一类兴趣和物品，
  却很难用自然语言描述并生成解释展现给用户。

## 2.6 基于图的模型

​	用户行为很容易用二分图表示，因此很多图的算法都可以用到推荐系统中。本节将重点讨论如何将用户行为用图表示，并利用图的算法给用户进行个性化推荐。

### 2.6.1 用户行为数据的二分图表示

​	基于图的模型（graph-based model）是推荐系统中的重要内容。其实，很多研究人员把基于邻域的模型也称为基于图的模型，因为**可以把基于邻域的模型看做基于图的模型的简单形式**。

​	在研究基于图的模型之前，首先需要将用户行为数据表示成图的形式。本章讨论的用户行为数据是由一系列二元组组成的，其中每个二元组(u, i)表示用户u对物品i产生过行为。这种数据集很容易用一个二分图表示。

​	令G(V,E)表示用户物品二分图，其中V = V<sub>U</sub> U V<sub>I</sub> 由用户顶点集合 V<sub>U</sub> 和物品顶点集合V<sub>I</sub>组成。对于数据集中每一个二元组(u, i)，图中都有一套对应的边e(v<sub>u</sub>,v<sub>i</sub>) ，其中v<sub>u</sub> ∈ V<sub>U</sub> 是用户u对应的顶点，v<sub>i</sub> ∈ V<sub>I</sub> 是物品i对应的顶点。下图是一个简单的用户物品二分图模型，其中圆形节点代表用户，方形节点代表物品，圆形节点和方形节点之间的边代表用户对物品的行为。比如图中用户节点A和物品节点a、b、d相连，说明用户A对物品a、b、d产生过行为。

![img](http://www.ituring.com.cn/figures/2012/tuijinxitongshijian/06.D%2002%20Z/image71.png)

### 2.6.2 基于图的推荐算法

​	将用户行为表示为二分图模型后，下面的任务就是在二分图上给用户进行个性化推荐。如果将个性化推荐算法放到二分图模型上，那么给用户u推荐物品的任务就可以转化为度量用户顶点v<sub>u</sub>和与v<sub>u</sub>没有边直接相连的物品节点在图上的相关性，相关性越高的物品在推荐列表中的权重就越高。

​	度量图中两个顶点之间相关性的方法很多，但一般来说图中顶点的相关性主要取决于下面3个因素：

+ 两个顶点之间的路径数；

+ 两个顶点之间路径的长度；

+ 两个顶点之间的路径经过的顶点。

​	而相关性高的一对顶点一般具有如下特征：

+ 两个顶点之间有很多路径相连；

+ 连接两个顶点之间的路径长度都比较短；

+ **连接两个顶点之间的路径不会经过出度比较大的顶点**。

​	举一个简单的例子，如下图所示，用户A和物品c、e没有边相连，但是用户A和物品c有两条长度为3的路径相连，用户A和物品e有两条长度为3的路径相连。那么，顶点A与e之间的相关性要高于顶点A与c，因而物品e在用户A的推荐列表中应该排在物品c之前，因为顶点A与e之间有两条路径——（A, b, C, e）和（A, d, D, e）。其中，（A, b, C, e）路径经过的顶点的出度为（3, 2, 2,2），而（A, d, D, e）路径经过的顶点的出度为（3, 2, 3, 2）。因此，（A, d, D, e）经过了一个出度比较大的顶点D，所以（A, d, D, e）对顶点A与e之间相关性的贡献要小于（A, b, C, e）。

![enter image description here](https://www.ituring.com.cn/download/01v0rRZrzCex)

​	基于上面3个主要因素，研究人员设计了很多计算图中顶点之间相关性的方法。本节将介绍一种基于随机游走的PersonalRank算法。

​	假设要给用户u进行个性化推荐，可以从用户u对应的节点v<sub>u</sub>开始在用户物品二分图上进行随机游走。游走到任何一个节点时，首先按照概率α决定是继续游走，还是停止这次游走并从v<sub>u</sub>节点开始重新游走。如果决定继续游走，那么就从当前节点指向的节点中按照均匀分布随机选择一个节点作为游走下次经过的节点。这样，经过很多次随机游走后，每个物品节点被访问到的概率会收敛到一个数。最终的推荐列表中物品的权重就是物品节点的访问概率。

​	虽然PersonalRank算法可以通过随机游走进行比较好的理论解释，但该算法在时间复杂度上有明显的缺点。因为**在为每个用户进行推荐时，都需要在整个用户物品二分图上进行迭代，直到整个图上的每个顶点的PR值收敛**。**这一过程的时间复杂度非常高，不仅无法在线提供实时推荐，甚至离线生成推荐结果也很耗时**。

​	为了解决PersonalRank每次都需要在全图迭代并因此造成时间复杂度很高的问题，这里给出两种解决方案。

+ 第一种很容易想到，就是减少迭代次数，在收敛之前就停止。这样会影响最终的精度，但一般来说影响不会特别大。
+ 另一种方法就是从矩阵论出发，重新设计算法。

# 3.  第3章 推荐系统冷启动问题

​	推荐系统需要根据用户的历史行为和兴趣预测用户未来的行为和兴趣，因此大量的用户行为数据就成为推荐系统的重要组成部分和先决条件。对于很多像百度、当当这样的网站来说，这或许不是个问题，因为它们目前已经积累了大量的用户数据。但是对于很多做纯粹推荐系统的网站（比如Jinni和Pandora），或者很多在开始阶段就希望有个性化推荐应用的网站来说，**如何在没有大量用户数据的情况下设计个性化推荐系统并且让用户对推荐结果满意从而愿意使用推荐系统，就是冷启动的问题**。

​	下面各节将简单介绍一下冷启动问题的分类，以及如何解决不同种类的冷启动问题。

## 3.1 冷启动问题简介

​	冷启动问题（cold start）主要分3类。

+ **用户冷启动**：用户冷启动主要解决如何给新用户做个性化推荐的问题。当新用户到来时，我们没有他的行为数据，所以也无法根据他的历史行为预测其兴趣，从而无法借此给他做个性化推荐。

+ **物品冷启动**：物品冷启动主要解决如何将新的物品推荐给可能对它感兴趣的用户这一问题。

+ **系统冷启动**：系统冷启动主要解决如何在一个新开发的网站上（还没有用户，也没有用户行为，只有一些物品的信息）设计个性化推荐系统，从而在网站刚发布时就让用户体验到个性化推荐服务这一问题。

​	对于这3种不同的冷启动问题，有不同的解决方案。一般来说，可以参考如下解决方案。

+ **提供非个性化的推荐**：非个性化推荐的最简单例子就是热门排行榜，我们可以给用户推荐热门排行榜，然后等到用户数据收集到一定的时候，再切换为个性化推荐。

+ 利用用户注册时提供的年龄、性别等数据做粗粒度的个性化。

+ 利用用户的社交网络账号登录（需要用户授权），导入用户在社交网站上的好友信息，然后给用户推荐其好友喜欢的物品。

+ 要求用户在登录时对一些物品进行反馈，收集用户对这些物品的兴趣信息，然后给用户推荐那些和这些物品相似的物品。

+ 对于新加入的物品，可以利用内容信息，将它们推荐给喜欢过和它们相似的物品的用户。

+ 在系统冷启动时，可以引入专家的知识，通过一定的高效方式迅速建立起物品的相关度表。

​	下面几节将详细描述其中的某些方案。

## 3.2 利用用户注册信息

​	用户的注册信息分3种。

+ 人口统计学信息 包括用户的年龄、性别、职业、民族、学历和居住地。

+ 用户兴趣的描述 有一些网站会让用户用文字描述他们的兴趣。

+ 从其他网站导入的用户站外行为数据 比如用户通过豆瓣、新浪微博的账号登录，就可以在得到用户同意的情况下获取用户在豆瓣或者新浪微博的一些行为数据和社交网络数据。

​	这一节主要讨论如何通过用户注册时填写的人口统计学信息给用户提供粗粒度的个性化推荐。

​	人口统计学特征包括年龄、性别、工作、学历、居住地、国籍、民族等，这些特征对预测用户的兴趣有很重要的作用，比如男性和女性的兴趣不同， 不同年龄的人兴趣也不同。

基于注册信息的个性化推荐流程基本如下：

1. 获取用户的注册信息；

2. 根据用户的注册信息对用户分类；

3. 给用户推荐他所属分类中用户喜欢的物品。

​	**基于用户注册信息的推荐算法其核心问题是计算每种特征的用户喜欢的物品**。

> 基于人口统计学特征的推荐系统其典型代表是Bruce Krulwich开发的Lifestyle Finder。首先，Bruce Krulwich将美国人群根据人口统计学属性分成62类，然后对于每个新用户根据其填写的个人资料判断他属于什么分类，最后给他推荐这类用户最喜欢的15个链接，其中5个链接是推荐他购买的商品，5个链接是推荐他旅游的地点，剩下的5个链接是推荐他去逛的商店。

## 3.3 选择合适的物品启动用户的兴趣

关键字提取：

+ 冷启动
+ 决策树

---

> [3.3　选择合适的物品启动用户的兴趣](https://www.ituring.com.cn/book/miniarticle/13917)

​	解决用户冷启动问题的另一个方法是在新用户第一次访问推荐系统时，不立即给用户展示推荐结果，而是**给用户提供一些物品，让用户反馈他们对这些物品的兴趣，然后根据用户反馈给提供个性化推荐**。很多推荐系统采取了这种方式来解决用户冷启动问题。

​	对于这些通过让用户对物品进行评分来收集用户兴趣，从而对用户进行冷启动的系统，它们需要解决的首要问题就是**如何选择物品让用户进行反馈**。

​	一般来说，能够用来启动用户兴趣的物品需要具有以下特点。

+ 比较热门：如果要让用户对一个物品进行反馈，前提是用户知道这个物品是什么东西。以电影为例，如果一开始让用户进行反馈的电影都很冷门，而用户不知道这些电影的情节和内容，也就无法对它们做出准确的反馈。

+ 具有代表性和区分性：启动用户兴趣的物品不能是大众化或老少咸宜的，因为这样的物品对用户的兴趣没有区分性。还以电影为例，用一部票房很高且广受欢迎的电影做启动物品，可以想象的到的是几乎所有用户都会喜欢这部电影，因而无法区分用户个性化的兴趣。

+ 启动物品集合需要有多样性：在冷启动时，我们不知道用户的兴趣，而用户兴趣的可能性非常多，为了匹配多样的兴趣，我们需要提供具有很高覆盖率的启动物品集合，这些物品能覆盖几乎所有主流的用户兴趣。

​	Jinni在让用户反馈时没有直接拿电影让用户反馈，而是给出了12个电影类型，让用户先选择喜欢哪种类型，这样就很好地保证了启动物品集合的多样性。

​	上面这些因素都是选择启动物品时需要考虑的，但如何设计一个选择启动物品集合的系统呢？Nadav Golbandi在论文中探讨了这个问题，提出可以用一个**决策树**解决这个问题。

​	首先，给定一群用户，Nadav Golbandi用这群用户对物品评分的方差度量这群用户兴趣的一致程度。**如果方差很大，说明这一群用户的兴趣不太一致，反之则说明这群用户的兴趣比较一致**。

​	对于物品i，Nadav Golbandi将用户分成3类——**喜欢物品i的用户、不喜欢物品i的用户和不知道物品i的用户**（即没有给i评分的用户）。**如果这3类用户集合内的用户对其他的物品兴趣很不一致，说明物品i具有较高的区分度**。

​	Nadav Golbandi的算法首先会从所有用户中找到具有最高区分度的物品i，然后将用户分成3类。然后在每类用户中再找到最具区分度的物品，然后将每一类用户又各自分为3类，也就是将总用户分成9类，然后这样继续下去，最终可以通过对一系列物品的看法将用户进行分类。而在冷启动时，我们从根节点开始询问用户对该节点物品的看法，然后根据用户的选择将用户放到不同的分枝，直到进入最后的叶子节点，此时我们就已经对用户的兴趣有了比较清楚的了解，从而可以开始对用户进行比较准确地个性化推荐。

​	下图通过一个简单的例子解释Nadav Golbandi的算法。如图所示，假设通过分析用户数据，我们发现《变形金刚》最有区分度。而在喜欢《变形金刚》的用户中《钢铁侠》最有区分度，不知道《变形金刚》的用户中《阿甘正传》最有区分度，不喜欢《变形金刚》的用户中《泰坦尼克号》最有区分度。进一步分析，我们发现不喜欢《变形金刚》但喜欢《泰坦尼克号》的用户中，《人鬼情未了》最有区分度。那么，假设来了一个新用户，系统会首先询问他对《变形金刚》的看法，如果他说不喜欢，我们就会问他对《泰坦尼克》号的看法，如果他说喜欢，我们就会问他对《人鬼情未了》的看法，如果这个时候用户停止了反馈，我们也大概能知道该用户可能对爱情片比较感兴趣，对科幻片兴趣不大。

![img](http://www.ituring.com.cn/figures/2012/tuijinxitongshijian/07.D%2003%20Z/image30.png)

> 以Jinni为例，当新用户访问推荐系统时，它会给出一条提示语，表示用户需要给多部电影评分才能获取推荐结果。当用户选择给多部电影评分后，Jinni会首先展示一个页面让用户选择他喜欢的电影类别，当用户选择了某一个类别后，Jinni会展示第三个界面让用户对电影进行反馈。

## 3.4 利用物品的内容信息

关键字提取：

+ 冷启动
+ UserCF和ItemCF
+ 向量空间模型
+ 内容过滤算法
+ 话题模型（代表性的有LDA）
+ 词袋模型(bag of words)

---

> [3.4　利用物品的内容信息](https://www.ituring.com.cn/book/miniarticle/13918)

​	**物品冷启动需要解决的问题是如何将新加入的物品推荐给对它感兴趣的用户**。物品冷启动在新闻网站等时效性很强的网站中非常重要，因为那些网站中时时刻刻都有新加入的物品，而且每个物品必须能够在第一时间展现给用户，否则经过一段时间后，物品的价值就大大降低了。

​	第2章介绍了两种主要的推荐算法——UserCF和ItemCF算法。首先需要指出的是，**UserCF算法对物品冷启动问题并不非常敏感**。因为，UserCF在给用户进行推荐时，会首先找到和用户兴趣相似的一群用户，然后给用户推荐这一群用户喜欢的物品。在很多网站中，推荐列表并不是给用户展示内容的唯一列表，那么当一个新物品加入时，总会有用户从某些途径看到这些物品，对这些物品产生反馈。那么，当一个用户对某个物品产生反馈后，和他历史兴趣相似的其他用户的推荐列表中就有可能出现这一物品，从而更多的人就会对这个物品产生反馈，导致更多的人的推荐列表中会出现这一物品，因此该物品就能不断地扩散开来，从而逐步展示到对它感兴趣用户的推荐列表中。

​	但是，**有些网站中推荐列表可能是用户获取信息的主要途径，比如豆瓣网络电台。那么对于UserCF算法就需要解决第一推动力的问题，即第一个用户从哪儿发现新的物品**。只要有一小部分人能够发现并喜欢新的物品，UserCF算法就能将这些物品扩散到更多的用户中。解决第一推动力最简单的方法是将新的物品随机展示给用户，但这样显然不太个性化，因此**可以考虑利用物品的内容信息，将新物品先投放给曾经喜欢过和它内容相似的其他物品的用户**。关于如何利用内容信息，本节将在后面介绍。

​	**对于ItemCF算法来说，物品冷启动就是一个严重的问题**了。因为ItemCF算法的原理是给用户推荐和他之前喜欢的物品相似的物品。ItemCF算法会每隔一段时间利用用户行为计算物品相似度表（一般一天计算一次），在线服务时ItemCF算法会将之前计算好的物品相关度矩阵放在内存中。因此，当新物品加入时，内存中的物品相关表中不会存在这个物品，从而ItemCF算法无法推荐新的物品。解决这一问题的办法是频繁更新物品相似度表，但**基于用户行为计算物品相似度是非常耗时的事情**，主要原因是用户行为日志非常庞大。而且，**新物品如果不展示给用户，用户就无法对它产生行为，通过行为日志计算是计算不出包含新物品的相关矩阵的**。为此，我们只能利用物品的内容信息计算物品相关表，并且频繁地更新相关表（比如半小时计算一次）。

​	物品的内容信息多种多样，不同类型的物品有不同的内容信息。如果是电影，那么内容信息一般包括标题、导演、演员、编剧、剧情、风格、国家、年代等。如果是图书，内容信息一般包含标题、作者、出版社、正文、分类等。下表展示了常见物品的常用内容信息。

​	常见物品的内容信息

| 类型 | 内容信息                                         |
| ---- | ------------------------------------------------ |
| 图书 | 标题、作者、出版社、出版年代、丛书名、目录、正文 |
| 论文 | 标题、作者、作者单位、关键字、分类、摘要、正文   |
| 电影 | 标题、导演、演员、编剧、类别、剧情简介、发行公司 |
| 新闻 | 标题、正文、来源、作者                           |
| 微博 | 作者、内容、评论                                 |

​	一般来说，物品的内容可以通过向量空间模型表示，该模型会将物品表示成一个关键词向量。如果物品的内容是一些诸如导演、演员等实体的话，可以直接将这些实体作为关键词。但如果内容是文本的形式，则需要引入一些理解自然语言的技术抽取关键词。下图展示了从文本生成关键词向量的主要步骤。对于中文，首先要对文本进行分词，将字流变成词流，然后从词流中检测出命名实体（如人名、地名、组织名等），这些实体和一些其他重要的词将组成关键词集合，最后对关键词进行排名，计算每个关键词的权重，从而生成**关键词向量**。

![img](http://www.ituring.com.cn/figures/2012/tuijinxitongshijian/07.D%2003%20Z/image31.png)

​	**向量空间模型的优点是简单，缺点是丢失了一些信息**，比如关键词之间的关系信息。

​	**不过在绝大多数应用中，向量空间模型对于文本的分类、聚类、相似度计算已经可以给出令人满意的结果**。

​	得到物品的相似度之后，可以利用上一章提到的ItemCF算法的思想，给用户推荐和他历史上喜欢的物品内容相似的物品。

​	也许有读者认为，既然内容相似度计算简单，能频繁更新，而且能够解决物品冷启动问题，那么为什么还需要协同过滤的算法。为了说明内容过滤算法和协同过滤算法的优劣，本节在MovieLens和GitHub两个数据集上进行了实验。MovieLens数据集上一章已经详细介绍了，它也提供了有限的内容信息，主要包括电影的类别信息（动作片、爱情片等类别），GitHub数据集包含代码开发者对开源项目的兴趣数据，它的用户是程序员，物品是开源工程，如果一名程序员关注某个开源工程，就会有一条行为记录。该数据集中主要的内容数据是开源项目的所有者名。

​	表3-5比较了内容过滤算法ContentItemKNN和协调过滤算法ItemCF在MovieLens和GitHub数据集上的离线实验性能。为了对比，我们同时加入了Random和MostPopular两个非个性化的推荐算法作为基准。

​	表3-5　MovieLens/GitHub数据集中几种推荐算法性能的对比

| 方　法         | 准　确　率 | 召　回　率 | 覆　盖　率 | 流　行　度 |
| :------------- | :--------- | :--------- | :--------- | :--------- |
| **MovieLens**  |            |            |            |            |
| Random         | 0.631%     | 0.305%     | 100%       | 4.3855     |
| MostPopular    | 12.79%     | 6.18%      | 2.60%      | 7.7244     |
| ItemCF         | 22.28%     | 10.76%     | 18.84%     | 7.254526   |
| ContentItemKNN | 6.78%      | 3.28%      | 19.06%     | 5.8481     |
| **GitHub**     |            |            |            |            |
| Random         | 0.000985%  | 0.00305%   | 84.18%     | 0.9878     |
| MostPopular    | 1.18%      | 4.36%      | 0.0299%    | 7.1277     |
| ItemCF         | 2.56%      | 9.44%      | 33.71%     | 2.9119     |
| ContentItemKNN | 6.98%      | 25.75%     | 34.44%     | 1.7086     |

​	从MovieLens数据集上的结果可以发现，ContentItemKNN的准确率和召回率仅仅优于Random算法，明显差于ItemCF算法，甚至比MostPopular算法还要差。不过在覆盖率和流行度指标上ContentItemKNN却优于ItemCF。这主要是因为**内容过滤算法忽视了用户行为，从而也忽视了物品的流行度以及用户行为中所包含的规律，所以它的精度比较低，但结果的新颖度却比较高**。

​	不过，事情不是绝对的。如果看GitHub数据集的结果，我们会发现完全相反的现象——Content-ItemKNN在所有指标上都优于ItemCF。这主要是因为GitHub提供了一个非常强的内容特征，就是开源项目的作者。<u>在GitHub中，程序员会经常会关注同一个作者的不同项目，这一点是GitHub数据集最重要的特征。而协同过滤算法由于数据稀疏的影响，不能从用户行为中完全统计出这一特征，所以协同过滤算法反而不如利用了先验信息的内容过滤算法</u>。这一点也说明，**如果用户的行为强烈受某一内容属性的影响，那么内容过滤的算法还是可以在精度上超过协同过滤算法的**。不过这种强的内容特征不是所有物品都具有的，而且需要丰富的领域知识才能获得，所以很多时候内容过滤算法的精度比协同过滤算法差。不过，这也提醒我们，如果能够将这两种算法融合，一定能够获得比单独使用这两种算法更好的效果。

​	**向量空间模型在内容数据丰富时可以获得比较好的效果**。以文本为例，如果是计算长文本的相似度，用向量空间模型利用关键词计算相似度已经可以获得很高的精确度。但是，如果文本很短，关键词很少，向量空间模型就很难计算出准确的相似度。

​	举个例子，假设有两篇论文，它们的标题分别是“推荐系统的动态特性”和“基于时间的协同过滤算法研究”。如果读者对推荐系统很熟悉，可以知道这两篇文章的研究方向是类似的，但是它们标题中没有一样的关键词。其实，它们的关键词虽然不同，但却是相似的。“动态”和“基于时间”含义相似，“协同过滤”是“推荐系统”的一种算法。换句话说，这两篇文章的**关键词虽然不同，但关键词所属的话题是相同的**。在**这种情况下，首先需要知道文章的话题分布，然后才能准确地计算文章的相似度**。**如何建立文章、话题和关键词的关系是话题模型（topic model）研究的重点**。

+ **代表性的话题模型有LDA**。

  ​	以往关于该模型的理论文章已经很多了，本书不准备讨论太多的数学问题，所以这里准备用形象的语言介绍一下LDA，并用工程师很容易懂的方法介绍这个算法。关于LDA的详细理论介绍可以参考DM Blei的论文“Latent Dirichlet Allocation”。	

  ​	任何模型都有一个假设，LDA作为一种生成模型，对一篇文档产生的过程进行了建模。**话题模型的基本思想是，一个人在写一篇文档的时候，会首先想这篇文章要讨论哪些话题，然后思考这些话题应该用什么词描述，从而最终用词写成一篇文章。因此，文章和词之间是通过话题联系的。**

+ **LDA中有3种元素，即文档、话题和词语**。

  ​	**每一篇文档都会表现为词的集合，这称为词袋模型(bag of words)。每个词在一篇文章中属于一个话题。令D为文档集合，D\[i]是第i篇文档。w\[i]\[j]是第i篇文档中的第j个词。z\[i]\[j]是第i篇文档中第j个词属于的话题**。

+ **LDA的计算过程包括初始化和迭代两部分**。

  ​	首先要对z进行初始化，而初始化的方法很简单，假设一共有K个话题，那么对第i篇文章中的第j个词，可以**随机给它赋予一个话题**。同时，用NWZ(w,z)记录词w被赋予话题z的次数，NZD(z,d)记录文档d中被赋予话题z的词的个数。

  ```pseudocode
  foreach document i in range(0,|D|):
    foreach word j in range(0, |D(i)|):
      z[i][j] = rand() % K
      NZD[z[i][j], D[i]]++
      NWZ[w[i][j], z[i][j]]++
      NZ[z[i][j]]++
  ```

  ​	在初始化之后，要通过迭代使话题的分布收敛到一个合理的分布上去。伪代码如下所示：

  ```pseudocode
  while not converged:
  	foreach document i in range(0, |D|):
  		foreach word j in range(0, |D(i)|):
  			NWZ[w[i][j], z[i][j]]--
  			NZ[z[i][j]]--
  			NZD[z[i][j], D[i]]--
  			z[i][j] = SampleTopic()
  			NWZ[w[i][j], z[i][j]]++
  			NZ[z[i][j]]++
  			NZD[z[i][j], D[i]]++
  ```

​	LDA可以很好地将词组合成不同的话题。这里我们引用David M. Blei在论文中给出的一个实验结果。他利用了一个科学论文摘要的数据集，该数据集包含16 333篇新闻，共23 075个不同的单词。通过LDA，他计算出100个话题并且在论文中给出了其中4个话题排名最高（也就是p(w|z)最大）的15个词。从图3-12所示的聚类结果可以看到，LDA可以较好地对词进行聚类，找到每个词的相关词。

![img](http://www.ituring.com.cn/figures/2012/tuijinxitongshijian/07.D%2003%20Z/image38.png)

​	**在使用LDA计算物品的内容相似度时，我们可以先计算出物品在话题上的分布，然后利用两个物品的话题分布计算物品的相似度**。比如，如果两个物品的话题分布相似，则认为两个物品具有较高的相似度，反之则认为两个物品的相似度较低。计算分布的相似度可以利用KL散度：

![img](http://www.ituring.com.cn/figures/2012/tuijinxitongshijian/07.D%2003%20Z/image39.png)

​	其中p和q是两个分布，KL散度越大说明分布的相似度越低。

## 3.5 发挥专家的作用

​	**很多推荐系统在建立时，既没有用户的行为数据，也没有充足的物品内容信息来计算准确的物品相似度。那么，为了在推荐系统建立时就让用户得到比较好的体验，很多系统都利用专家进行标注**。这方面的代表系统是个性化网络电台Pandora和电影推荐网站Jinni。

Pandora是一个给用户播放音乐的个性化电台应用。众所周知，计算音乐之间的相似度是比较困难的。首先，音乐是多媒体，如果从音频分析入手计算歌曲之间的相似度，则技术门槛很高，而且也很难计算得令人满意。其次，仅仅利用歌曲的专辑、歌手等属性信息很难获得令人满意的歌曲相似度表，因为一名歌手、一部专辑往往只有一两首好歌。为了解决这个问题，Pandora雇用了一批懂计算机的音乐人进行了一项称为音乐基因的项目。他们听了几万名歌手的歌，并对这些歌的各个维度进行标注。最终，他们使用了400多个特征（Pandora称这些特征为基因）。标注完所有的歌曲后，**每首歌都可以表示为一个400维的向量，然后通过常见的向量相似度算法可以计算出歌曲的相似度。**

​	和Pandora类似，Jinni也利用相似的想法设计了电影基因系统，让专家给电影进行标注。Jinni网站对电影基因项目进行了介绍。

​	这里的基因包括如下分类。

+ 心情（Mood） 表示用户观看电影的心情，比如对于《功夫熊猫》观众会觉得很幽默，很兴奋。

+ 剧情（Plot） 包括电影剧情的标签。

+ 类别（Genres） 表示电影的类别，主要包括动画片、喜剧片、动作片等分类。

+ 时间（Time/Period） 电影故事发生的时间。

+ 地点（Place） 电影故事发生的地点。

+ 观众（Audience） 电影的主要观众群。

+ 获奖（Praise） 电影的获奖和评价情况。

+ 风格（Style） 功夫片、全明星阵容等。

+ 态度（Attitudes） 电影描述故事的态度。

+ 画面（Look） 电脑拍摄的画面技术，比如《功夫熊猫》是用电脑动画制作的。

+ 标记（Flag） 主要表示电影有没有暴力和色情内容。

​	Jinni在电影基因工程中采用了半人工、半自动的方式。首先，它让专家对电影进行标记，每个电影都有大约50个基因，这些基因来自大约1000个基因库。然后，在专家标记一定的样本后，Jinni会使用自然语言理解和机器学习技术，通过分析用户对电影的评论和电影的一些内容属性对电影（特别是新电影）进行自己的标记。同时，Jinni也设计了让用户对基因进行反馈的界面，希望通过用户反馈不断改进电影基因系统。

​	总之，**Jinni通过专家和机器学习相结合的方法解决了系统冷启动问题**。

# 4. 第4章 利用用户标签数据

> [推荐系统——利用用户标签数据](https://blog.csdn.net/qq_38931949/article/details/84959436)

​	**推荐系统的目的是联系用户的兴趣和物品，这种联系需要依赖不同的媒介**。GroupLens在一篇文章中表示目前流行的推荐系统基本上通过3种方式联系用户兴趣和物品。

+ 第一种方式是利用用户喜欢过的物品，给用户推荐与他喜欢过的物品相似的物品，这就是前面提到的基于物品的算法。（ItemCF）
+ 第二种方式是利用和用户兴趣相似的其他用户，给用户推荐那些和他们兴趣爱好相似的其他用户喜欢的物品，这是前面提到的基于用户的算法。（UserCF）
+ 第三种重要的方式是通过一些**特征（feature）**联系用户和物品，给用户推荐那些具有用户喜欢的特征的物品。这里的特征有不同的表现方式，比如可以表现为物品的属性集合（比如对于图书，属性集合包括作者、出版社、主题和关键词等），也可以表现为**隐语义向量**（latent factor vector），这可以通过前面提出的隐语义模型习得到。

![img](https://img-blog.csdnimg.cn/20181211181022508.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4OTMxOTQ5,size_16,color_FFFFFF,t_70)

​	本章将讨论一种重要的特征表现方式——标签。

​	根据维基百科的定义，标签是一种无层次化结构的、用来描述信息的关键词，它可以用来描述物品的语义。根据给物品打标签的人的不同，标签应用一般分为两种：

+ 一种是让**作者或者专家给物品打标签**；
+ 另一种是让**普通用户给物品打标签**，也就是**UGC（User Generated Content，用户生成的内容）**的标签应用。

​	**UGC的标签系统是一种表示用户兴趣和物品语义的重要方式**。当一个用户对一个物品打上一个标签，这个标签一方面描述了用户的兴趣，另一方面则表示了物品的语义，从而将用户和物品联系了起来。

​	本章主要讨论UGC的标签应用，研究用户给物品打标签的行为，探讨如何通过分析这种行为给用户进行个性化推荐。

## 4.1 UGC 标签系统的代表应用

> [《推荐系统实践》样章：如何利用用户标签数据（一）](https://www.ituring.com.cn/article/details/725)	<=	下面4.1.X的图片基本都是来自该文章。

​	UGC标签系统是很多Web 2.0网站的必要组成部分，本节将讨论使用UGC标签系统的代表网站——UGC标签系统的鼻祖Delicious、论文书签网站CiteULike、音乐网站Last.fm、视频网站Hulu、书和电影评论网站豆瓣等。下面将分别介绍这些应用。

### 4.1.1 Delicious

​	Delicous可算是标签系统里的开山鼻祖，它允许用户给互联网上的每个网页打标签，从而通过标签重新组织整个互联网。

​	图4-2是Delicious中被用户打上recommender、system标签最多的网页，这些网页反应了用户心目中和推荐系统最相关的网页。

​	图4-3是Delicious中“豆瓣电台”这个网页被用户打的最多的标签，可以看到这些标签确实从各个角度准确地描述了“豆瓣电台”这个物品。

​	图4-2 Delicious中被打上recommender和system标签的网页

![enter image description here](https://www.ituring.com.cn/download/01K9ZcrFRRIw)

​	图4-3 Delicious中“豆瓣电台”网页被用户打的最多的标签

![enter image description here](https://www.ituring.com.cn/download/01K9ZbX64ssg)

### 4.1.2 CiteULike

​	CiteULike是一个著名的论文书签网站，它允许研究人员提交或者收藏自己感兴趣的论文并且给论文打标签，从而帮助用户更好地发现和自己研究领域相关的优秀论文。我们知道，研究人员搜索自己研究领域内值得参考的论文是很费时费力的工作，而CiteULike通过群体智能，让每个研究人员对自己了解的论文进行标记，借此帮助其他研究人员更好更快地发现自己感兴趣的论文。图4-4展示了CiteULike中一篇有关推荐系统评测的文章以及用户给这篇文章打过最多的标签，可以发现，最多的两个标签是collaborative-filtering（协同过滤）和evaluate（评测），确实比较准确地反应了这篇论文的主要内容。

​	图4-4 CiteULike中一篇论文的标签

![enter image description here](https://www.ituring.com.cn/download/01K9ZbXEOBcP)

### 4.1.3 Last.fm

​	Last.fm是一家著名的音乐网站，它通过分析用户的听歌行为预测用户对音乐的兴趣，从而给用户推荐个性化的音乐。作为多媒体，音乐不像文本那样可以很容易地分析内容信息。为了在不进行复杂音频分析的情况下获得音乐的内容信息，Last.fm引入了UGC标签系统，让用户用标签标记音乐和歌手。图4-5展示了披头士乐队在Last.fm中的标签云（tag cloud）。从这个标签云可以看到，披头士应该是一个英国（british）的传统摇滚乐队（classic rock），流行于20世纪60年代（60s）。

​	图4-5 Last.fm中披头士乐队的标签云

![enter image description here](https://www.ituring.com.cn/download/01K9ZbXLbxWe)

### 4.1.4 豆瓣

​	豆瓣是中国著名的评论和社交网站，同时也是中国个性化推荐领域的领军企业之一。豆瓣在个性化推荐领域进行了广泛尝试，标签系统也是其尝试的领域之一。它允许用户对图书和电影打标签，借此获得图书和电影的内容信息和语义，并用这种信息改善推荐效果。图4-6展示了《数据挖掘导论》在豆瓣被用户打标签的情况。如图所示，最多的几个标签分别是数据挖掘、计算机、计算机科学、数据分析、IT数据分析等。这些标签准确地概括了这本书的内容信息。

​	图4-6 豆瓣读书中《数据挖掘导论》一书的常用标签

![enter image description here](https://www.ituring.com.cn/download/01K9ZbXWVFb7)

### 4.1.5 Hulu

​	Hulu是美国著名的视频网站。视频作为一种最为复杂的多媒体，获取它的内容信息是最困难的，因此Hulu也引入了用户标签系统来让用户对电视剧和电影进行标记。图4-7展示了美剧《豪斯医生》的常用标签，可以看到，Hulu对标签做了分类并展示了每一类最热门的标签。从类型（Genre）看，《豪斯医生》是一部医学片（medical）；从时间看，这部剧开始于2004年；从人物看，这部美剧的主演是hugh laurie，他在剧中饰演的人物是greg house。

​	图4-7 Hulu中《豪斯医生》的常用标签

![enter image description here](https://www.ituring.com.cn/download/01K9ZbY7EpuU)

​	从前面的各种应用可以看到，标签系统在各种各样的（音乐、视频和社交等）网站中都得到了广泛应用。**标签系统的最大优势在于可以发挥群体的智能，获得对物品内容信息比较准确的关键词描述，而准确的内容信息是提升个性化推荐系统性能的重要资源**。

​	关于标签系统的作用， GroupLen的Shilads Wieland Sen在MoveLens电影推荐系统上做了更为深入的、基于问卷调查的研究。在博士论文中，他探讨了标签系统的不同作用，以及每种作用能够影响多大的人群，如下所示。

+ 表达：标签系统帮助我表达对物品的看法。（30%的用户同意。）

+ 组织：打标签帮助我组织我喜欢的电影。（23%的用户同意。）

+ 学习：打标签帮助我增加对电影的了解。（27%的用户同意。）

+ 发现：标签系统使我更容易发现喜欢的电影。（19%的用户同意。）

+ 决策：标签系统帮助我判定是否看某一部电影。（14%的用户同意。）

​	上面的研究证明，标签系统确实能够帮助用户发现可能喜欢的电影，而这正是个性化推荐系统的使命之一。因此，本章将对如何发挥标签在个性化推荐中的作用进行深入探讨。

## 4.2 标签系统中的推荐问题

​	打标签作为一种重要的用户行为，蕴含了很多用户兴趣信息，因此深入研究和利用用户打标签的行为可以很好地指导我们改进个性化推荐系统的推荐质量。同时，**标签的表示形式非常简单，便于很多算法处理**。

​	标签系统中的推荐问题主要有以下两个。

+ 如何利用用户打标签的行为为其推荐物品（基于标签的推荐）？

+ 如何在用户给物品打标签时为其推荐适合该物品的标签（标签推荐）？

​	为了研究上面的两个问题，我们首先需要解答下面3个问题。

+ **用户为什么要打标签？**

+ **用户怎么打标签？**

+ **用户打什么样的标签？**

### 4.2.1 用户为什么进行标注

​	在设计基于标签的个性化推荐系统之前，我们需要深入了解用户的标注行为（即打标签的行为），知道用户为什么要标注，用户怎么标注，只有深入了解用户的行为，我们才能基于这个行为设计出令他们满意的个性化推荐系统。

​	Morgan Ames研究图片分享网站中用户标注的动机问题，并从两个维度进行探讨。

+ 首先是社会维度，有些用户标注是给内容上传者使用的（便于上传者组织自己的信息），而有些用户标注是给广大用户使用的（便于帮助其他用户找到信息）。
+ 另一个维度是功能维度，有些标注用于更好地组织内容，方便用户将来的查找，而另一些标注用于传达某种信息，比如照片的拍摄时间和地点等。

### 4.2.2 用户如何打标签

> [推荐系统（四）——利用用户标签数据](https://zhuanlan.zhihu.com/p/47556784)

​	在互联网中，尽管每个用户的行为看起来是随机的，但其实这些表面随机的行为背后蕴含着很多规律。这一节将通过研究Delicious数据集总结用户标注行为中的一些统计规律。

​	德国研究人员公布过一个很庞大的Delicious数据集，该数据集包含2003年9月到2007年12月Delicious用户4.2亿条标签行为记录。本节选用该数据集2007年一个月的数据进行分析，对该数据集的统计特性进行研究。

​	前面几章都提到，**用户行为数据集中用户活跃度和物品流行度的分布都遵循长尾分布（PowerLaw分布）**。因此，我们首先看一下标签流行度的分布。我们定义的一个标签被一个用户使用在一个物品上，它的流行度就加一。如下代码计算了每个标签的流行度。

```python
def TagPopularity(records):
  tagfreq = dict()
  for user,item,tag in records:
    if tag not in tagfreq:
      tagfreq[tag] = 1
    else:
      tagfreq[tag] += 1
  return tagfreq
```

​	如图4-8所示，横坐标是流行度k，纵坐标是数据集中流行度为k的标签总数n(k)。标签的流行度分布也呈现非常典型的长尾分布，它的双对数曲线几乎是一条直线。
$$
logn(k)=αlogk+β=logk^α.e^β
$$

$$
n(k)=e^β.k^α=γ.k^α
$$

​	图4-8 标签流行度的长尾分布

![img](https://pic3.zhimg.com/80/v2-35695fdc624009809fdad9b831ea87d6_1440w.jpg)

### 4.2.3 用户打什么样的标签

​	在用户看到一个物品时，我们希望他打的标签是能够准确描述物品内容属性的关键词，但用户往往不是按照我们的想法操作，而是可能会给物品打上各种各样奇奇怪怪的标签。

​	Scott A. Golder 总结了Delicious上的标签，将它们分为如下几类。

+ 表明物品是什么 比如是一只鸟，就会有“鸟”这个词的标签；是豆瓣的首页，就有一个标签叫“豆瓣”；是乔布斯的首页，就会有个标签叫“乔布斯”。

+ 表明物品的种类 比如在Delicious的书签中，表示一个网页类别的标签包括 article（文章）、blog（博客）、 book（图书）等。

+ 表明谁拥有物品 比如很多博客的标签中会包括博客的作者等信息。

+ 表达用户的观点 比如用户认为网页很有趣，就会打上标签funny（有趣），认为很无聊，就会打上标签boring（无聊）。

+ 用户相关的标签 比如 my favorite（我最喜欢的）、my comment（我的评论）等。

+ 用户的任务 比如 to read（即将阅读）、job search（找工作）等。

​	很多不同的网站也设计了自己的标签分类系统，比如Hulu对视频的标签就做了分类。图4-9是著名的美剧《豪斯医生》的标签。可以看到，Hulu将电视剧的标签分成了如下几类。

​	图4-9 著名美剧《豪斯医生》在视频网站Hulu上的标签分类

# 《推荐系统实践》-粗略读书笔记

> 为推荐系统的搭建做准备，时间比较紧迫，暂时不细读了。 下面关于公式、代码的部分，没有找到现成的图，手敲麻烦意义不大，需要时看书、上网查找即可。

# 1. 第1章 好的推荐

## 1.1 什么是推荐系统

- 推荐系统的基本任务是联系用户和物品，解决信息过载的问题

- 从物品的角度出发，推荐系统可以更好地发掘物品的长尾（long tail）。主流商品代表绝大多数用户的需求，而长尾商品代表**少数人的个性化需求**。推荐系统通过发掘用户的行为，找到用户的个性化需求，从而将长尾商品准确地推荐给需要它的用户，帮助用户发现那些他们感兴趣但很难发现的商品。

- 常见的几种推荐方式

  - 社会化推荐（social recommendation）

    用户间推荐

  - 基于内容的推荐 （content-based filtering）

    根据用户历史兴趣推荐类似内容

  - 基于协同过滤的推荐（collaborative filtering）

    给用户推荐兴趣相似的用户所感兴趣的内容

## 1.2 个性化推荐系统的应用

​	个性化推荐系统通过**分析大量用户行为日志**，给不同用户提供不同的个性化页面展示，来提高网站的点击率和转化率。

​	几乎所有的推荐系统应用都是由三部分构成：

- **前台的展示页面**
- **后台的日志系统**
- **推荐算法系统**

### 1.2.1 电子商务

1. 亚马逊个性化推荐系统列表

   **基于物品推荐**

   - 推荐结果的标题、缩略图以及其他内容属性
   - 推荐结果的平均分
   - 推荐理由

### 1.2.2 电影和视频网站

1. Netflix电影推荐界面

   **基于物品推荐**

   - 电影的标题和海报
   - 用户反馈模块——包括Play（播放）、评分和Not Interested（不感兴趣）3种
   - 推荐理由——因为用户曾经喜欢过别的电影

### 1.2.3 个性化音乐网络电台

个性化推荐的成功应用需要两个条件：

1. 信息过载。因为如果用户可以很容易地从所有物品中找到喜欢的物品，就不需要个性化推荐了。
2. 用户大部分时候没有特别明确的需求。用户如果有明确的需求，可直接通过搜索引擎找到感兴趣的物品。

著名个性化音乐推荐产品：Pandora、Last.fm、豆瓣电台

Last.fm记录了所有用户的听歌记录以及用户对歌曲的反馈，在这一基础上计算出不同用户在歌曲上的喜好相似度，从而给用户推荐和他有相似听歌爱好的其他用户喜欢的歌曲。

​	音乐推荐是推荐系统里非常特殊的领域。2011年的Recsys大会专门邀请了Pandora的研究人员对音乐推荐进行了演讲。演讲人总结了音乐推荐的如下特点。

- 物品空间大 物品数很多，物品空间很大，这主要是相对于书和电影而言。
- 消费每首歌的代价很小 对于在线音乐来说，音乐都是免费的，不需要付费。
- 物品种类丰富 音乐种类丰富，有很多的流派。
- 听一首歌耗时很少 听一首音乐的时间成本很低，不太浪费用户的时间，而且用户大都把音乐作为背景声音，同时进行其他工作。
- 物品重用率很高 每首歌用户会听很多遍，这和其他物品不同，比如用户不会反复看一个电影，不会反复买一本书。
- 用户充满激情 用户很有激情，一个用户会听很多首歌。
- 上下文相关 用户的口味很受当时上下文的影响，这里的上下文主要包括用户当时的心情（比如沮丧的时候喜欢听励志的歌曲）和所处情境（比如睡觉前喜欢听轻音乐）。
- 次序很重要 用户听音乐一般是按照一定的次序一首一首地听。
- 很多播放列表资源 很多用户都会创建很多个人播放列表。
- 不需要用户全神贯注 音乐不需要用户全神贯注地听，很多用户将音乐作为背景声音。
- 高度社会化

### 1.2.4 社交网络

代表：Twitter、FaceBook

社交网络中的个性化推荐技术主要应用在3个方面：

- 利用用户的社交网络信息对用户进行个性化的物品推荐；
- 信息流的会话推荐；
- 给用户推荐好友。

### 1.2.5 个性化阅读

​	目前互联网上的个性化阅读工具很多，国际知名的有Google Reader，国内有鲜果网等。

- Google Reader是一款流行的社会化阅读工具。它允许用户关注自己感兴趣的人，然后看到所关注用户分享的文章。
- 个性化阅读工具Zite则是收集用户对文章的偏好信息。
- Digg首先根据用户的Digg历史计算用户之间的兴趣相似度，然后给用户推荐和他兴趣相似的用户喜欢的文章。

### 1.2.6 基于位置的服务

- Foursquare推出了探索功能，给用户推荐好友在附近的情况

### 1.2.7 个性化邮件

- 推荐系统Tapestry，协同过滤筛选信息，通过分析用户阅读邮件的历史行为和习惯对新邮件进行重新排序，从而提高用户的工作效率。
- 谷歌的研究人员在这个问题上也进行了深入研究，于2010年推出了优先级收件箱功能。该产品通过分析用户对邮件的历史行为，找到用户感兴趣的邮件，展示在一个专门的收件箱里。用户每天可以先浏览这个邮箱里的邮件，再浏览其他邮件。

### 1.2.8 个性化广告

> [网络广告中，CPC、CPA、CPM 的定义各是怎样的？](https://www.zhihu.com/question/20416888)
>
> 1. CPM（Cost Per Mille） ：展现成本，或者叫千人展现成本
> 2. CPC（Cost Per Click） 点击成本，即每产生一次点击所花费的成本
> 3. CPA（Cost Per Action）：每行动成本。即按行动收费

​	广告是互联网公司生存的根本。很多互联网公司的盈利模式都是基于广告的，而广告的CPC、CPM直接决定了很多互联网公司的收入。

​	个性化广告投放和狭义个性化推荐的区别是，个性化推荐着重于帮助用户找到可能令他们感兴趣的物品，而**广告推荐着重于帮助广告找到可能对它们感兴趣的用户**，即一个是以用户为核心，而另一个以广告为核心。目前的个性化广告投放技术主要分为3种。

- 上下文广告 通过分析用户正在浏览的网页内容，投放和网页内容相关的广告。代表系统是谷歌的Adsense。
- 搜索广告 通过分析用户在当前会话中的搜索记录，判断用户的搜索目的，投放和用户目的相关的广告。
- 个性化展示广告 我们经常在很多网站看到大量展示广告（就是那些大的横幅图片），它们是根据用户的兴趣，对不同用户投放不同的展示广告。雅虎是这方面研究的代表。

## 1.3 推荐系统评测

> 看到这就想到最近美团爆出杀熟的操作。三方共赢这种美好的愿望还是想想就好，哈哈。

​	一个完整的推荐系统一般存在3个参与方：

- 用户
- 物品提供者
- 提供推荐系统的网站

​	在评测一个推荐算法时，需要同时考虑三方的利益，一个好的推荐系统是能够令三方共赢的系统。

### 1.3.1 推荐系统实验方法

在推荐系统中，主要有3种评测推荐效果的实验方法：

- 离线实验（offline experiment）
- 用户调查（user study）
- 在线实验（online experiment）

#### 1. 离线实验

离线实验的方法一般由如下几个步骤构成：

1. 通过日志系统获得用户行为数据，并按照一定格式生成一个标准的数据集；
2. 将数据集按照一定的规则分成训练集和测试集；
3. 在训练集上训练用户兴趣模型，在测试集上进行预测；
4. 通过事先定义的离线指标评测算法在测试集上的预测结果。

从上面的步骤可以看到，**推荐系统的离线实验都是在数据集上完成的**，也就是说它不需要一个实际的系统来供它实验，而只要有一个从实际系统日志中提取的数据集即可。这种实验方法的好处是不需要真实用户参与，可以直接快速地计算出来，从而方便、快速地测试大量不同的算法。

它的**主要缺点是无法获得很多商业上关注的指标，如点击率、转化率等**，而找到和商业指标非常相关的离线指标也是很困难的事情。

| 优点                     | 缺点                             |
| ------------------------ | -------------------------------- |
| 不需要对实际系统的控制权 | 无法计算商业上关心的指标         |
| 不需要用户参与实验       | 离线实验的指标和商业指标存在差异 |
| 速度快，可以测试大量算法 |                                  |

#### 2. 用户调查

​	注意，离线实验的指标和实际的商业指标存在差距，比如预测准确率和用户满意度之间就存在很大差别，**高预测准确率不等于高用户满意度**。

​	用户调查的优缺点也很明显。它的优点是可以获得很多体现用户主观感受的指标，相对在线实验风险很低，出现错误后很容易弥补。缺点是招募测试用户代价较大，很难组织大规模的测试用户，因此会使测试结果的统计意义不足。此外，在很多时候设计双盲实验非常困难，而且用户在测试环境下的行为和真实环境下的行为可能有所不同，因而在测试环境下收集的测试指标可能在真实环境下无法重现。

#### 3. 在线实验

> [黄一能：什么是科学的AB测试？谈谈分层实验和流量正交 ](https://www.sohu.com/a/343208894_713733)
>
> 科学的AB实验要求保证每次实验只有一个变量，各组其他所有元素都必须保持一致。如果每个变量都独立切分流量会大大制约实验的效率，一是实验流量变少，得出显著结果的时间会拉长。二是可以并行的实验量受到了制约。如果不切分流量实验，无法验证效果的变化究竟是那个改动带来的。
>
> [AB测试中两个常见的问题，谈谈流量分层和置信度](https://zhuanlan.zhihu.com/p/108317075)

​	在完成离线实验和必要的用户调查后，可以将推荐系统上线做**AB测试**，将它和旧的算法进行比较。

​	AB测试是一种很常用的在线评测算法的实验方法。它通过一定的规则将用户随机分成几组，并对不同组的用户采用不同的算法，然后通过统计不同组用户的各种不同的评测指标比较不同算法，比如可以统计不同组用户的点击率，通过点击率比较不同算法的性能。

​	网站http://www.abtests.com/，给出了很多通过实际AB测试提高网站用户满意度的例子，从中我们可以学习到如何进行合理的AB测试。

​	**AB测试的优点是可以公平获得不同算法实际在线时的性能指标**，包括商业上关注的指标。AB测试的**缺点主要是周期比较长**，必须进行长期的实验才能得到可靠的结果。因此一般不会用AB测试测试所有的算法，而只是用它测试那些在离线实验和用户调查中表现很好的算法。

​	切分流量是AB测试中的关键，不同的层以及控制这些层的团队需要从一个统一的地方获得自己AB测试的流量，而不同层之间的流量应该是正交的。

​	下图是一个简单的AB测试系统。用户进入网站后，流量分配系统决定用户是否需要被进行AB测试，如果需要的话，流量分配系统会给用户打上在测试中属于什么分组的标签。然后用户浏览网页，而用户在浏览网页时的行为都会被通过日志系统发回后台的日志数据库。此时，如果用户有测试分组的标签，那么该标签也会被发回后台数据库。在后台，实验人员的工作首先是配置流量分配系统，决定满足什么条件的用户参加什么样的测试。其次，实验人员需要统计日志数据库中的数据，通过评测系统生成不同分组用户的实验报告，并比较和评测实验结果。

![img](http://www.ituring.com.cn/figures/2012/tuijinxitongshijian/05.D%2001%20Z/image23.png)



一般来说，一个新的推荐算法最终上线，需要完成上面所说的3个实验。

- 首先，需要通过离线实验证明它在很多离线指标上优于现有的算法。
- 然后，需要通过用户调查确定它的用户满意度不低于现有的算法。
- 最后，通过在线的AB测试确定它在我们关心的指标上优于现有的算法。

### 1.3.2 评测指标

#### 1. 用户满意度

​	用户满意度没有办法离线计算，只能通过用户调查或者在线实验获得。

​	用户调查获得用户满意度主要是通过调查问卷的形式。而在线系统中，用户满意度主要通过一些对用户行为的统计得到。更一般的情况下，我们可以用点击率、用户停留时间和转化率等指标度量用户的满意度。

#### 2. 预测准确度

​	预测准确度度量一个推荐系统或者推荐算法预测用户行为的能力。该指标可以通过离线实验计算。

​	在计算该指标时需要有一个离线的数据集，该数据集包含用户的历史行为记录。然后，将该数据集通过时间分成训练集和测试集。最后，通过在训练集上建立用户的行为和兴趣模型预测用户在测试集上的行为，并计算预测行为和测试集上实际行为的重合度作为预测准确度。

##### 评分预测

​	预测用户对物品评分的行为称为评分预测。

##### TopN推荐

​	网站在提供推荐服务时，一般是给用户一个个性化的推荐列表，这种推荐叫做**TopN推荐**。TopN推荐的预测准确率一般通过准确率（precision）/召回率（recall）度量。

​	有的时候，为了全面评测TopN推荐的准确率和召回率，一般会选取不同的推荐列表长度N，计算出一组准确率/召回率，然后画出准确率/召回率曲线（precision/recall curve）。

##### 关于评分预测和TopN推荐的讨论

​	评分预测一直是推荐系统研究的热点，绝大多数推荐系统的研究都是基于用户评分数据的评分预测。

#### 3. 覆盖率

> [请问什么是基尼系数，怎样计算出来的？](https://zhidao.baidu.com/question/1797381608016293707.html)

​	覆盖率（coverage）描述一个推荐系统对物品长尾的发掘能力。覆盖率是一个内容提供商会关心的指标。

​	以图书推荐为例，出版社可能会很关心他们的书有没有被推荐给用户。覆盖率为100%的推荐系统可以将每个物品都推荐给至少一个用户。此外，从上面的定义也可以看到，热门排行榜的推荐覆盖率是很低的，它只会推荐那些热门的物品，这些物品在总物品中占的比例很小。一个好的推荐系统不仅需要有比较高的用户满意度，也要有较高的覆盖率。

​	可以通过研究物品在推荐列表中出现次数的分布描述推荐系统挖掘长尾的能力。如果这个分布比较平，那么说明推荐系统的覆盖率较高，而如果这个分布较陡峭，说明推荐系统的覆盖率较低。

​	社会学领域有一个著名的**马太效应，即所谓强者更强，弱者更弱的效应**。如果一个系统会增大热门物品和非热门物品的流行度差距，让热门的物品更加热门，不热门的物品更加不热门，那么这个系统就有马太效应。

​	推荐系统的初衷是希望消除马太效应，使得各种物品都能被展示给对它们感兴趣的某一类人群。但是，很多研究表明现在主流的推荐算法（比如协同过滤算法）是具有马太效应的。**评测推荐系统是否具有马太效应的简单办法就是使用基尼系数**。（如果G1是从初始用户行为中计算出的物品流行度的基尼系数，G2是从推荐列表中计算出的物品流行度的基尼系数，那么如果G2 > G1，就说明推荐算法具有马太效应。）

#### 4. 多样性

​	为了满足用户广泛的兴趣，推荐列表需要能够覆盖用户不同的兴趣领域，即推荐结果需要具有多样性。多样性推荐列表的好处用一句俗话表述就是“不在一棵树上吊死”。

​	**多样性描述了推荐列表中物品两两之间的不相似性。因此，多样性和相似性是对应的**。

#### 5. 新颖性

​	新颖的推荐是指给用户推荐那些他们以前没有听说过的物品。

​	O’scar Celma在博士论文“Music Recommendation and Discovery in the Long Tail”①中研究了新颖度的评测。评测新颖度的最简单方法是利用推荐结果的平均流行度，因为越不热门的物品越可能让用户觉得新颖。因此，**如果推荐结果中物品的平均热门程度较低，那么推荐结果就可能有比较高的新颖性**。

​	通过牺牲精度来提高多样性和新颖性是很容易的，而**困难的是如何在不牺牲精度的情况下提高多样性和新颖性**。

#### 6. 惊喜度

​	**如果推荐结果和用户的历史兴趣不相似，但却让用户觉得满意，那么就可以说推荐结果的惊喜度很高，而推荐的新颖性仅仅取决于用户是否听说过这个推荐结果**。

​	目前并没有什么公认的惊喜度指标定义方式，这里只给出一种定性的度量方式。上面提到，令用户惊喜的推荐结果是和用户历史上喜欢的物品不相似，但用户却觉得满意的推荐。那么，**定义惊喜度需要首先定义推荐结果和用户历史上喜欢的物品的相似度，其次需要定义用户对推荐结果的满意度**。

​	提高推荐惊喜度需要提高推荐结果的用户满意度，同时降低推荐结果和用户历史兴趣的相似度。

> 用户满意度只能通过问卷调查或者在线实验获得，而推荐结果和用户历史上喜欢的物品相似度一般可以用内容相似度定义。也就是说，如果获得了一个用户观看电影的历史，得到这些电影的演员和导演集合A，然后给用户推荐一个不属于集合A的导演和演员创作的电影，而用户表示非常满意，这样就实现了一个惊喜度很高的推荐。

#### 7. 信任度

​	同样的推荐结果，以让用户信任的方式推荐给用户就更能让用户产生购买欲，而以类似广告形式的方法推荐给用户就可能很难让用户产生购买的意愿。

​	提高推荐系统的信任度主要有两种方法。

- 首先需要增加推荐系统的透明度（transparency），而增加推荐系统透明度的主要办法是提供推荐解释。只有让用户了解推荐系统的运行机制，让用户认同推荐系统的运行机制，才会提高用户对推荐系统的信任度。
- 其次是考虑用户的社交网络信息，利用用户的好友信息给用户做推荐，并且用好友进行推荐解释。这是因为用户对他们的好友一般都比较信任，因此如果推荐的商品是好友购买过的，那么他们对推荐结果就会相对比较信任。

> Epinion为了防止垃圾评论或者广告评论影响用户的决策，在每条用户评论的右侧都显示了评论作者的信息，并且让用户判断是信任该评论人还是将他加入黑名单。如果网站具有Epinion的用户信任系统，那么可以在给用户做推荐时，尽量推荐他信任的其他用户评论过的物品。

#### 8. 实时性

​	很多推荐系统都会在离线状态每天计算一次用户推荐列表，然后于在线期间将推荐列表展示给用户。这种设计显然是无法满足实时性的。与用户行为相应的实时性，可以通过推荐列表的变化速率来评测。**如果推荐列表在用户有行为后变化不大，或者没有变化，说明推荐系统的实时性不高**。

​	实时性的第二个方面是推荐系统需要能够**将新加入系统的物品推荐给用户**。这主要考验了推荐系统处理物品**冷启动**的能力。

​	对于新物品推荐能力，我们可以利用用户推荐列表中有多大比例的物品是当天新加的来评测。

#### 9. 健壮性

​	任何一个能带来利益的算法系统都会被人攻击，这方面最典型的例子就是搜索引擎。搜索引擎的作弊和反作弊斗争异常激烈，这是因为如果能让自己的商品成为热门搜索词的第一个搜索果，会带来极大的商业利益。推荐系统目前也遇到了同样的作弊问题，而**健壮性（即robust,鲁棒性）指标衡量了一个推荐系统抗击作弊的能力**。

​	**算法健壮性的评测主要利用模拟攻击**。首先，给定一个数据集和一个算法，可以用这个算法给这个数据集中的用户生成推荐列表。然后，用常用的攻击方法向数据集中注入噪声数据，然后利用算法在注入噪声后的数据集上再次给用户生成推荐列表。最后，通过比较攻击前后推荐列表的相似度评测算法的健壮性。如果攻击后的推荐列表相对于攻击前没有发生大的变化，就说明算法比较健壮。

​	在实际系统中，提高系统的健壮性，除了选择健壮性高的算法，还有以下方法。

- **设计推荐系统时尽量使用代价比较高的用户行为**。比如，如果有用户购买行为和用户浏览行为，那么主要应该使用用户购买行为，因为购买需要付费，所以攻击购买行为的代价远远大于攻击浏览行为。
- 在使用数据前，进行攻击检测，从而对数据进行清理。

> 众所周知，绝大部分推荐系统都是通过分析用户的行为实现推荐算法的。
>
> 比如，亚马逊有一种推荐叫做“购买商品A的用户也经常购买的其他商品”。它的主要计算方法是统计购买商品A的用户购买其他商品的次数。那么，我们可以很简单地攻击这个算法，让自己的商品在这个推荐列表中获得比较高的排名，比如可以注册很多账号，用这些账号同时购买A和自己的商品。
>
> 还有一种攻击主要针对评分系统，比如豆瓣的电影评分。这种攻击很简单，就是雇用一批人给自己的商品非常高的评分，而评分行为是推荐系统依赖的重要用户行为。

#### 10. 商业目标

​	很多时候，网站评测推荐系统更加注重网站的商业目标是否达成，而商业目标和网站的盈利模式是息息相关的。一般来说，最本质的商业目标就是平均一个用户给公司带来的盈利。不过这种指标不是很难计算，只是计算一次需要比较大的代价。因此，很多公司会根据自己的盈利模式设计不同的商业目标。

​	不同的网站具有不同的商业目标。比如电子商务网站的目标可能是销售额，基于展示广告盈利的网站其商业目标可能是广告展示总数，基于点击广告盈利的网站其商业目标可能是广告点击总数。因此，设计推荐系统时需要考虑最终的商业目标，而网站使用推荐系统的目的除了满足用户发现内容的需求，也需要利用推荐系统加快实现商业上的指标。

#### 11. 总结

​	获取各种评测指标的途径

|            | 离线实验 | 问卷调查 | 在线实验 |
| ---------- | -------- | -------- | -------- |
| 用户满意度 | ✖️        | ☑️        | ⭕️        |
| 预测准确度 | ☑️        | ☑️        | ✖️        |
| 覆盖率     | ☑️        | ☑️        | ☑️        |
| 多样性     | ⭕️        | ☑️        | ⭕️        |
| 新颖性     | ⭕️        | ☑️        | ⭕️        |
| 惊喜度     | ✖️        | ☑️        | ✖️        |

​	对于可以离线优化的指标，书籍作者的建议是应该在给定覆盖率、多样性、新颖性等限制条件下，尽量优化预测准确度。

用一个数学公式表达，离线实验的优化目标是：

```
最大化预测准确度
使得 覆盖率 > A
    多样性 > B
    新颖性 > C
其中，A、B、C的取值应该视不同的应用而定。
```

### 1.3.3 评测维度

​	增加评测维度的目的就是知道一个算法在什么情况下性能最好。这样可以为融合不同推荐算法取得最好的整体性能带来参考。

​	一般来说，评测维度分为如下3种。

- 用户维度：主要包括用户的人口统计学信息、活跃度以及是不是新用户等。
- 物品维度：包括物品的属性信息、流行度、平均分以及是不是新加入的物品等。
- 时间维度：包括季节，是工作日还是周末，是白天还是晚上等。

​	如果能够在推荐系统评测报告中包含不同维度下的系统评测指标，就能帮我们全面地了解推荐系统性能，找到一个看上去比较弱的算法的优势，发现一个看上去比较强的算法的缺点。

# 2. 第2章 利用用户行为数据

> [数据挖掘中最经典的案例之一-啤酒与尿布是真实的案例吗？](https://www.zhihu.com/question/20567005)

​	实现个性化推荐的最理想情况是用户能在注册的时候主动告诉我们他喜欢什么，但这种方法有３个缺点：

- 首先，现在的自然语言理解技术很难理解用户用来描述兴趣的自然语言；
- 其次，用户的兴趣是不断变化的，但用户不会不停地更新兴趣描述；
- 最后，很多时候用户并不知道自己喜欢什么，或者很难用语言描述自己喜欢什么。

​	因此，我们需要通过算法自动发掘用户行为数据，从用户的行为中推测出用户的兴趣，从而给用户推荐满足他们兴趣的物品。

​	啤酒和尿布的故事在互联网上被发扬光大。电子商务公司通过分析用户的购物车，找出诸如“购买A商品的用户都购买B商品”这种规律，同时在用户浏览A商品时直接为其展示购买A商品的用户都购买的其他商品。

​	基于用户行为分析的推荐算法是个性化推荐系统的重要算法，学术界一般将这种类型的算法称为**协同过滤算法**。顾名思义，协同过滤就是指用户可以齐心协力，通过不断地和网站互动，使自己的推荐列表能够不断过滤掉自己不感兴趣的物品，从而越来越满足自己的需求。

> 当当网在用户浏览《数据挖掘导论》时给用户推荐“购买本商品的顾客还买过”的书

## 2.1 用户行为数据简介

​	本章提到的个性化推荐算法都是基于用户行为数据分析设计的，因此本节将首先介绍用户行为数据。

​	用户行为数据在网站上最简单的存在形式就是日志。网站在运行过程中都产生大量原始日志（raw log），并将其存储在文件系统中。很多互联网业务会把多种原始日志按照用户行为汇总成会话日志（session log），其中每个 会话表示一次用户行为和对应的服务。比如，在搜索引擎和搜索广告系统中，服务会为每次查询生成一个展示日志（impression log），其中记录了查询和返回结果。如果用户点击了某个结果，这个点击信息会被服务器截获并存储在点击日志（click log）中。一个并行程序会周期性地归并展示日志和点击日志，得到的会话日志中每个消息是一个用户提交的查询、得到的结果以及点击。类似地，推荐系统和电子商务网站也会汇总原始日志生成描述用户行为的会话日志。会话日志通常存储在分布式数据仓库中，如支持离线分析的 Hadoop Hive和支持在线分析的Google Dremel。这些日志记录了用户的各种行为，如在电子商务网站中这些行为主要包括网页浏览、购买、点击、评分和评论等。

​	用户行为在个性化推荐系统中一般分两种：

- 显性反馈行为（explicit feedback）
- 隐性反馈行为（implicit feedback）

​	**显性反馈行为包括用户明确表示对物品喜好的行为**。

​	**隐性反馈行为指的是那些不能明确反应用户喜好的行为**。最具代表性的隐性反馈行为就是页面浏览行为。用户浏览一个物品的页面并不代表用户一定喜欢这个页面展示的物品，比如可能因为这个页面链接显示在首页，用户更容易点击它而已。相比显性反馈，隐性反馈虽然不明确，但数据量更大。在很多网站中，很多用户甚至只有隐性反馈数据，而没有显性反馈数据。

​	显性反馈数据和隐性反馈数据的比较

|          | 显性反馈数据 | 隐性反馈数据   |
| -------- | ------------ | -------------- |
| 用户兴趣 | 明确         | 不明确         |
| 数量     | 较少         | 庞大           |
| 存储     | 数据库       | 分布式文件系统 |
| 实时读取 | 实时         | 有延迟         |
| 正负反馈 | 都有         | **只有正反馈** |

​	各代表网站中显性反馈数据和隐性反馈数据的例子

|              | 显性反馈                   | 隐性反馈                               |
| ------------ | -------------------------- | -------------------------------------- |
| 视频网站     | 用户对视频的评分           | 用户观看视频的日志、浏览视频页面的日志 |
| 电子商务网站 | 用户对商品的评分           | 购买日志、浏览日志                     |
| 门户网站     | 用户对新闻的评分           | 阅读新闻的日志                         |
| 音乐网站     | 用户对音乐/歌手/专辑的评分 | 听歌的日志                             |

​	用户行为的统一表示

| 符号             | 说明                                                         |
| ---------------- | ------------------------------------------------------------ |
| user id          | 产生行为的用户的唯一标示                                     |
| item id          | 产生行为的用户的唯一标示                                     |
| behavior type    | 行为的种类（比如是购买还是浏览）                             |
| context          | 产生行为的上下文、包括时间和地点等                           |
| behavior weight  | 行为的权重（如果是观看视频的行为，那么这个权重可以是观看视频的时长；如果是打分行为，这个权重可以是分数） |
| behavior content | 行为的内容（如果是评论行为，那么就是评论的文本；如果是打标签的行为，就是标签） |

​	一般来说，不同的数据集包含不同的行为，目前比较有代表性的数据集有下面几个。

- 无上下文信息的隐性反馈数据集：每一条行为记录仅仅包含用户ID和物品ID。
- 无上下文信息的显性反馈数据集：每一条记录包含用户ID、物品ID和用户对物品的评分。
- 有上下文信息的隐性反馈数据集：每一条记录包含用户ID、物品ID和用户对物品产生行为的时间戳。Lastfm数据集就是这种类型的数据集。
- 有上下文信息的显性反馈数据集：每一条记录包含用户ID、物品ID、用户对物品的评分和评分行为发生的时间戳。Netflix Prize提供的就是这种类型的数据集。

​	本章使用的数据集基本都是第一种数据集，即无上下文信息的隐性反馈数据集。

> YouTube最早是用5分评分系统收集显性反馈的，但后来他们的研究人员统计了不同评分的评分数，结果发现，用户最常用的评分是5分，其次是1分，其他的分数很少有用户打。因此，后来YouTube就把评分系统改成了两档评分系统（喜欢/不喜欢）。
>
> YouTube的用户主要将精力放在看视频上，因此他们只有在特别不满或者特别满意时才会评分，因此二级评分系统就足够了。但如果是评论网站，用户主要将精力放在评论上，这时多级评分系统就是必要的。

## 2.2 用户行为分析

​	首先需要对用户行为数据进行分析，了解数据中蕴含的一般规律，这样才能对算法的设计起到指导作用。

### 2.2.1 用户活跃度和物品流行度的分布

> [什么是「长尾效应」 ？](https://www.zhihu.com/question/20027490/answer/259310914)

​	很多关于互联网数据的研究发现，互联网上的很多数据分布都满足一种称为Power Law的分布，这个分布在互联网领域也称**长尾分布**。

​	用户行为数据也蕴含着这种规律。

### 2.2.2 用户活跃度和物品流行度的关系

​	一般来说，不活跃的用户要么是新用户，要么是只来过网站一两次的老用户。那么，不同活跃度的用户喜欢的物品的流行度是否有差别？**一般认为，新用户倾向于浏览热门的物品**，因为他们对网站还不熟悉，只能点击首页的热门物品，而**老用户会逐渐开始浏览冷门的物品**。

​	**仅仅基于用户行为数据设计的推荐算法一般称为协同过滤算法**。学术界对协同过滤算法进行了深入研究，提出了很多方法，比如：

- **基于邻域的方法**（neighborhood-based）
- 隐语义模型（latent factor model）
- 基于图的随机游走算法（random walk on graph）

​	在这些方法中，最著名的、**在业界得到最广泛应用的算法是基于邻域的方法**，而基于邻域的方法主要包含下面两种算法。

- **基于用户的协同过滤算法：这种算法给用户推荐和他兴趣相似的其他用户喜欢的物品。**
- **基于物品的协同过滤算法：这种算法给用户推荐和他之前喜欢的物品相似的物品。**

下面几节将首先介绍上面两种算法，然后再简单介绍隐语义模型和基于图的模型。

## 2.3 实验设计和算法评测

​	前文说过，评测推荐系统有3种方法——离线实验、用户调查和在线实验。本节将通过离线实验方法评测提到的算法。首先介绍用到的数据集，然后介绍采用的实验方法和评测指标。

### 2.3.1 数据集

​	本章采用GroupLens提供的MovieLens数据集介绍和评测各种算法。 MovieLens数据集有3个不同的版本，本章选用中等大小的数据集。该数据集包含6000多用户对4000多部电影的100万条评分。该数据集是一个评分数据集，用户可以给电影评5个不同等级的分数（1～5分）。**本章着重研究隐反馈数据集中的TopN推荐问题，因此忽略了数据集中的评分记录**。也就是说，TopN推荐的任务是预测用户会不会对某部电影评分，而不是预测用户在准备对某部电影评分的前提下会给电影评多少分。

### 2.3.2 实验设计

> [用简单易懂的语言描述「过拟合 overfitting」？](https://www.zhihu.com/question/32246256)

​	协同过滤算法的离线实验一般如下设计。首先，将用户行为数据集按照均匀分布随机分成M份（本章取M=8），挑选一份作为测试集，将剩下的M-1份作为训练集。然后在训练集上建立用户兴趣模型，并在测试集上对用户行为进行预测，统计出相应的评测指标。为了保证评测指标并不是过拟合的结果，需要进行M次实验，并且每次都使用不同的测试集。然后将M次实验测出的评测指标的平均值作为最终的评测指标。

​	下面的Python代码描述了将数据集随机分成训练集和测试集的过程：

```
def SplitData(data, M, k, seed):
  test = []
  train = []
  random.seed(seed)
  for user, item in data:
    if random.randint(0,M) == k:
      test.append([user,item])
    else:
      train.append([user,item])
  return train, test
```

​	这里，每次实验选取不同的k（0 ≤ k ≤ M-1）和相同的随机数种子seed，进行M次实验就可以得到M个不同的训练集和测试集，然后分别进行实验，用M次实验的平均值作为最后的评测指标。这样做主要是防止某次实验的结果是过拟合的结果（over fitting），**但如果数据集够大，模型够简单，为了快速通过离线实验初步地选择算法，也可以只进行一次实验**。

### 2.3.3 评测指标

> [如何解释召回率与精确率？](https://www.zhihu.com/question/19645541)
>
> 召回率 (Recall)：正样本有多少被找出来了（召回了多少）。
>
> 精确率 (Precision)：你认为的正样本，有多少猜对了（猜的精确性如何）。

​	**召回率描述有多少比例的用户—物品评分记录包含在最终的推荐列表中，而准确率描述最终的推荐列表中有多少比例是发生过的用户—物品评分记录**。下面两段代码给出了召回率和准确率的计算方法。

```
def Recall(train, test, N):
  hit = 0
  all = 0
  for user in train.keys():
    tu = test[user]
    rank = GetRecommendation(user, N)
    for item, pui in rank:
      if item in tu:
        hit += 1
        all += len(tu)
  return hit / (all * 1.0)
def Precision(train, test, N):
  hit = 0
  all = 0
  for user in train.keys():
    tu = test[user]
    rank = GetRecommendation(user, N)
      for item, pui in rank:
        if item in tu:
          hit += 1
      all += N
  return hit / (all * 1.0)
```

​	除了评测推荐算法的精度，本章还计算了算法的覆盖率，**覆盖率反映了推荐算法发掘长尾的能力**，覆盖率越高，说明推荐算法越能够将长尾中的物品推荐给用户。

​	如果所有的物品都被推荐给至少一个用户，那么覆盖率就是100%。如下代码可以用来计算推荐算法的覆盖率：

```
def Coverage(train, test, N):
  recommend_items = set()
  all_items = set()
  for user in train.keys():
    for item in train[user].keys():
      all_items.add(item)
    rank = GetRecommendation(user, N)
    for item, pui in rank:
      recommend_items.add(item)
  return len(recommend_items) / (len(all_items) * 1.0)
```

​	最后，我们还需要评测推荐的新颖度，这里用推荐列表中物品的平均流行度度量推荐结果的新颖度。如果推荐出的物品都很热门，说明推荐的新颖度较低，否则说明推荐结果比较新颖。

```
def Popularity(train, test, N):
  item_popularity = dict()
  for user, items in train.items():
    for item in items.keys()
      if item not in item_popularity:
        item_popularity[item] = 0
      item_popularity[item] += 1
  ret = 0
  n = 0
  for user in train.keys():
    rank = GetRecommendation(user, N)
    for item, pui in rank:
      ret += math.log(1 + item_popularity[item])
      n += 1
  ret /= n * 1.0
  return ret
```

​	这里，在计算平均流行度时对每个物品的流行度取对数，这是因为物品的流行度分布满足长尾分布，在取对数后，流行度的平均值更加稳定。

> [在统计学中为什么要对变量取对数？](https://www.zhihu.com/question/22012482)
>
> 要研究A和B的关系，可以先研究 lnA和B的关系，因为令 z=lnA，那么 z和B的关系搞明白了，只要取 A=e^z，则 A和B的关系也出来了。所以如果你要研究A和B的关系，那么研究 “A的变换”和“B的变换”之间的关系也是可以的。
>
> 统计学中你要使用某个方法，就要满足这个方法的条件，如果你所研究的变量不满足条件，但是变量进行变换后就满足条件了，那么就可以进行变换。通常 “对数变换” 使用的最频繁，因为对数变换后你会神奇的发现条件就满足了。
>
> 比如一个右偏非负的数据（最常见的就是工资，财富），不满足正态，但是取对数后就符合正态了。
>
> 取对数还有其他的好处，其中一个就是能把大的数变小。变小的同时数据的方差也变小。比如动物的体重和身高。有老鼠，有大象，有恐龙。数据出来后你会发现恐龙，大象的数据非常大，另外方差也特别大。大象，恐龙的数据看起来就像是异常值，但是它们不是异常值，这种数据分析起来非常不好处理，怎么办？身高体重都取对数，变换后你会发现豁然开朗！
>
> 总的来说，取对数就是为了把不满足的条件变成满足或者让我们分析的结果变得更好一点。

## 2.4 基于邻域的算法

​	基于邻域的算法是推荐系统中最基本的算法，该算法不仅在学术界得到了深入研究，而且在业界得到了广泛应用。基于邻域的算法分为两大类，一类是基于用户的协同过滤算法，另一类是基于物品的协同过滤算法。下面几节将对这两种算法进行深入介绍，对比它们的优缺点并提出改进方案。

### 2.4.1 基于用户的协同过滤算法

​	**基于用户的协同过滤算法是推荐系统中最古老的算法**。可以不夸张地说，这个算法的诞生标志了推荐系统的诞生。该算法在1992年被提出，并应用于邮件过滤系统，1994年被GroupLens用于新闻过滤。在此之后直到200年，该算法都是推荐系统领域最著名的算法。本节将对该算法进行详细介绍，首先介绍最基础的算法，然后在此基础上提出不同的改进方法，并通过真实的数据集进行评测。

#### 1. 基础算法

​	基于用户的协同过滤算法主要包括两个步骤。

1. 找到和目标用户兴趣相似的用户集合。
2. 找到这个集合中的用户喜欢的，且目标用户没有听说过的物品推荐给目标用户。

步骤(1)的关键就是计算两个用户的兴趣相似度。这里，协同过滤算法主要**利用行为的相似度计算兴趣的相似度**。

参数K是UserCF的一个重要参数，它的调整对推荐算法的各种指标都会产生一定的影响。

- 准确率和召回率：可以看到，推荐系统的精度指标（准确率和召回率）并不和参数K成线性关系。在MovieLens数据集中，选择K=80左右会获得比较高的准确率和召回率。因此选择合适的K对于获得高的推荐系统精度比较重要。当然，推荐结果的精度对K也不是特别敏感，只要选在一定的区域内，就可以获得不错的精度。
- 流行度：可以看到，在3个数据集上K越大则UserCF推荐结果就越热门。这是因为K决定了UserCF在给你做推荐时参考多少和你兴趣相似的其他用户的兴趣，那么如果K越大，参考的人越多，结果就越来越趋近于全局热门的物品。
- 覆盖率：可以看到，在3个数据集上，K越大则UserCF推荐结果的覆盖率越低。覆盖率的降低是因为流行度的增加，随着流行度增加，UserCF越来越倾向于推荐热门的物品，从而对长尾物品的推荐越来越少，因此造成了覆盖率的降低。

#### 2. 用户相似度计算的改进

​	上一节介绍了计算用户兴趣相似度的最简单的公式（余弦相似度公式），但这个公式过于粗糙，本节将讨论如何改进该公式来提高UserCF的推荐性能。

​	**两个用户对冷门物品采取过同样的行为更能说明他们兴趣的相似度**。

#### 3. 实际在线系统使用UserCF的例子

​	**相比我们后面要讨论的基于物品的协同过滤算法（ItemCF）， UserCF在目前的实际应用中使用并不多**。

> Digg在博客中公布了使用推荐系统后的效果，主要指标如下所示。
>
> - 用户反馈增加：用户“顶”和“踩”的行为增加了40%。
> - 平均每个用户将从34个具相似兴趣的好友那儿获得200条推荐结果。
> - 用户和好友的交互活跃度增加了24%。
> - 用户评论增加了11%。
>
> 上面只是对比了使用推荐系统后和使用推荐系统前的结果，并非AB测试的结果，因此还不完全具有说服力，但还是部分证明了推荐系统的有效性。

### 2.4.2 基于物品的协同过滤算法

​	**基于物品的协同过滤（item-based collaborative filtering）算法是目前业界应用最多的算法**。无论是亚马逊网，还是Netflix、Hulu、YouTube，其推荐算法的基础都是该算法。本节将从基础的算法开始介绍，然后提出算法的改进方法，并通过实际数据集评测该算法。

#### 1. 基础算法

​	基于用户的协同过滤算法在一些网站（如Digg）中得到了应用，但该算法有一些缺点。

- 首先，**随着网站的用户数目越来越大，计算用户兴趣相似度矩阵将越来越困难，其运算时间复杂度和空间复杂度的增长和用户数的增长近似于平方关系。**
- 其次，**基于用户的协同过滤很难对推荐结果作出解释**。

​	因此，著名的电子商务公司亚马逊提出了另一个算法——基于物品的协同过滤算法。

​	**基于物品的协同过滤算法（简称ItemCF）给用户推荐那些和他们之前喜欢的物品相似的物品**。比如，该算法会因为你购买过《数据挖掘导论》而给你推荐《机器学习》。不过，ItemCF算法并不利用物品的内容属性计算物品之间的相似度，它主要通过分析用户的行为记录计算物品之间的相似度。

​	该算法认为，**物品A和物品B具有很大的相似度是因为喜欢物品A的用户大都也喜欢物品B。**

​	基于物品的协同过滤算法可以利用用户的历史行为给推荐结果提供推荐解释，比如给用户推荐《天龙八部》的解释可以是因为用户之前喜欢《射雕英雄传》。

> - 亚马逊在iPhone商品界面上提供的与iPhone相关的商品，而相关商品都是购买iPhone的用户也经常购买的其他商品。
> - Hulu在个性化视频推荐利用ItemCF给每个推荐结果提供了一个推荐解释，而用于解释的视频都是用户之前观看或者收藏过的视频。

基于物品的协同过滤算法主要分为两步。

1. 计算物品之间的相似度。
2. 根据物品的相似度和用户的历史行为给用户生成推荐列表。

​	在协同过滤中两个物品产生相似度是因为它们共同被很多用户喜欢，也就是说每个用户都可以通过他们的历史兴趣列表给物品“贡献”相似度。这里面蕴涵着一个假设，就是每个用户的兴趣都局限在某几个方面，因此如果两个物品属于一个用户的兴趣列表，那么这两个物品可能就属于有限的几个领域，而如果两个物品属于很多用户的兴趣列表，那么它们就可能属于同一个领域，因而有很大的相似度。

​	ItemCF通过公式计算用户对一个物品的兴趣，**和用户历史上感兴趣的物品越相似的物品，越有可能在用户的推荐列表中获得比较高的排名**。

​	**ItemCF的一个优势就是可以提供推荐解释，即利用用户历史上喜欢的物品为现在的推荐结果进行解释**。

​	在MovieLens数据集上ItemCF算法离线实验的各项性能指标的评测结果。

- 精度（准确率和召回率）：可以看到ItemCF推荐结果的精度也是不和K成正相关或者负相关的，因此选择合适的K对获得最高精度是非常重要的。
- 流行度：和UserCF不同，参数K对ItemCF推荐结果流行度的影响也不是完全正相关的。随着K的增加，结果流行度会逐渐提高，但当K增加到一定程度，流行度就不会再有明显变化。
- 覆盖率：K增加会降低系统的覆盖率。

#### 2. 用户活跃度对物品相似度的影响

​	从前面的讨论可以看到，在协同过滤中两个物品产生相似度是因为它们共同出现在很多用户的兴趣列表中。换句话说，每个用户的兴趣列表都对物品的相似度产生贡献。那么，是不是每个用户的贡献都相同呢？

​	假设有这么一个用户，他是开书店的，并且买了当当网上80%的书准备用来自己卖。那么，他的购物车里包含当当网80%的书。假设当当网有100万本书，也就是说他买了80万本。从前面对ItemCF的讨论可以看到，这意味着因为存在这么一个用户，有80万本书两两之间就产生了相似度，也就是说，内存里即将诞生一个80万乘80万的稠密矩阵。

​	另外可以看到，这个用户虽然活跃，但是买这些书并非都是出于自身的兴趣，而且这些书覆盖了当当网图书的很多领域，所以**这个用户对于他所购买书的两两相似度的贡献应该远远小于一个只买了十几本自己喜欢的书的文学青年**。

​	John S. Breese在论文中提出了一个称为IUF（Inverse User Frequence），即用户活跃度对数的倒数的参数，他也认为**活跃用户对物品相似度的贡献应该小于不活跃的用户**。

​	**对于很多过于活跃的用户，比如上面那位买了当当网80%图书的用户，为了避免相似度矩阵过于稠密，我们在实际计算中一般直接忽略他的兴趣列表，而不将其纳入到相似度计算的数据集中**。

#### 3. 物品相似度的归一化

​	Karypis在研究中发现如果将ItemCF的相似度矩阵按最大值归一化，可以提高推荐的准确率。

​	**归一化的好处不仅仅在于增加推荐的准确度，它还可以提高推荐的覆盖率和多样性**。

​	对于两个不同的类，什么样的类其类内物品之间的相似度高，什么样的类其类内物品相似度低呢？**一般来说，热门的类其类内物品相似度一般比较大**。如果不进行归一化，就会推荐比较热门的类里面的物品，而这些物品也是比较热门的。因此，推荐的覆盖率就比较低。相反，如果进行相似度的归一化，则可以提高推荐系统的覆盖率。

> 假设物品分为两类——A和B，A类物品之间的相似度为0.5，B类物品之间的相似度为0.6，而A类物品和B类物品之间的相似度是0.2。在这种情况下，如果一个用户喜欢了5个A类物品和5个B类物品，用ItemCF给他进行推荐，推荐的就都是B类物品，因为B类物品之间的相似度大。但如果归一化之后，A类物品之间的相似度变成了1，B类物品之间的相似度也是1，那么这种情况下，用户如果喜欢5个A类物品和5个B类物品，那么他的推荐列表中A类物品和B类物品的数目也应该是大致相等的。从这个例子可以看出，相似度的归一化可以提高推荐的多样性。

### 2.4.3 UserCF和ItemCF的综合比较

​	UserCF是推荐系统领域较为古老的算法，1992年就已经在电子邮件的个性化推荐系统Tapestry中得到了应用，1994年被GroupLens用来实现新闻的个性化推荐，后来被著名的文章分享网站Digg用来给用户推荐个性化的网络文章。ItemCF则是相对比较新的算法，在著名的电子商务网站亚马逊和DVD租赁网站Netflix中得到了广泛应用。

- **UserCF给用户推荐那些和他有共同兴趣爱好的用户喜欢的物品**
- **ItemCF给用户推荐那些和他之前喜欢的物品类似的物品**

​	从这个算法的原理可以看到，UserCF的推荐结果着重于反映和用户兴趣相似的小群体的热点，而ItemCF的推荐结果着重于维系用户的历史兴趣。换句话说，**UserCF的推荐更社会化，反映了用户所在的小型兴趣群体中物品的热门程度，而ItemCF的推荐更加个性化，反映了用户自己的兴趣传承**。

​	UserCF适合用于新闻推荐的另一个原因是从技术角度考量的。因为作为一种物品，新闻的更新非常快，每时每刻都有新内容出现，而ItemCF需要维护一张物品相关度的表，如果物品更新很快，那么这张表也需要很快更新，这在技术上很难实现。**绝大多数物品相关度表都只能做到一天一次更新**，这在新闻领域是不可以接受的。而UserCF只需要用户相似性表，虽然UserCF对于新用户也需要更新相似度表，但**在新闻网站中，物品的更新速度远远快于新用户的加入速度**，而且对于新用户，完全可以给他推荐最热门的新闻，因此UserCF显然是利大于弊。

​	但是，在图书、电子商务和电影网站，比如亚马逊、豆瓣、Netflix中，ItemCF则能极大地发挥优势。首先，在这些网站中，用户的兴趣是比较固定和持久的。一个技术人员可能都是在购买技术方面的书，而且他们对书的热门程度并不是那么敏感，事实上**越是资深的技术人员，他们看的书就越可能不热门**。此外，这些系统中的用户大都不太需要流行度来辅助他们判断一个物品的好坏，而是可以通过自己熟悉领域的知识自己判断物品的质量。因此，这些网站中个性化推荐的任务是**帮助用户发现和他研究领域相关的物品**。因此，ItemCF算法成为了这些网站的首选算法。此外，**这些网站的物品更新速度不会特别快，一天一次更新物品相似度矩阵对它们来说不会造成太大的损失**，是可以接受的。

​	同时，从技术上考虑：

- **UserCF需要维护一个用户相似度的矩阵**
- **ItemCF需要维护一个物品相似度矩阵**。

​	从存储的角度说，如果用户很多，那么维护用户兴趣相似度矩阵需要很大的空间，同理，如果物品很多，那么维护物品相似度矩阵代价较大。

​	在早期的研究中，大部分研究人员都是让少量的用户对大量的物品进行评价，然后研究用户兴趣的模式。那么，对于他们来说，因为用户很少，计算用户兴趣相似度是最快也是最简单的方法。但在实际的互联网中，用户数目往往非常庞大，而在图书、电子商务网站中，物品的数目则是比较少的。此外，物品的相似度相对于用户的兴趣一般比较稳定，因此使用ItemCF是比较好的选择。当然，新闻网站是个例外，在那儿，物品的相似度变化很快，物品数目庞大，相反用户兴趣则相对固定（都是喜欢看热门的），所以新闻网站的个性化推荐使用UserCF算法的更多。

​	UserCF和ItemCF优缺点的对比



|          | UserCF                                                       | ItemCF                                                       |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 性能     | 适用于用户较少的场合，如果用户很多，计算用户相似度矩阵代价很大 | 适用于物品数明显小于用户数的场合，如果物品很多（网页），计算物品相似度矩阵代价很大 |
| 领域     | 时效性较强，用户个性化兴趣不太明显的领域                     | 长尾物品丰富，用户个性化需求强烈的领域                       |
| 实时性   | 用户有新行为，不一定造成推荐结果的立即变化                   | 用户有新行为，一定会导致推荐结果的实时变化                   |
| 冷启动   | 在新用户对很少的物品产生行为后，不能立即对他进行个性化推荐，因为用户相似度表是每隔一段时间离线计算的                 新物品上线后一段时间，一旦有用户对物品产生行为，就可以将新物品推荐给和对它产生行为的用户兴趣相似的其他用户 | 新用户只要对一个物品产生行为，就可以给他推荐和该物品相关的其他物品                 但没有办法在不离线更新物品相似度表的情况下将新物品推荐给用户 |
| 推荐理由 | 很难提供令用户信服的推荐解释                                 | 利用用户的历史行为给用户做推荐解释，可以令用户比较信服       |



​	首先要指出的是，**离线实验的性能在选择推荐算法时并不起决定作用**。

- 首先应该满足产品的需求，比如如果需要提供推荐解释，那么可能得选择ItemCF算法。
- 其次，需要看实现代价，比如若用户太多，很难计算用户相似度矩阵，这个时候可能不得不抛弃UserCF算法。
- 最后，离线指标和点击率等在线指标不一定成正比。

​	 而且，这里对比的是最原始的UserCF和ItemCF算法，这两种算法都可以进行各种各样的改进。**一般来说，这两种算法经过优化后，最终得到的离线性能是近似的**。

​	下一节将分析为什么原始ItemCF算法的覆盖率和新颖度都不高。

#### 哈利波特问题

​	亚马逊网的研究人员在设计ItemCF算法之初发现ItemCF算法计算出的图书相关表存在一个问题，就是很多书都和《哈利波特》相关。也就是说，购买任何一本书的人似乎都会购买《哈利波特》。后来他们研究发现，主要是因为《哈利波特》太热门了，确实是购买任何一本书的人几乎都会购买它。

​	每个用户一般都会在不同的领域喜欢一种物品。以电视为例，看新闻联播是父辈每天的必修课，他们每天基本就看新闻联播，而且每天不看别的新闻，就看这一种新闻。此外，他们很多都是电视剧迷，都会看央视一套8点的电视剧。那么，最终结果就是黄金时间的电视剧都和新闻联播相似，而新闻联播和其他新闻的相似度很低。

​	上面的问题换句话说就是，**两个不同领域的最热门物品之间往往具有比较高的相似度**。这个时候，仅仅靠用户行为数据是不能解决这个问题的，因为用户的行为表示这种物品之间应该相似度很高。此时，我们只能依靠引入物品的内容数据解决这个问题，比如对不同领域的物品降低权重等。这些就不是协同过滤讨论的范畴了。

## 2.5 隐语义模型

> [最小推荐系统：隐语义模型(Latent Factor Model)](https://zhuanlan.zhihu.com/p/150285625)

​	自从Netflix Prize比赛举办以来，LFM（latent factor model）**隐语义模型**逐渐成为推荐系统领域耳熟能详的名词。其实该算法最早在文本挖掘领域被提出，用于找到文本的隐含语义。相关的名词有LSI、pLSA、LDA和Topic Model。本节将对隐含语义模型在Top-N推荐中的应用进行详细介绍，并通过实际的数据评测该模型。

### 2.5.1 基础算法

​	隐语义模型是最近几年推荐系统领域最为热门的研究话题，它的核心思想是**通过隐含特征(latent factor)联系用户兴趣和物品**。

​	通过一个例子来理解一下这个模型。用户A的兴趣涉及侦探小说、科普图书以及一些计算机技术书，而用户B的兴趣比较集中在数学和机器学习方面。

​	如何给A和B推荐图书呢？

- 对于UserCF，首先需要找到和他们看了同样书的其他用户（兴趣相似的用户），然后给他们推荐那些用户喜欢的其他书。
- 对于ItemCF，需要给他们推荐和他们已经看的书相似的书，比如作者B看了很多关于数据挖掘的书，可以给他推荐机器学习或者模式识别方面的书。

​	还有一种方法，可以对书和物品的兴趣进行分类。**对于某个用户，首先得到他的兴趣分类，然后从分类中挑选他可能喜欢的物品**。

​	总结一下，这个**基于兴趣分类**的方法大概需要解决3个问题。

- 如何给物品进行分类？
- 如何确定用户对哪些类的物品感兴趣，以及感兴趣的程度？
- 对于一个给定的类，选择哪些属于这个类的物品推荐给用户，以及如何确定这些物品在一个类中的权重？

​	对于第一个问题的简单解决方案是找编辑给物品分类。以图书为例，每本书出版时，编辑都会给书一个分类。为了给图书分类，出版界普遍遵循中国图书分类法。但是，即使有很系统的分类体系，编辑给出的分类仍然具有以下缺点。

- 编辑的意见不能代表各种用户的意见。比如，对于《具体数学》应该属于什么分类，有人认为应该属于数学，有些人认为应该属于计算机。从内容看，这本书是关于数学的，但从用户看，这本书的读大部分是做计算机出身的。编辑的分类大部分是从书的内容出发，而不是从书的读者群出发。
- 编辑**很难控制分类的粒度**。我们知道分类是有不同粒度的，《数据挖掘导论》在粗粒度的分类中可能属于计算机技术，但在细粒度的分类中可能属于数据挖掘。**对于不同的用户，我们可能需要不同的粒度。比如对于一位初学者，我们粗粒度地给他做推荐就可以了，而对于一名资深研究人员，我们就需要深入到他的很细分的领域给他做个性化推荐**。
- 编辑很难给一个物品多个分类。有的书不仅属于一个类，而是**可能属于很多的类**。
- 编辑很难给出多维度的分类。我们知道，分类是可以有很多维度的，比如按照作者分类、按照译者分类、按照出版社分类。比如不同的用户看《具体数学》原因可能不同，有些人是因为它是数学方面的书所以才看的，而有些人是因为它是大师Knuth的著作所以才去看，因此**在不同人的眼中这本书属于不同的分类**。
- 编辑很难决定一个物品在某一个**分类中的权重**。比如编辑可以很容易地决定《数据挖掘导论》属于数据挖掘类图书，但这本书在这类书中的定位是什么样的，编辑就很难给出一个准确的数字来表示。

​	为了解决上面的问题，研究人员提出：为什么我们不从数据出发，自动地找到那些类，然后进行个性化推荐？于是，隐含语义分析技术（latent variable analysis）出现了。隐含语义分析技术因为采取**基于用户行为统计的自动聚类**，较好地解决了上面提出的5个问题。

- 编辑的意见不能代表各种用户的意见，但**隐含语义分析技术的分类来自对用户行为的统计，代表了用户对物品分类的看法**。**隐含语义分析技术和ItemCF在物品分类方面的思想类似，如果两个物品被很多用户同时喜欢，那么这两个物品就很有可能属于同一个类**。
- 编辑很难控制分类的粒度，但**隐含语义分析技术允许我们指定最终有多少个分类**，这个数字越大，分类的粒度就会越细，反正分类粒度就越粗。
- 编辑很难给一个物品多个分类，但**隐含语义分析技术会计算出物品属于每个类的权重**，因此每个物品都不是硬性地被分到某一个类中。
- 编辑很难给出多维度的分类，但**隐含语义分析技术给出的每个分类都不是同一个维度的，它是基于用户的共同兴趣计算出来的**，如果用户的共同兴趣是某一个维度，那么LFM给出的类也是相同的维度。
- 编辑很难决定一个物品在某一个分类中的权重，但**隐含语义分析技术可以通过统计用户行为决定物品在每个类中的权重**，如果喜欢某个类的用户都会喜欢某个物品，那么这个物品在这个类中的权重就可能比较高。

​	推荐系统的用户行为分为显性反馈和隐性反馈。**LFM在显性反馈数据（也就是评分数据）上解决评分预测问题并达到了很好的精度**。不过本章主要讨论的是隐性反馈数据集，这种数据集的特点是只有正样本（用户喜欢什么物品），而没有负样本（用户对什么物品不感兴趣）。

​	那么，**在隐性反馈数据集上应用LFM解决TopN推荐的第一个关键问题就是如何给每个用户生成负样本**。

​	对于这个问题，Rong Pan在文章中进行了深入探讨。他对比了如下几种方法。

- 对于一个用户，用他所有没有过行为的物品作为负样本。
- 对于一个用户，从他没有过行为的物品中均匀采样出一些物品作为负样本。
- 对于一个用户，从他没有过行为的物品中采样出一些物品作为负样本，但采样时，保证每个用户的正负样本数目相当。
- 对于一个用户，从他没有过行为的物品中采样出一些物品作为负样本，但采样时，偏重采样不热门的物品。

​	对于第一种方法，它的明显缺点是负样本太多，正负样本数目相差悬殊，因而计算复杂度很高，最终结果的精度也很差。对于另外3种方法，Rong Pan在文章中表示第三种好于第二种，而第二种好于第四种。

​	后来，通过2011年的KDD Cup的Yahoo! Music推荐系统比赛，我们发现对负样本采样时应该遵循以下原则：

- **对每个用户，要保证正负样本的平衡（数目相似）。**
- **对每个用户采样负样本时，要选取那些很热门，而用户却没有行为的物品。**

​	**一般认为，很热门而用户却没有行为更加代表用户对这个物品不感兴趣。因为对于冷门的物品，用户可能是压根没在网站中发现这个物品，所以谈不上是否感兴趣**。

​	在LFM中，重要的参数有4个：

- 隐特征的个数F；
- 学习速率alpha；
- 正则化参数lambda；
- **负样本/正样本比例 ratio。**

​	通过实验发现，**ratio参数对LFM的性能影响最大**。

​	随着负样本数目的增加，LFM的准确率和召回率有明显提高。不过当ratio>10以后，准确率和召回率基本就比较稳定了。同时，随着负样本数目的增加，覆盖率不断降低，而推荐结果的流行度不断增加，说明ratio参数控制了推荐算法发掘长尾的能力。如果将LFM的结果与前面ItemCF和UserCF算法的性能相比，可以发现LFM在所有指标上都优于UserCF和ItemCF。当然，这只是在MovieLens一个数据集上的结果，我们也发现，当数据集非常稀疏时，LFM的性能会明显下降，甚至不如UserCF和ItemCF的性能。

### 2.5.2 基于LFM的实际系统的例子

​	雅虎的研究人员公布过一个使用LFM进行雅虎首页个性化设计的方案①。本节将简单介绍他们的设计并讨论他们的设计方案。

​	雅虎首页的界面，包括不同的模块，比如左侧的分类导航列表、中间的热门新闻列表、右侧的最近热门话题列表。雅虎的研究人员认为这3个模块都可以进行一定的个性化，可以根据用户的兴趣给他们展示不同的内容。

​	当然，雅虎的研究人员在上面的模型基础上进行了一些修改，利用了一些改进的LFM模型。这些模型主要来自Netflix Prize比赛，因此我们会在第8章详细讨论这些模型。

​	但是，**LFM模型在实际使用中有一个困难，那就是它很难实现实时的推荐**。

​	经典的LFM模型每次训练时都**需要扫描所有的用户行为记录**，这样才能计算出用户隐类向量（pu）和物品隐类向量（qi）。而且LFM的训练需要在用户行为记录上**反复迭代才能获得比较好的性能**。因此，LFM的每次训练都很耗时，一般在实际应用中只能每天训练一次，并且计算出所有用户的推荐结果。

​	**LFM模型不能因为用户行为的变化实时地调整推荐结果来满足用户最近的行为**。

​	实时性在雅虎的首页个性化推荐系统中非常重要。为了解决传统LFM不能实时化，而产品需要实时性的矛盾，雅虎的研究人员提出了一个解决方案。

​	他们的解决方案分为两个部分。首先，他们利用新闻链接的内容属性（关键词、类别等）得到链接i的内容特征向量yi。其次，他们会实时地收集用户对链接的行为，并且用这些数据得到链接i的隐特征向量qi。然后，他们会利用如下公式预测用户u是否会单击链接i：



​	其中，yi是根据物品的内容属性直接生成的，xuk是用户u对内容特征k的兴趣程度，用户向量xu可以根据历史行为记录获得，而且每天只需要计算一次。而pu、qi是根据实时拿到的用户最近几小时的行为训练LFM获得的。因此，对于一个新加入的物品i，可以通过xTu * yi估计用户u对物品i的兴趣，然后经过几个小时后，就可以通过pTu * qi 得到更加准确的预测值。

​	上面的讨论只是简单阐述了雅虎所用的方法，关于雅虎具体的方法可以参考他们的报告。

### 2.5.3 LFM和基于邻域的方法的比较

​	**LFM是一种基于机器学习的方法**，具有比较好的理论基础。这个方法和基于邻域的方法（比如UserCF、ItemCF）相比，各有优缺点。下面将从不同的方面对比LFM和基于邻域的方法。

- 理论基础：LFM具有比较好的理论基础，它是一种学习方法，通过优化一个设定的指标 建立最优的模型。**基于邻域的方法更多的是一种基于统计的方法，并没有学习过程**。
- 离线计算的空间复杂度：**基于邻域的方法需要维护一张离线的相关表**。在离线计算相关 表的过程中，如果用户/物品数很多，将会占据很大的内存。假设有M个用户和N个物品， 在计算相关表的过程中，我们可能会获得一张比较稠密的临时相关表（尽管最终我们对 每个物品只保留K个最相关的物品，但在中间计算过程中稠密的相关表是不可避免的）， 那么假设是用户相关表，则需要O(M*M)的空间，而对于物品相关表，则需要O(N*N)的空 间。而LFM在建模过程中，如果是F个隐类，那么它需要的存储空间是O(F*(M+N))，这在 M和N很大时可以很好地节省离线计算的内存。**在Netflix Prize中，因为用户数很庞大** **（40多万），很少有人使用UserCF算法（据说需要30 GB左右的内存），而LFM由于大量节** **省了训练过程中的内存（只需要4 GB），从而成为Netflix Prize中最流行的算法**。
- 离线计算的时间复杂度：假设有M个用户、N个物品、K条用户对物品的行为记录。那么， UserCF计算用户相关表的时间复杂度是O(N * (K/N)^2)，而ItemCF计算物品相关表的时间 复杂度是O(M*(K/M)^2)。而对于LFM，如果用F个隐类，迭代S次，那么它的计算复杂度 是O(K * F * S)。那么，如果K/N > F*S，则代表UserCF的时间复杂度低于LFM，如果 K/M>F*S，则说明ItemCF的时间复杂度低于LFM。**在一般情况下，LFM的时间复杂度要** **稍微高于UserCF和ItemCF，这主要是因为该算法需要多次迭代**。但总体上，这两种算法 在时间复杂度上没有质的差别。
- 在线实时推荐：UserCF和ItemCF在线服务算法需要将相关表缓存在内存中，然后可以在 线进行实时的预测。以ItemCF算法为例，一旦用户喜欢了新的物品，就可以通过查询内 存中的相关表将和该物品相似的其他物品推荐给用户。因此，一旦用户有了新的行为， 而且该行为被实时地记录到后台的数据库系统中，他的推荐列表就会发生变化。而从LFM 的预测公式可以看到，**LFM在给用户生成推荐列表时，需要计算用户对所有物品的兴趣** **权重，然后排名，返回权重最大的N个物品**。那么，在物品数很多时，这一过程的时间 复杂度非常高，可达O(M*N*F)。因此，**LFM不太适合用于物品数非常庞大的系统，如** **果要用，我们也需要一个比较快的算法给用户先计算一个比较小的候选列表，然后再用** **LFM重新排名。**另一方面，**LFM在生成一个用户推荐列表时速度太慢，因此不能在线实** **时计算，而需要离线将所有用户的推荐结果事先计算好存储在数据库中**。因此，**LFM不** **能进行在线实时推荐**，也就是说，当用户有了新的行为后，他的推荐列表不会发生变化。
- 推荐解释：**ItemCF算法支持很好的推荐解释，它可以利用用户的历史行为解释推荐结果。** 但LFM无法提供这样的解释，它计算出的隐类虽然在语义上确实代表了一类兴趣和物品， 却很难用自然语言描述并生成解释展现给用户。

## 2.6 基于图的模型

​	用户行为很容易用二分图表示，因此很多图的算法都可以用到推荐系统中。本节将重点讨论如何将用户行为用图表示，并利用图的算法给用户进行个性化推荐。

### 2.6.1 用户行为数据的二分图表示

​	基于图的模型（graph-based model）是推荐系统中的重要内容。其实，很多研究人员把基于邻域的模型也称为基于图的模型，因为**可以把基于邻域的模型看做基于图的模型的简单形式**。

​	在研究基于图的模型之前，首先需要将用户行为数据表示成图的形式。本章讨论的用户行为数据是由一系列二元组组成的，其中每个二元组(u, i)表示用户u对物品i产生过行为。这种数据集很容易用一个二分图表示。

​	令G(V,E)表示用户物品二分图，其中V = VU U VI 由用户顶点集合 VU 和物品顶点集合VI组成。对于数据集中每一个二元组(u, i)，图中都有一套对应的边e(vu,vi) ，其中vu ∈ VU 是用户u对应的顶点，vi ∈ VI 是物品i对应的顶点。下图是一个简单的用户物品二分图模型，其中圆形节点代表用户，方形节点代表物品，圆形节点和方形节点之间的边代表用户对物品的行为。比如图中用户节点A和物品节点a、b、d相连，说明用户A对物品a、b、d产生过行为。

![img](http://www.ituring.com.cn/figures/2012/tuijinxitongshijian/06.D%2002%20Z/image71.png)

### 2.6.2 基于图的推荐算法

​	将用户行为表示为二分图模型后，下面的任务就是在二分图上给用户进行个性化推荐。如果将个性化推荐算法放到二分图模型上，那么给用户u推荐物品的任务就可以转化为度量用户顶点vu和与vu没有边直接相连的物品节点在图上的相关性，相关性越高的物品在推荐列表中的权重就越高。

​	度量图中两个顶点之间相关性的方法很多，但一般来说图中顶点的相关性主要取决于下面3个因素：

- 两个顶点之间的路径数；
- 两个顶点之间路径的长度；
- 两个顶点之间的路径经过的顶点。

​	而相关性高的一对顶点一般具有如下特征：

- 两个顶点之间有很多路径相连；
- 连接两个顶点之间的路径长度都比较短；
- **连接两个顶点之间的路径不会经过出度比较大的顶点**。

​	举一个简单的例子，如下图所示，用户A和物品c、e没有边相连，但是用户A和物品c有两条长度为3的路径相连，用户A和物品e有两条长度为3的路径相连。那么，顶点A与e之间的相关性要高于顶点A与c，因而物品e在用户A的推荐列表中应该排在物品c之前，因为顶点A与e之间有两条路径——（A, b, C, e）和（A, d, D, e）。其中，（A, b, C, e）路径经过的顶点的出度为（3, 2, 2,2），而（A, d, D, e）路径经过的顶点的出度为（3, 2, 3, 2）。因此，（A, d, D, e）经过了一个出度比较大的顶点D，所以（A, d, D, e）对顶点A与e之间相关性的贡献要小于（A, b, C, e）。

![enter image description here](https://www.ituring.com.cn/download/01v0rRZrzCex)

​	基于上面3个主要因素，研究人员设计了很多计算图中顶点之间相关性的方法。本节将介绍一种基于随机游走的PersonalRank算法。

​	假设要给用户u进行个性化推荐，可以从用户u对应的节点vu开始在用户物品二分图上进行随机游走。游走到任何一个节点时，首先按照概率α决定是继续游走，还是停止这次游走并从vu节点开始重新游走。如果决定继续游走，那么就从当前节点指向的节点中按照均匀分布随机选择一个节点作为游走下次经过的节点。这样，经过很多次随机游走后，每个物品节点被访问到的概率会收敛到一个数。最终的推荐列表中物品的权重就是物品节点的访问概率。

​	虽然PersonalRank算法可以通过随机游走进行比较好的理论解释，但该算法在时间复杂度上有明显的缺点。因为**在为每个用户进行推荐时，都需要在整个用户物品二分图上进行迭代，直到整个图上的每个顶点的PR值收敛**。**这一过程的时间复杂度非常高，不仅无法在线提供实时推荐，甚至离线生成推荐结果也很耗时**。

​	为了解决PersonalRank每次都需要在全图迭代并因此造成时间复杂度很高的问题，这里给出两种解决方案。

- 第一种很容易想到，就是减少迭代次数，在收敛之前就停止。这样会影响最终的精度，但一般来说影响不会特别大。
- 另一种方法就是从矩阵论出发，重新设计算法。

# 3.  第3章 推荐系统冷启动问题

​	推荐系统需要根据用户的历史行为和兴趣预测用户未来的行为和兴趣，因此大量的用户行为数据就成为推荐系统的重要组成部分和先决条件。对于很多像百度、当当这样的网站来说，这或许不是个问题，因为它们目前已经积累了大量的用户数据。但是对于很多做纯粹推荐系统的网站（比如Jinni和Pandora），或者很多在开始阶段就希望有个性化推荐应用的网站来说，**如何在没有大量用户数据的情况下设计个性化推荐系统并且让用户对推荐结果满意从而愿意使用推荐系统，就是冷启动的问题**。

​	下面各节将简单介绍一下冷启动问题的分类，以及如何解决不同种类的冷启动问题。

## 3.1 冷启动问题简介

​	冷启动问题（cold start）主要分3类。

- **用户冷启动**：用户冷启动主要解决如何给新用户做个性化推荐的问题。当新用户到来时，我们没有他的行为数据，所以也无法根据他的历史行为预测其兴趣，从而无法借此给他做个性化推荐。
- **物品冷启动**：物品冷启动主要解决如何将新的物品推荐给可能对它感兴趣的用户这一问题。
- **系统冷启动**：系统冷启动主要解决如何在一个新开发的网站上（还没有用户，也没有用户行为，只有一些物品的信息）设计个性化推荐系统，从而在网站刚发布时就让用户体验到个性化推荐服务这一问题。

​	对于这3种不同的冷启动问题，有不同的解决方案。一般来说，可以参考如下解决方案。

- **提供非个性化的推荐**：非个性化推荐的最简单例子就是热门排行榜，我们可以给用户推荐热门排行榜，然后等到用户数据收集到一定的时候，再切换为个性化推荐。
- 利用用户注册时提供的年龄、性别等数据做粗粒度的个性化。
- 利用用户的社交网络账号登录（需要用户授权），导入用户在社交网站上的好友信息，然后给用户推荐其好友喜欢的物品。
- 要求用户在登录时对一些物品进行反馈，收集用户对这些物品的兴趣信息，然后给用户推荐那些和这些物品相似的物品。
- 对于新加入的物品，可以利用内容信息，将它们推荐给喜欢过和它们相似的物品的用户。
- 在系统冷启动时，可以引入专家的知识，通过一定的高效方式迅速建立起物品的相关度表。

​	下面几节将详细描述其中的某些方案。

## 3.2 利用用户注册信息

​	用户的注册信息分3种。

- 人口统计学信息 包括用户的年龄、性别、职业、民族、学历和居住地。
- 用户兴趣的描述 有一些网站会让用户用文字描述他们的兴趣。
- 从其他网站导入的用户站外行为数据 比如用户通过豆瓣、新浪微博的账号登录，就可以在得到用户同意的情况下获取用户在豆瓣或者新浪微博的一些行为数据和社交网络数据。

​	这一节主要讨论如何通过用户注册时填写的人口统计学信息给用户提供粗粒度的个性化推荐。

​	人口统计学特征包括年龄、性别、工作、学历、居住地、国籍、民族等，这些特征对预测用户的兴趣有很重要的作用，比如男性和女性的兴趣不同， 不同年龄的人兴趣也不同。

基于注册信息的个性化推荐流程基本如下：

1. 获取用户的注册信息；
2. 根据用户的注册信息对用户分类；
3. 给用户推荐他所属分类中用户喜欢的物品。

​	**基于用户注册信息的推荐算法其核心问题是计算每种特征的用户喜欢的物品**。

> 基于人口统计学特征的推荐系统其典型代表是Bruce Krulwich开发的Lifestyle Finder。首先，Bruce Krulwich将美国人群根据人口统计学属性分成62类，然后对于每个新用户根据其填写的个人资料判断他属于什么分类，最后给他推荐这类用户最喜欢的15个链接，其中5个链接是推荐他购买的商品，5个链接是推荐他旅游的地点，剩下的5个链接是推荐他去逛的商店。

## 3.3 选择合适的物品启动用户的兴趣

关键字提取：

- 冷启动
- 决策树

> [3.3　选择合适的物品启动用户的兴趣](https://www.ituring.com.cn/book/miniarticle/13917)

​	解决用户冷启动问题的另一个方法是在新用户第一次访问推荐系统时，不立即给用户展示推荐结果，而是**给用户提供一些物品，让用户反馈他们对这些物品的兴趣，然后根据用户反馈给提供个性化推荐**。很多推荐系统采取了这种方式来解决用户冷启动问题。

​	对于这些通过让用户对物品进行评分来收集用户兴趣，从而对用户进行冷启动的系统，它们需要解决的首要问题就是**如何选择物品让用户进行反馈**。

​	一般来说，能够用来启动用户兴趣的物品需要具有以下特点。

- 比较热门：如果要让用户对一个物品进行反馈，前提是用户知道这个物品是什么东西。以电影为例，如果一开始让用户进行反馈的电影都很冷门，而用户不知道这些电影的情节和内容，也就无法对它们做出准确的反馈。
- 具有代表性和区分性：启动用户兴趣的物品不能是大众化或老少咸宜的，因为这样的物品对用户的兴趣没有区分性。还以电影为例，用一部票房很高且广受欢迎的电影做启动物品，可以想象的到的是几乎所有用户都会喜欢这部电影，因而无法区分用户个性化的兴趣。
- 启动物品集合需要有多样性：在冷启动时，我们不知道用户的兴趣，而用户兴趣的可能性非常多，为了匹配多样的兴趣，我们需要提供具有很高覆盖率的启动物品集合，这些物品能覆盖几乎所有主流的用户兴趣。

​	Jinni在让用户反馈时没有直接拿电影让用户反馈，而是给出了12个电影类型，让用户先选择喜欢哪种类型，这样就很好地保证了启动物品集合的多样性。

​	上面这些因素都是选择启动物品时需要考虑的，但如何设计一个选择启动物品集合的系统呢？Nadav Golbandi在论文中探讨了这个问题，提出可以用一个**决策树**解决这个问题。

​	首先，给定一群用户，Nadav Golbandi用这群用户对物品评分的方差度量这群用户兴趣的一致程度。**如果方差很大，说明这一群用户的兴趣不太一致，反之则说明这群用户的兴趣比较一致**。

​	对于物品i，Nadav Golbandi将用户分成3类——**喜欢物品i的用户、不喜欢物品i的用户和不知道物品i的用户**（即没有给i评分的用户）。**如果这3类用户集合内的用户对其他的物品兴趣很不一致，说明物品i具有较高的区分度**。

​	Nadav Golbandi的算法首先会从所有用户中找到具有最高区分度的物品i，然后将用户分成3类。然后在每类用户中再找到最具区分度的物品，然后将每一类用户又各自分为3类，也就是将总用户分成9类，然后这样继续下去，最终可以通过对一系列物品的看法将用户进行分类。而在冷启动时，我们从根节点开始询问用户对该节点物品的看法，然后根据用户的选择将用户放到不同的分枝，直到进入最后的叶子节点，此时我们就已经对用户的兴趣有了比较清楚的了解，从而可以开始对用户进行比较准确地个性化推荐。

​	下图通过一个简单的例子解释Nadav Golbandi的算法。如图所示，假设通过分析用户数据，我们发现《变形金刚》最有区分度。而在喜欢《变形金刚》的用户中《钢铁侠》最有区分度，不知道《变形金刚》的用户中《阿甘正传》最有区分度，不喜欢《变形金刚》的用户中《泰坦尼克号》最有区分度。进一步分析，我们发现不喜欢《变形金刚》但喜欢《泰坦尼克号》的用户中，《人鬼情未了》最有区分度。那么，假设来了一个新用户，系统会首先询问他对《变形金刚》的看法，如果他说不喜欢，我们就会问他对《泰坦尼克》号的看法，如果他说喜欢，我们就会问他对《人鬼情未了》的看法，如果这个时候用户停止了反馈，我们也大概能知道该用户可能对爱情片比较感兴趣，对科幻片兴趣不大。

![img](http://www.ituring.com.cn/figures/2012/tuijinxitongshijian/07.D%2003%20Z/image30.png)

> 以Jinni为例，当新用户访问推荐系统时，它会给出一条提示语，表示用户需要给多部电影评分才能获取推荐结果。当用户选择给多部电影评分后，Jinni会首先展示一个页面让用户选择他喜欢的电影类别，当用户选择了某一个类别后，Jinni会展示第三个界面让用户对电影进行反馈。

## 3.4 利用物品的内容信息

关键字提取：

- 冷启动
- UserCF和ItemCF
- 向量空间模型
- 内容过滤算法
- 话题模型（代表性的有LDA）
- 词袋模型(bag of words)

> [3.4　利用物品的内容信息](https://www.ituring.com.cn/book/miniarticle/13918)

​	**物品冷启动需要解决的问题是如何将新加入的物品推荐给对它感兴趣的用户**。物品冷启动在新闻网站等时效性很强的网站中非常重要，因为那些网站中时时刻刻都有新加入的物品，而且每个物品必须能够在第一时间展现给用户，否则经过一段时间后，物品的价值就大大降低了。

​	第2章介绍了两种主要的推荐算法——UserCF和ItemCF算法。首先需要指出的是，**UserCF算法对物品冷启动问题并不非常敏感**。因为，UserCF在给用户进行推荐时，会首先找到和用户兴趣相似的一群用户，然后给用户推荐这一群用户喜欢的物品。在很多网站中，推荐列表并不是给用户展示内容的唯一列表，那么当一个新物品加入时，总会有用户从某些途径看到这些物品，对这些物品产生反馈。那么，当一个用户对某个物品产生反馈后，和他历史兴趣相似的其他用户的推荐列表中就有可能出现这一物品，从而更多的人就会对这个物品产生反馈，导致更多的人的推荐列表中会出现这一物品，因此该物品就能不断地扩散开来，从而逐步展示到对它感兴趣用户的推荐列表中。

​	但是，**有些网站中推荐列表可能是用户获取信息的主要途径，比如豆瓣网络电台。那么对于UserCF算法就需要解决第一推动力的问题，即第一个用户从哪儿发现新的物品**。只要有一小部分人能够发现并喜欢新的物品，UserCF算法就能将这些物品扩散到更多的用户中。解决第一推动力最简单的方法是将新的物品随机展示给用户，但这样显然不太个性化，因此**可以考虑利用物品的内容信息，将新物品先投放给曾经喜欢过和它内容相似的其他物品的用户**。关于如何利用内容信息，本节将在后面介绍。

​	**对于ItemCF算法来说，物品冷启动就是一个严重的问题**了。因为ItemCF算法的原理是给用户推荐和他之前喜欢的物品相似的物品。ItemCF算法会每隔一段时间利用用户行为计算物品相似度表（一般一天计算一次），在线服务时ItemCF算法会将之前计算好的物品相关度矩阵放在内存中。因此，当新物品加入时，内存中的物品相关表中不会存在这个物品，从而ItemCF算法无法推荐新的物品。解决这一问题的办法是频繁更新物品相似度表，但**基于用户行为计算物品相似度是非常耗时的事情**，主要原因是用户行为日志非常庞大。而且，**新物品如果不展示给用户，用户就无法对它产生行为，通过行为日志计算是计算不出包含新物品的相关矩阵的**。为此，我们只能利用物品的内容信息计算物品相关表，并且频繁地更新相关表（比如半小时计算一次）。

​	物品的内容信息多种多样，不同类型的物品有不同的内容信息。如果是电影，那么内容信息一般包括标题、导演、演员、编剧、剧情、风格、国家、年代等。如果是图书，内容信息一般包含标题、作者、出版社、正文、分类等。下表展示了常见物品的常用内容信息。

​	常见物品的内容信息

| 类型 | 内容信息                                         |
| ---- | ------------------------------------------------ |
| 图书 | 标题、作者、出版社、出版年代、丛书名、目录、正文 |
| 论文 | 标题、作者、作者单位、关键字、分类、摘要、正文   |
| 电影 | 标题、导演、演员、编剧、类别、剧情简介、发行公司 |
| 新闻 | 标题、正文、来源、作者                           |
| 微博 | 作者、内容、评论                                 |

​	一般来说，物品的内容可以通过向量空间模型表示，该模型会将物品表示成一个关键词向量。如果物品的内容是一些诸如导演、演员等实体的话，可以直接将这些实体作为关键词。但如果内容是文本的形式，则需要引入一些理解自然语言的技术抽取关键词。下图展示了从文本生成关键词向量的主要步骤。对于中文，首先要对文本进行分词，将字流变成词流，然后从词流中检测出命名实体（如人名、地名、组织名等），这些实体和一些其他重要的词将组成关键词集合，最后对关键词进行排名，计算每个关键词的权重，从而生成**关键词向量**。

![img](http://www.ituring.com.cn/figures/2012/tuijinxitongshijian/07.D%2003%20Z/image31.png)

​	**向量空间模型的优点是简单，缺点是丢失了一些信息**，比如关键词之间的关系信息。

​	**不过在绝大多数应用中，向量空间模型对于文本的分类、聚类、相似度计算已经可以给出令人满意的结果**。

​	得到物品的相似度之后，可以利用上一章提到的ItemCF算法的思想，给用户推荐和他历史上喜欢的物品内容相似的物品。

​	也许有读者认为，既然内容相似度计算简单，能频繁更新，而且能够解决物品冷启动问题，那么为什么还需要协同过滤的算法。为了说明内容过滤算法和协同过滤算法的优劣，本节在MovieLens和GitHub两个数据集上进行了实验。MovieLens数据集上一章已经详细介绍了，它也提供了有限的内容信息，主要包括电影的类别信息（动作片、爱情片等类别），GitHub数据集包含代码开发者对开源项目的兴趣数据，它的用户是程序员，物品是开源工程，如果一名程序员关注某个开源工程，就会有一条行为记录。该数据集中主要的内容数据是开源项目的所有者名。

​	表3-5比较了内容过滤算法ContentItemKNN和协调过滤算法ItemCF在MovieLens和GitHub数据集上的离线实验性能。为了对比，我们同时加入了Random和MostPopular两个非个性化的推荐算法作为基准。

​	表3-5　MovieLens/GitHub数据集中几种推荐算法性能的对比

| 方　法         | 准　确　率 | 召　回　率 | 覆　盖　率 | 流　行　度 |
| :------------- | :--------- | :--------- | :--------- | :--------- |
| **MovieLens**  |            |            |            |            |
| Random         | 0.631%     | 0.305%     | 100%       | 4.3855     |
| MostPopular    | 12.79%     | 6.18%      | 2.60%      | 7.7244     |
| ItemCF         | 22.28%     | 10.76%     | 18.84%     | 7.254526   |
| ContentItemKNN | 6.78%      | 3.28%      | 19.06%     | 5.8481     |
| **GitHub**     |            |            |            |            |
| Random         | 0.000985%  | 0.00305%   | 84.18%     | 0.9878     |
| MostPopular    | 1.18%      | 4.36%      | 0.0299%    | 7.1277     |
| ItemCF         | 2.56%      | 9.44%      | 33.71%     | 2.9119     |
| ContentItemKNN | 6.98%      | 25.75%     | 34.44%     | 1.7086     |

​	从MovieLens数据集上的结果可以发现，ContentItemKNN的准确率和召回率仅仅优于Random算法，明显差于ItemCF算法，甚至比MostPopular算法还要差。不过在覆盖率和流行度指标上ContentItemKNN却优于ItemCF。这主要是因为**内容过滤算法忽视了用户行为，从而也忽视了物品的流行度以及用户行为中所包含的规律，所以它的精度比较低，但结果的新颖度却比较高**。

​	不过，事情不是绝对的。如果看GitHub数据集的结果，我们会发现完全相反的现象——Content-ItemKNN在所有指标上都优于ItemCF。这主要是因为GitHub提供了一个非常强的内容特征，就是开源项目的作者。在GitHub中，程序员会经常会关注同一个作者的不同项目，这一点是GitHub数据集最重要的特征。而协同过滤算法由于数据稀疏的影响，不能从用户行为中完全统计出这一特征，所以协同过滤算法反而不如利用了先验信息的内容过滤算法。这一点也说明，**如果用户的行为强烈受某一内容属性的影响，那么内容过滤的算法还是可以在精度上超过协同过滤算法的**。不过这种强的内容特征不是所有物品都具有的，而且需要丰富的领域知识才能获得，所以很多时候内容过滤算法的精度比协同过滤算法差。不过，这也提醒我们，如果能够将这两种算法融合，一定能够获得比单独使用这两种算法更好的效果。

​	**向量空间模型在内容数据丰富时可以获得比较好的效果**。以文本为例，如果是计算长文本的相似度，用向量空间模型利用关键词计算相似度已经可以获得很高的精确度。但是，如果文本很短，关键词很少，向量空间模型就很难计算出准确的相似度。

​	举个例子，假设有两篇论文，它们的标题分别是“推荐系统的动态特性”和“基于时间的协同过滤算法研究”。如果读者对推荐系统很熟悉，可以知道这两篇文章的研究方向是类似的，但是它们标题中没有一样的关键词。其实，它们的关键词虽然不同，但却是相似的。“动态”和“基于时间”含义相似，“协同过滤”是“推荐系统”的一种算法。换句话说，这两篇文章的**关键词虽然不同，但关键词所属的话题是相同的**。在**这种情况下，首先需要知道文章的话题分布，然后才能准确地计算文章的相似度**。**如何建立文章、话题和关键词的关系是话题模型（topic model）研究的重点**。

- **代表性的话题模型有LDA**。

  ​	以往关于该模型的理论文章已经很多了，本书不准备讨论太多的数学问题，所以这里准备用形象的语言介绍一下LDA，并用工程师很容易懂的方法介绍这个算法。关于LDA的详细理论介绍可以参考DM Blei的论文“Latent Dirichlet Allocation”。	

  ​	任何模型都有一个假设，LDA作为一种生成模型，对一篇文档产生的过程进行了建模。**话题模型的基本思想是，一个人在写一篇文档的时候，会首先想这篇文章要讨论哪些话题，然后思考这些话题应该用什么词描述，从而最终用词写成一篇文章。因此，文章和词之间是通过话题联系的。**

- **LDA中有3种元素，即文档、话题和词语**。

  ​	**每一篇文档都会表现为词的集合，这称为词袋模型(bag of words)。每个词在一篇文章中属于一个话题。令D为文档集合，D[i]是第i篇文档。w[i][j]是第i篇文档中的第j个词。z[i][j]是第i篇文档中第j个词属于的话题**。

- **LDA的计算过程包括初始化和迭代两部分**。

  ​	首先要对z进行初始化，而初始化的方法很简单，假设一共有K个话题，那么对第i篇文章中的第j个词，可以**随机给它赋予一个话题**。同时，用NWZ(w,z)记录词w被赋予话题z的次数，NZD(z,d)记录文档d中被赋予话题z的词的个数。

  ```
  foreach document i in range(0,|D|):
    foreach word j in range(0, |D(i)|):
      z[i][j] = rand() % K
      NZD[z[i][j], D[i]]++
      NWZ[w[i][j], z[i][j]]++
      NZ[z[i][j]]++
  ```

  ​	在初始化之后，要通过迭代使话题的分布收敛到一个合理的分布上去。伪代码如下所示：

  ```
  while not converged:
    foreach document i in range(0, |D|):
      foreach word j in range(0, |D(i)|):
        NWZ[w[i][j], z[i][j]]--
        NZ[z[i][j]]--
        NZD[z[i][j], D[i]]--
        z[i][j] = SampleTopic()
        NWZ[w[i][j], z[i][j]]++
        NZ[z[i][j]]++
        NZD[z[i][j], D[i]]++
  ```

​	LDA可以很好地将词组合成不同的话题。这里我们引用David M. Blei在论文中给出的一个实验结果。他利用了一个科学论文摘要的数据集，该数据集包含16 333篇新闻，共23 075个不同的单词。通过LDA，他计算出100个话题并且在论文中给出了其中4个话题排名最高（也就是p(w|z)最大）的15个词。从图3-12所示的聚类结果可以看到，LDA可以较好地对词进行聚类，找到每个词的相关词。

![img](http://www.ituring.com.cn/figures/2012/tuijinxitongshijian/07.D%2003%20Z/image38.png)

​	**在使用LDA计算物品的内容相似度时，我们可以先计算出物品在话题上的分布，然后利用两个物品的话题分布计算物品的相似度**。比如，如果两个物品的话题分布相似，则认为两个物品具有较高的相似度，反之则认为两个物品的相似度较低。计算分布的相似度可以利用KL散度：

![img](http://www.ituring.com.cn/figures/2012/tuijinxitongshijian/07.D%2003%20Z/image39.png)

​	其中p和q是两个分布，KL散度越大说明分布的相似度越低。

## 3.5 发挥专家的作用

​	**很多推荐系统在建立时，既没有用户的行为数据，也没有充足的物品内容信息来计算准确的物品相似度。那么，为了在推荐系统建立时就让用户得到比较好的体验，很多系统都利用专家进行标注**。这方面的代表系统是个性化网络电台Pandora和电影推荐网站Jinni。

Pandora是一个给用户播放音乐的个性化电台应用。众所周知，计算音乐之间的相似度是比较困难的。首先，音乐是多媒体，如果从音频分析入手计算歌曲之间的相似度，则技术门槛很高，而且也很难计算得令人满意。其次，仅仅利用歌曲的专辑、歌手等属性信息很难获得令人满意的歌曲相似度表，因为一名歌手、一部专辑往往只有一两首好歌。为了解决这个问题，Pandora雇用了一批懂计算机的音乐人进行了一项称为音乐基因的项目。他们听了几万名歌手的歌，并对这些歌的各个维度进行标注。最终，他们使用了400多个特征（Pandora称这些特征为基因）。标注完所有的歌曲后，**每首歌都可以表示为一个400维的向量，然后通过常见的向量相似度算法可以计算出歌曲的相似度。**

​	和Pandora类似，Jinni也利用相似的想法设计了电影基因系统，让专家给电影进行标注。Jinni网站对电影基因项目进行了介绍。

​	这里的基因包括如下分类。

- 心情（Mood） 表示用户观看电影的心情，比如对于《功夫熊猫》观众会觉得很幽默，很兴奋。
- 剧情（Plot） 包括电影剧情的标签。
- 类别（Genres） 表示电影的类别，主要包括动画片、喜剧片、动作片等分类。
- 时间（Time/Period） 电影故事发生的时间。
- 地点（Place） 电影故事发生的地点。
- 观众（Audience） 电影的主要观众群。
- 获奖（Praise） 电影的获奖和评价情况。
- 风格（Style） 功夫片、全明星阵容等。
- 态度（Attitudes） 电影描述故事的态度。
- 画面（Look） 电脑拍摄的画面技术，比如《功夫熊猫》是用电脑动画制作的。
- 标记（Flag） 主要表示电影有没有暴力和色情内容。

​	Jinni在电影基因工程中采用了半人工、半自动的方式。首先，它让专家对电影进行标记，每个电影都有大约50个基因，这些基因来自大约1000个基因库。然后，在专家标记一定的样本后，Jinni会使用自然语言理解和机器学习技术，通过分析用户对电影的评论和电影的一些内容属性对电影（特别是新电影）进行自己的标记。同时，Jinni也设计了让用户对基因进行反馈的界面，希望通过用户反馈不断改进电影基因系统。

​	总之，**Jinni通过专家和机器学习相结合的方法解决了系统冷启动问题**。

# 4. 第4章 利用用户标签数据

> [推荐系统——利用用户标签数据](https://blog.csdn.net/qq_38931949/article/details/84959436)

​	**推荐系统的目的是联系用户的兴趣和物品，这种联系需要依赖不同的媒介**。GroupLens在一篇文章中表示目前流行的推荐系统基本上通过3种方式联系用户兴趣和物品。

- 第一种方式是利用用户喜欢过的物品，给用户推荐与他喜欢过的物品相似的物品，这就是前面提到的基于物品的算法。（ItemCF）
- 第二种方式是利用和用户兴趣相似的其他用户，给用户推荐那些和他们兴趣爱好相似的其他用户喜欢的物品，这是前面提到的基于用户的算法。（UserCF）
- 第三种重要的方式是通过一些**特征（feature）**联系用户和物品，给用户推荐那些具有用户喜欢的特征的物品。这里的特征有不同的表现方式，比如可以表现为物品的属性集合（比如对于图书，属性集合包括作者、出版社、主题和关键词等），也可以表现为**隐语义向量**（latent factor vector），这可以通过前面提出的隐语义模型习得到。

![img](https://img-blog.csdnimg.cn/20181211181022508.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4OTMxOTQ5,size_16,color_FFFFFF,t_70)

​	本章将讨论一种重要的特征表现方式——标签。

​	根据维基百科的定义，标签是一种无层次化结构的、用来描述信息的关键词，它可以用来描述物品的语义。根据给物品打标签的人的不同，标签应用一般分为两种：

- 一种是让**作者或者专家给物品打标签**；
- 另一种是让**普通用户给物品打标签**，也就是**UGC（User Generated Content，用户生成的内容）**的标签应用。

​	**UGC的标签系统是一种表示用户兴趣和物品语义的重要方式**。当一个用户对一个物品打上一个标签，这个标签一方面描述了用户的兴趣，另一方面则表示了物品的语义，从而将用户和物品联系了起来。

​	本章主要讨论UGC的标签应用，研究用户给物品打标签的行为，探讨如何通过分析这种行为给用户进行个性化推荐。

## 4.1 UGC 标签系统的代表应用

> [《推荐系统实践》样章：如何利用用户标签数据（一）](https://www.ituring.com.cn/article/details/725)	<=	下面4.1.X的图片基本都是来自该文章。

​	UGC标签系统是很多Web 2.0网站的必要组成部分，本节将讨论使用UGC标签系统的代表网站——UGC标签系统的鼻祖Delicious、论文书签网站CiteULike、音乐网站Last.fm、视频网站Hulu、书和电影评论网站豆瓣等。下面将分别介绍这些应用。

### 4.1.1 Delicious

​	Delicous可算是标签系统里的开山鼻祖，它允许用户给互联网上的每个网页打标签，从而通过标签重新组织整个互联网。

​	图4-2是Delicious中被用户打上recommender、system标签最多的网页，这些网页反应了用户心目中和推荐系统最相关的网页。

​	图4-3是Delicious中“豆瓣电台”这个网页被用户打的最多的标签，可以看到这些标签确实从各个角度准确地描述了“豆瓣电台”这个物品。

​	图4-2 Delicious中被打上recommender和system标签的网页

![enter image description here](https://www.ituring.com.cn/download/01K9ZcrFRRIw)

​	图4-3 Delicious中“豆瓣电台”网页被用户打的最多的标签

![enter image description here](https://www.ituring.com.cn/download/01K9ZbX64ssg)

### 4.1.2 CiteULike

​	CiteULike是一个著名的论文书签网站，它允许研究人员提交或者收藏自己感兴趣的论文并且给论文打标签，从而帮助用户更好地发现和自己研究领域相关的优秀论文。我们知道，研究人员搜索自己研究领域内值得参考的论文是很费时费力的工作，而CiteULike通过群体智能，让每个研究人员对自己了解的论文进行标记，借此帮助其他研究人员更好更快地发现自己感兴趣的论文。图4-4展示了CiteULike中一篇有关推荐系统评测的文章以及用户给这篇文章打过最多的标签，可以发现，最多的两个标签是collaborative-filtering（协同过滤）和evaluate（评测），确实比较准确地反应了这篇论文的主要内容。

​	图4-4 CiteULike中一篇论文的标签

![enter image description here](https://www.ituring.com.cn/download/01K9ZbXEOBcP)

### 4.1.3 Last.fm

​	Last.fm是一家著名的音乐网站，它通过分析用户的听歌行为预测用户对音乐的兴趣，从而给用户推荐个性化的音乐。作为多媒体，音乐不像文本那样可以很容易地分析内容信息。为了在不进行复杂音频分析的情况下获得音乐的内容信息，Last.fm引入了UGC标签系统，让用户用标签标记音乐和歌手。图4-5展示了披头士乐队在Last.fm中的标签云（tag cloud）。从这个标签云可以看到，披头士应该是一个英国（british）的传统摇滚乐队（classic rock），流行于20世纪60年代（60s）。

​	图4-5 Last.fm中披头士乐队的标签云

![enter image description here](https://www.ituring.com.cn/download/01K9ZbXLbxWe)

### 4.1.4 豆瓣

​	豆瓣是中国著名的评论和社交网站，同时也是中国个性化推荐领域的领军企业之一。豆瓣在个性化推荐领域进行了广泛尝试，标签系统也是其尝试的领域之一。它允许用户对图书和电影打标签，借此获得图书和电影的内容信息和语义，并用这种信息改善推荐效果。图4-6展示了《数据挖掘导论》在豆瓣被用户打标签的情况。如图所示，最多的几个标签分别是数据挖掘、计算机、计算机科学、数据分析、IT数据分析等。这些标签准确地概括了这本书的内容信息。

​	图4-6 豆瓣读书中《数据挖掘导论》一书的常用标签

![enter image description here](https://www.ituring.com.cn/download/01K9ZbXWVFb7)

### 4.1.5 Hulu

​	Hulu是美国著名的视频网站。视频作为一种最为复杂的多媒体，获取它的内容信息是最困难的，因此Hulu也引入了用户标签系统来让用户对电视剧和电影进行标记。图4-7展示了美剧《豪斯医生》的常用标签，可以看到，Hulu对标签做了分类并展示了每一类最热门的标签。从类型（Genre）看，《豪斯医生》是一部医学片（medical）；从时间看，这部剧开始于2004年；从人物看，这部美剧的主演是hugh laurie，他在剧中饰演的人物是greg house。

​	图4-7 Hulu中《豪斯医生》的常用标签

![enter image description here](https://www.ituring.com.cn/download/01K9ZbY7EpuU)

​	从前面的各种应用可以看到，标签系统在各种各样的（音乐、视频和社交等）网站中都得到了广泛应用。**标签系统的最大优势在于可以发挥群体的智能，获得对物品内容信息比较准确的关键词描述，而准确的内容信息是提升个性化推荐系统性能的重要资源**。

​	关于标签系统的作用， GroupLen的Shilads Wieland Sen在MoveLens电影推荐系统上做了更为深入的、基于问卷调查的研究。在博士论文中，他探讨了标签系统的不同作用，以及每种作用能够影响多大的人群，如下所示。

- 表达：标签系统帮助我表达对物品的看法。（30%的用户同意。）
- 组织：打标签帮助我组织我喜欢的电影。（23%的用户同意。）
- 学习：打标签帮助我增加对电影的了解。（27%的用户同意。）
- 发现：标签系统使我更容易发现喜欢的电影。（19%的用户同意。）
- 决策：标签系统帮助我判定是否看某一部电影。（14%的用户同意。）

​	上面的研究证明，标签系统确实能够帮助用户发现可能喜欢的电影，而这正是个性化推荐系统的使命之一。因此，本章将对如何发挥标签在个性化推荐中的作用进行深入探讨。

## 4.2 标签系统中的推荐问题

​	打标签作为一种重要的用户行为，蕴含了很多用户兴趣信息，因此深入研究和利用用户打标签的行为可以很好地指导我们改进个性化推荐系统的推荐质量。同时，**标签的表示形式非常简单，便于很多算法处理**。

​	标签系统中的推荐问题主要有以下两个。

- 如何利用用户打标签的行为为其推荐物品（基于标签的推荐）？
- 如何在用户给物品打标签时为其推荐适合该物品的标签（标签推荐）？

​	为了研究上面的两个问题，我们首先需要解答下面3个问题。

- **用户为什么要打标签？**
- **用户怎么打标签？**
- **用户打什么样的标签？**

### 4.2.1 用户为什么进行标注

​	在设计基于标签的个性化推荐系统之前，我们需要深入了解用户的标注行为（即打标签的行为），知道用户为什么要标注，用户怎么标注，只有深入了解用户的行为，我们才能基于这个行为设计出令他们满意的个性化推荐系统。

​	Morgan Ames研究图片分享网站中用户标注的动机问题，并从两个维度进行探讨。

- 首先是社会维度，有些用户标注是给内容上传者使用的（便于上传者组织自己的信息），而有些用户标注是给广大用户使用的（便于帮助其他用户找到信息）。
- 另一个维度是功能维度，有些标注用于更好地组织内容，方便用户将来的查找，而另一些标注用于传达某种信息，比如照片的拍摄时间和地点等。

### 4.2.2 用户如何打标签

> [推荐系统（四）——利用用户标签数据](https://zhuanlan.zhihu.com/p/47556784)

​	在互联网中，尽管每个用户的行为看起来是随机的，但其实这些表面随机的行为背后蕴含着很多规律。这一节将通过研究Delicious数据集总结用户标注行为中的一些统计规律。

​	德国研究人员公布过一个很庞大的Delicious数据集，该数据集包含2003年9月到2007年12月Delicious用户4.2亿条标签行为记录。本节选用该数据集2007年一个月的数据进行分析，对该数据集的统计特性进行研究。

​	前面几章都提到，**用户行为数据集中用户活跃度和物品流行度的分布都遵循长尾分布（PowerLaw分布）**。因此，我们首先看一下标签流行度的分布。我们定义的一个标签被一个用户使用在一个物品上，它的流行度就加一。如下代码计算了每个标签的流行度。

```
def TagPopularity(records):
  tagfreq = dict()
  for user,item,tag in records:
    if tag not in tagfreq:
      tagfreq[tag] = 1
    else:
      tagfreq[tag] += 1
  return tagfreq
```

​	如图4-8所示，横坐标是流行度k，纵坐标是数据集中流行度为k的标签总数n(k)。标签的流行度分布也呈现非常典型的长尾分布，它的双对数曲线几乎是一条直线。





​	图4-8 标签流行度的长尾分布

![img](https://pic3.zhimg.com/80/v2-35695fdc624009809fdad9b831ea87d6_1440w.jpg)

### 4.2.3 用户打什么样的标签

> [推荐系统（四）——利用用户标签数据](https://zhuanlan.zhihu.com/p/47556784)

​	在用户看到一个物品时，我们希望他打的标签是能够准确描述物品内容属性的关键词，但用户往往不是按照我们的想法操作，而是可能会给物品打上各种各样奇奇怪怪的标签。

​	Scott A. Golder 总结了Delicious上的标签，将它们分为如下几类。

- **表明物品是什么**：比如是一只鸟，就会有“鸟”这个词的标签；是豆瓣的首页，就有一个标签叫“豆瓣”；是乔布斯的首页，就会有个标签叫“乔布斯”。

- **表明物品的种类**：比如在Delicious的书签中，表示一个网页类别的标签包括 article（文章）、blog（博客）、 book（图书）等。

- **表明谁拥有物品**：比如很多博客的标签中会包括博客的作者等信息。

- **表达用户的观点**：比如用户认为网页很有趣，就会打上标签funny（有趣），认为很无聊，就会打上标签boring（无聊）。

- **用户相关的标签**：比如 my favorite（我最喜欢的）、my comment（我的评论）等。

- **用户的任务**：比如 to read（即将阅读）、job search（找工作）等。

​	很多不同的网站也设计了自己的标签分类系统，比如Hulu对视频的标签就做了分类。图4-9是著名的美剧《豪斯医生》的标签。可以看到，Hulu将电视剧的标签分成了如下几类。

​	图4-9 著名美剧《豪斯医生》在视频网站Hulu上的标签分类

![img](https://pic2.zhimg.com/80/v2-d8f3316262a0b65ff1a17d0437eae239_1440w.jpg)

+ 类型（Genre）：主要表示这个电视剧的类别，比如《豪斯医生》属于医学剧情片（medical drama）。

+ 时间（Time）：主要包括电视剧发布的时间，有时也包括电视剧中事件发生的时间，比如20世纪90年代。

+ 人物（People）：主要包括电视剧的导演、演员和剧中重要人物等。

+ 地点（Place）：剧情发生的地点，或者视频拍摄的地点等。

+ 语言（Language）：这部电视剧使用的语言。

+ 奖项（Awards）：这部电视剧获得的相关奖项。

+ 其他（Details）：包含不能归类到上面各类中的其他所有标签。

## 4.3 基于标签的推荐系统

​	**用户用标签来描述对物品的看法，因此标签是联系用户和物品的纽带，也是反应用户兴趣的重要数据源，如何利用用户的标签数据提高个性化推荐结果的质量是推荐系统研究的重要课题**。

​	豆瓣很好地利用了标签数据，它将标签系统融入到了整个产品线中。首先，在每本书的页面上，豆瓣都提供了一个叫做“豆瓣成员常用标签”的应用，它给出了这本书上用户最常打的标签。同时，在用户给书做评价时，豆瓣也会让用户给图书打标签。最后，**在最终的个性化推荐结果里，豆瓣利用标签将用户的推荐结果做了聚类，显示了对不同标签下用户的推荐结果，从而增加了推荐的多样性和可解释性**。

​	**一个用户标签行为的数据集一般由一个三元组的集合表示，其中记录(u, i, b) 表示用户u给物品i打上了标签b**。当然，用户的真实标签行为数据远远比三元组表示的要复杂，比如用户打标签的时间、用户的属性数据、物品的属性数据等。但是本章为了集中讨论标签数据，只考虑上面定义的三元组形式的数据，即用户的每一次打标签行为都用一个三元组（用户、物品、标签）表示。

​	本章将采用两个不同的数据集评测**基于标签的物品推荐算法**。

​	一个是Delicious数据集，另一个是CiteULike数据集。Delicious数据集中包含用户对网页的标签记录。它每一行由4部分组成，即时间、用户ID、网页URL、标签。本章只抽取了其中用户对一些著名博客网站网页（Wordpress、BlogSpot、TechCrunch）的标签记录。CiteULike数据集包含用户对论文的标签记录，它每行也由4部分组成，即物品ID、用户ID、时间、标签，本章选取了其中稠密的部分。最终两个数据集的统计信息如表4-1所示，其最热门的20个标签见表4-2（这个没找到图，算了）。

![img](https://pic1.zhimg.com/80/v2-a8fdb4b8db01266505d655c948e74f8c_1440w.jpg)

### 4.3.1 实验设置

> 这部分还是看书了解下流程即可

​	本节将数据集随机分成10份。这里分割的键值是用户和物品，不包括标签。也就是说，用户对物品的多个标签记录要么都被分进训练集，要么都被分进测试集，不会一部分在训练集，另一部分在测试集中。然后，我们挑选1份作为测试集，剩下的9份作为训练集，通过学习训练集中的用户标签数据预测测试集上用户会给什么物品打标签。

​	对于用户u，令R(u)为给用户u的长度为N的推荐列表，里面包含我们认为用户会打标签的物品。令T(u)是测试集中用户u实际上打过标签的物品集合。然后，我们利用准确率（precision）和召回率（recall）评测个性化推荐算法的精度。

​	**推荐系统的多样性为所有用户推荐列表多样性的平均值**。

...

### 4.3.2 一个最简单的算法

​	拿到了用户标签行为数据，相信大家都可以想到一个最简单的个性化推荐算法。这个算法的描述如下所示。

+ 统计每个用户最常用的标签。

+ 对于每个标签，统计被打过这个标签次数最多的物品。

+ 对于一个用户，首先找到他常用的标签，然后找到具有这些标签的最热门物品推荐给这个用户。

​	对于上面的算法，用户u对物品i的兴趣公式如下：

![[公式]](https://www.zhihu.com/equation?tex=p%28u%2C+i%29+%3D+%5Csum_%7Bb%7Dn_%7Bu%2Cb%7D%5C+n_%7Bb%2Ci%7D)

​	这里，B(u)是用户u打过的标签集合，B(i)是物品i被打过的标签集合， ![[公式]](https://www.zhihu.com/equation?tex=n_%7Bu%2Cb%7D) 是用户u打过标签b 的次数， ![[公式]](https://www.zhihu.com/equation?tex=n_%7Bb%2C+i%7D) 是物品i被打过标签b的次数。

​	在Python中，我们遵循如下约定：

+ 用 records 存储标签数据的三元组，其中records[i] = [user, item, tag];

+ 用 user_tags 存储 n<sub>u,b</sub>，其中user_tags\[u]\[b] = n<sub>u,b</sub>;

+ 用 tag_items存储 n<sub>b,i</sub>，其中tag_items\[b]\[i] = n<sub>b,i</sub>。

​	如下程序可以从records中统计出user_tags和tag_items：

```python
def InitStat(records):
  user_tags = dict()
  tag_items = dict()
  user_items = dict()
  for user, item, tag in records.items():
    addValueToMat(user_tags, user, tag, 1)
    addValueToMat(tag_items, tag, item, 1)
    addValueToMat(user_items, user, item, 1)
```

​	统计出user_tags和tag_items之后，我们可以通过如下程序对用户进行个性化推荐：

```python
def Recommend(user):
  recommend_items = dict()
  tagged_items = user_items[user]
  for tag, wut in user_tags[user].items():
    for item, wti in tag_items[tag].items():
      #if items have been tagged, do not recommend them
      if item in tagged_items:
        continue
      if item not in recommend_items:
        recommend_items[item] = wut * wti
      else:
        recommend_items[item] += wut * wti
  return recommend_items
```

​	我们在Delicious数据集上对上面的算法进行评测，结果如表4-3所示。

​	表4-3 基于标签的简单推荐算法在Delicious数据集上的评测结果

![img](https://pic1.zhimg.com/80/v2-a8fdb4b8db01266505d655c948e74f8c_1440w.jpg)

### 4.3.3 算法的改进

> 这部分看书即可

#### 1. TF-IDF

#### 2. 数据稀疏性

​	为了提高推荐的准确率，我们可能要对标签集合做扩展，比如若用户曾经用过“推荐系统”这个标签，我们可以将这个标签的相似标签也加入到用户标签集合中，比如“个性化”、“协同过滤”等标签。

​	进行标签扩展有很多方法，其中常用的有话题模型（topic model），不过这里遵循简单的原则介绍一种基于邻域的方法。

​	标签扩展的本质是对每个标签找到和它相似的标签，也就是计算标签之间的相似度。最简单的相似度可以是同义词。如果有一个同义词词典，就可以根据这个词典进行标签扩展。如果没有这个词典，我们可以从数据中统计出标签的相似度。

​	**如果认为同一个物品上的不同标签具有某种相似度，那么当两个标签同时出现在很多物品的标签集合中时，我们就可以认为这两个标签具有较大的相似度**。

#### 3. 标签清理

​	**不是所有标签都能反应用户的兴趣**。比如，在一个视频网站中，用户可能对一个视频打了一个表示情绪的标签，比如“不好笑”，但我们不能因此认为用户对“不好笑”有兴趣，并且给用户推荐其他具有“不好笑”这个标签的视频。相反，如果用户对视频打过“成龙”这个标签，我们可以据此认为用户对成龙的电影感兴趣，从而给用户推荐成龙其他的电影。同时，标签系统里经常出现词形不同、词义相同的标签，比如recommender system和recommendation engine就是两个同义词。

​	**标签清理的另一个重要意义在于将标签作为推荐解释**。如果我们要把标签呈现给用户，将其作为给用户推荐某一个物品的解释，对标签的质量要求就很高。首先，这些标签不能包含没有意义的停止词或者表示情绪的词，其次这些推荐解释里不能包含很多意义相同的词语。

​	一般来说有如下标签清理方法：

+ **去除词频很高的停止词**；

+ **去除因词根不同造成的同义词**，比如 recommender system和recommendation system；

+ **去除因分隔符造成的同义词**，比如 collaborative_filtering和collaborative-filtering。

​	为了控制标签的质量，很多网站也采用了让用户进行反馈的思想，即让用户告诉系统某个标签是否合适。MovieLens在实验系统中就采用了这种方法。关于这方面的研究可以参考GroupLens的Shilad Wieland Sen同学的博士论文。此外，电影推荐网站Jinni也采用了这种方式（如图4-10所示）。当然，Jinni不属于**UGC**的标签系统，它给电影的标签是专家赋予的，因此它让用户对标签进行反馈其实是想融合专家和广大用户的知识。

​	图4-10 Jinni让用户对编辑给的标签进行反馈

![img](https://pic4.zhimg.com/80/v2-f59e4fd55aa3e5756dd86c82f9cf8f13_1440w.jpg)

### 4.3.4 基于图的推荐算法

> 这里看书效果好点

​	前面讨论的简单算法很容易懂，也容易实现，但缺点是不够系统化和理论化。因此，在这一节中我们主要讨论如何利用图模型做基于标签数据的个性化推荐。

#### 用图模型解释前面的简单算法

### 4.3.5 基于标签的推荐解释

> [推荐系统（四）——利用用户标签数据](https://zhuanlan.zhihu.com/p/47556784)

​	**基于标签的推荐其最大好处是可以利用标签做推荐解释**，这方面的代表性应用是豆瓣的个性化推荐系统。图4-13展示了豆瓣读书的个性化推荐界面。

​	图4-13 豆瓣读书的个性化推荐应用“豆瓣猜”的界面

![img](https://pic2.zhimg.com/80/v2-9af42309ba9ca8181c658bb6a2d4c9ed_1440w.jpg)

​	如图4-13所示，豆瓣读书推荐结果包括两部分。上面是一个标签云，表示用户的兴趣分布，标签的尺寸越大，表示用户对这个标签相关的图书越感兴趣。

​	豆瓣这样组织推荐结果页面有很多好处，首先是提高了推荐结果的多样性。我们知道，**一个用户的兴趣在长时间内是很广泛的，但在某一天却比较具体**。因此，我们如果想在某一天击中用户当天的兴趣，是非常困难的。而豆瓣通过标签云，展示了用户的所有兴趣，然后让用户自己根据他今天的兴趣选择相关的标签，得到推荐结果，从而极大地提高了推荐结果的多样性，使得推荐结果更容易满足用户多样的兴趣。

​	同时，标签云也提供了推荐解释功能。用户通过这个界面可以知道豆瓣给自己推荐的每一本书都是基于它认为自己对某个标签感兴趣。而对于每个标签，用户总能通过回忆自己之前的行为知道自己是否真的对这个标签感兴趣。

​	我们知道，要让用户直观上感觉推荐结果有道理是很困难的，而豆瓣将推荐结果的可解释性拆分成了两部分，首先让用户觉得标签云是有道理的，然后让用户觉得从某个标签推荐出某本书也是有道理的。因为生成让用户觉得有道理的标签云比生成让用户觉得有道理的推荐图书更加简单，标签和书的关系就更容易让用户觉得有道理，从而让用户最终觉得推荐出来的书也是很有道理的。

​	GroupLens的研究人员Jesse Vig对基于标签的解释进行了深入研究。和4.3.2节提出的算法类似，Jesse Vig**将用户和物品之间的关系变成了用户对标签的兴趣（tag preference）和标签与物品的相关度（tag relevance）**。

​	...

​	总结问卷调查的结果，作者得出了以下结论：

+ **用户对标签的兴趣对帮助用户理解为什么给他推荐某个物品更有帮助**；

+ **用户对标签的兴趣和物品标签相关度对于帮助用户判定自己是否喜欢被推荐物品具有同样的作用**；

+ **物品标签相关度对于帮助用户判定被推荐物品是否符合他当前的兴趣更有帮助**；

+ **客观事实类标签相比主观感受类标签对用户更有作用**。

## 4.4 给用户推荐标签

​	当用户浏览某个物品时，标签系统非常希望用户能够给这个物品打上高质量的标签，这样才能促进标签系统的良性循环。因此，很多标签系统都**设计了标签推荐模块给用户推荐标签**。图4-14展示了音乐网站Last.fm和豆瓣的标签推荐系统。

​	图4-14 Last.fm（左）和豆瓣（右）的标签推荐系统界面

![img](https://pic3.zhimg.com/80/v2-7e65053222f49a3c706bbf4376ecc18e_1440w.jpg)

### 4.4.1 为什么要给用户推荐标签

​	在讨论如何给用户推荐标签之前，首先需要了解为什么要给用户推荐标签。一般认为，给用户推荐标签有以下好处。

+ **方便用户输入标签** 让用户从键盘输入标签无疑会增加用户打标签的难度，这样很多用户不愿意给物品打标签，因此我们需要一个辅助工具来减小用户打标签的难度，从而提高用户打标签的参与度。

+ **提高标签质量** 同一个语义不同的用户可能用不同的词语来表示。这些同义词会使标签的词表变得很庞大，而且会使计算相似度不太准确。而使用推荐标签时，我们可以对词表进行选择，首先**保证词表不出现太多的同义词，同时保证出现的词都是一些比较热门的、有代表性的词**。

### 4.4.2 如何给用户推荐标签

​	用户u给物品i打标签时，我们有很多方法可以给用户推荐和物品i相关的标签。比较简单的方法有4种。

​	第0种方法就是**给用户u推荐整个系统里最热门的标签**（这里将这个算法称为PopularTags），之所以称为第0种，是因为这个算法太简单了，以至于不能称为一种标签推荐算法。令tags[b]为标签b的热门程度，那么这个算法的实现如下：

```python
def RecommendPopularTags(user,item, tags, N):
  return sorted(tags.items(), key=itemgetter(1), reverse=True)[0:N]
```

​	第1种方法就是**给用户u推荐物品i上最热门的标签**（这里将这个算法称为ItemPopularTags）。令item_tags\[i]\[b]为物品i被打上标签b的次数，那么这个算法的实现很简单，具体如下所示：

```python
def RecommendItemPopularTags(user,item, item_tags, N):
  return sorted(item_tags[item].items(), key=itemgetter(1), reverse=True)[0:N]
```

​	第2种方法是**给用户u推荐他自己经常使用的标签**（这里将这个算法称为UserPopularTags）。令user_tags\[u]\[b]为用户u使用标签b的次数，那么这个算法的实现如下所示：

```python
def RecommendUserPopularTags(user,item, user_tags, N):
  return sorted(user_tags[user].items(), key=itemgetter(1), reverse=True)[0:N]
```

​	第3种算法是前面两种的融合（这里记为HybridPopularTags），该方法通过一个系数将上面的推荐结果线性加权，然后生成最终的推荐结果。这个算法的实现代码如下：

```python
def RecommendHybridPopularTags(user,item, user_tags, item_tags, alpha, N):
  max_user_tag_weight = max(user_tags[user].values())
  for tag, weight in user_tags[user].items():
    ret[tag] = (1 – alpha) * weight / max_user_tag_weight
  max_item_tag_weight = max(item_tags[item].values())
  for tag, weight in item_tags[item].items():
    if tag not in ret:
      ret[tag] = alpha * weight / max_item_tag_weight
    else:
      ret[tag] += alpha * weight / max_item_tag_weight
  return sorted(ret[user].items(), key=itemgetter(1), reverse=True)[0:N]
```

​	注意在上面的实现中，我们在将两个列表线性相加时都将两个列表按最大值做了归一化，这样的好处是便于控制两个列表对最终结果的影响，而**不至于因为物品非常热门而淹没用户对推荐结果的影响，或者因为用户非常活跃而淹没物品对推荐结果的影响**。

### 4.4.3 实验设置

> 具体实验过程，看书实在点。

​	**很多应用在给用户推荐标签时会直接给出用户最常用的标签，以及物品最经常被打的标签**。

​	比如豆瓣（如图4-15所示），在书籍作者浏览《MongoDB权威指南》一书时，它给作者推荐的标签分为两类。一类是我的标签，即我之前常用的标签，可以看到这一类中包含诸如历史、传记等和MongoDB毫无关系的标签。另一类是常用标签，即别的用户给MongoDB打的最多的标签，可以看到这里面所有的标签都是和MongoDB相关的。

![img](https://pic3.zhimg.com/80/v2-cf2609d9ca0a7b72564f68c6ccc0cfe6_1440w.jpg)

​	不过，前面提到的**基于统计用户常用标签和物品常用标签的算法有一个缺点，就是对新用户或者不热门的物品很难有推荐结果**。解决这一问题有两个思路。

​	第一个思路：是**从物品的内容数据中抽取关键词作为标签**。这方面的研究很多，特别是在上下文广告领域。本书3.4节也介绍了生成关键词向量的一些方法。

​	第二个思路：是针对有结果，但结果不太多的情况。比如《MongoDB权威指南》一书只有一个用户曾经给它打过一个标签nosql，这个时刻可以做一些关键词扩展，加入一些和nosql相关的标签，比如数据库、编程等。**实现标签扩展的关键就是计算标签之间的相似度**。关于这一点，4.3.3节已经进行了深入探讨。

### 4.4.4 基于图的标签推荐算法

> [推荐系统实践》第四章 利用用户标签数据](https://blog.csdn.net/cuicuicuicuicuih/article/details/105554266)

​	**图模型同样可以用于标签推荐**。在根据用户打标签的行为生成图之后（如图4-11所示），我们可以利用PersonalRank算法进行排名。但这次遇到的问题和之前不同。这次的问题是，当用户u遇到物品i时，会给物品i打什么样的标签。因此，我们可以重新定义顶点的启动概率，如下所示：

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200416162125164.png)

​	也就是说，只有用户u和物品i对应的顶点有非0的启动概率，而其他顶点的启动概率都为0。在上面的定义中，v(u)和v(i)的启动概率并不相同，v(u)的启动概率是a，而v(i)的启动概率是1-a。参数α可以通过离线实验选择。

## 4.5 扩展阅读

​	本章主要讨论了UGC标签在推荐系统中的应用。标签作为描述语义的重要媒介，无论是对于描述用户兴趣还是表示物品的内容都有很重要的意义。标签在推荐系统中的应用主要集中在两个问题上，一个是**如何利用用户打标签的行为给用户推荐物品**，另一个是**如何给用户推荐标签**。本章在深入分析用户标签行为的基础上对这两个问题进行了深入探讨。

​	关于标签的问题，最近几年在学术界获得了广泛关注。ECML/PKDD在2008年曾经推出过基于标签的推荐系统比赛。在这些研究中涌现了很多新的方法，比如张量分解（tensorfactorization）、基于LDA的算法、基于图的算法等。不过这些算法很多具有较高的复杂度，在实际系统中应用起来还有很多实际的困难需要解决。

​	GroupLens的研究人员给MovieLens系统做了很多标签方面的工作。Shilad Sen在论文中研究了如何利用标签联系用户和物品并给用户进行个性化电影推荐。Jesse Vig在论文中研究了如何利用标签进行推荐解释，他将用户和物品之间的关系转化为用户对标签的兴趣（tag preference）以及标签和物品的相关度（tag relevance）两种因素。同时他们研究了如何对标签进行清理，以及如何选择合适的标签进行解释。

# 5. 第5章 利用上下文信息

