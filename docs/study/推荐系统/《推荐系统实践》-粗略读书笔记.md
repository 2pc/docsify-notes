# 《推荐系统实践》-粗略读书笔记

> 为推荐系统的搭建做准备，时间比较紧迫，暂时不细读了。
> 下面关于公式、代码的部分，没有找到现成的图，手敲麻烦意义不大，需要时看书、上网查找即可。

# 1. 第1章 好的推荐

## 1.1 什么是推荐系统

+ 推荐系统的基本任务是联系用户和物品，解决信息过载的问题

+ 从物品的角度出发，推荐系统可以更好地发掘物品的长尾（long tail）。主流商品代表绝大多数用户的需求，而长尾商品代表**少数人的个性化需求**。推荐系统通过发掘用户的行为，找到用户的个性化需求，从而将长尾商品准确地推荐给需要它的用户，帮助用户发现那些他们感兴趣但很难发现的商品。

+ 常见的几种推荐方式

  + 社会化推荐（social recommendation）

    用户间推荐

  + 基于内容的推荐 （content-based filtering）

    根据用户历史兴趣推荐类似内容

  + 基于协同过滤的推荐（collaborative filtering）

    给用户推荐兴趣相似的用户所感兴趣的内容

## 1.2 个性化推荐系统的应用

​	个性化推荐系统通过**分析大量用户行为日志**，给不同用户提供不同的个性化页面展示，来提高网站的点击率和转化率。

​	几乎所有的推荐系统应用都是由三部分构成：

+ **前台的展示页面**
+ **后台的日志系统**
+ **推荐算法系统**

### 1.2.1 电子商务

1. 亚马逊个性化推荐系统列表

   **基于物品推荐**

   + 推荐结果的标题、缩略图以及其他内容属性
   + 推荐结果的平均分
   + 推荐理由

### 1.2.2 电影和视频网站

1. Netflix电影推荐界面

   **基于物品推荐**

   + 电影的标题和海报
   + 用户反馈模块——包括Play（播放）、评分和Not Interested（不感兴趣）3种
   + 推荐理由——因为用户曾经喜欢过别的电影

### 1.2.3 个性化音乐网络电台

个性化推荐的成功应用需要两个条件：

1. 信息过载。因为如果用户可以很容易地从所有物品中找到喜欢的物品，就不需要个性化推荐了。
2. 用户大部分时候没有特别明确的需求。用户如果有明确的需求，可直接通过搜索引擎找到感兴趣的物品。

著名个性化音乐推荐产品：Pandora、Last.fm、豆瓣电台

Last.fm记录了所有用户的听歌记录以及用户对歌曲的反馈，在这一基础上计算出不同用户在歌曲上的喜好相似度，从而给用户推荐和他有相似听歌爱好的其他用户喜欢的歌曲。

​	音乐推荐是推荐系统里非常特殊的领域。2011年的Recsys大会专门邀请了Pandora的研究人员对音乐推荐进行了演讲。演讲人总结了音乐推荐的如下特点。

+ 物品空间大 物品数很多，物品空间很大，这主要是相对于书和电影而言。

+ 消费每首歌的代价很小 对于在线音乐来说，音乐都是免费的，不需要付费。

+ 物品种类丰富 音乐种类丰富，有很多的流派。

+ 听一首歌耗时很少 听一首音乐的时间成本很低，不太浪费用户的时间，而且用户大都把音乐作为背景声音，同时进行其他工作。

+ 物品重用率很高 每首歌用户会听很多遍，这和其他物品不同，比如用户不会反复看一个电影，不会反复买一本书。

+ 用户充满激情 用户很有激情，一个用户会听很多首歌。

+ 上下文相关 用户的口味很受当时上下文的影响，这里的上下文主要包括用户当时的心情（比如沮丧的时候喜欢听励志的歌曲）和所处情境（比如睡觉前喜欢听轻音乐）。

+ 次序很重要 用户听音乐一般是按照一定的次序一首一首地听。

+ 很多播放列表资源 很多用户都会创建很多个人播放列表。

+ 不需要用户全神贯注 音乐不需要用户全神贯注地听，很多用户将音乐作为背景声音。

+ 高度社会化

### 1.2.4 社交网络

代表：Twitter、FaceBook

社交网络中的个性化推荐技术主要应用在3个方面：

+ 利用用户的社交网络信息对用户进行个性化的物品推荐；

+ 信息流的会话推荐；

+ 给用户推荐好友。

### 1.2.5 个性化阅读

​	目前互联网上的个性化阅读工具很多，国际知名的有Google Reader，国内有鲜果网等。

+ Google Reader是一款流行的社会化阅读工具。它允许用户关注自己感兴趣的人，然后看到所关注用户分享的文章。
+ 个性化阅读工具Zite则是收集用户对文章的偏好信息。
+ Digg首先根据用户的Digg历史计算用户之间的兴趣相似度，然后给用户推荐和他兴趣相似的用户喜欢的文章。

### 1.2.6 基于位置的服务

+ Foursquare推出了探索功能，给用户推荐好友在附近的情况

### 1.2.7 个性化邮件

+ 推荐系统Tapestry，协同过滤筛选信息，通过分析用户阅读邮件的历史行为和习惯对新邮件进行重新排序，从而提高用户的工作效率。
+ 谷歌的研究人员在这个问题上也进行了深入研究，于2010年推出了优先级收件箱功能。该产品通过分析用户对邮件的历史行为，找到用户感兴趣的邮件，展示在一个专门的收件箱里。用户每天可以先浏览这个邮箱里的邮件，再浏览其他邮件。

### 1.2.8 个性化广告

> [网络广告中，CPC、CPA、CPM 的定义各是怎样的？](https://www.zhihu.com/question/20416888)
>
> 1. CPM（Cost Per Mille） ：展现成本，或者叫千人展现成本
> 2. CPC（Cost Per Click） 点击成本，即每产生一次点击所花费的成本
> 3. CPA（Cost Per Action）：每行动成本。即按行动收费

​	广告是互联网公司生存的根本。很多互联网公司的盈利模式都是基于广告的，而广告的CPC、CPM直接决定了很多互联网公司的收入。

​	个性化广告投放和狭义个性化推荐的区别是，个性化推荐着重于帮助用户找到可能令他们感兴趣的物品，而**广告推荐着重于帮助广告找到可能对它们感兴趣的用户**，即一个是以用户为核心，而另一个以广告为核心。目前的个性化广告投放技术主要分为3种。

+  上下文广告 通过分析用户正在浏览的网页内容，投放和网页内容相关的广告。代表系统是谷歌的Adsense。

+ 搜索广告 通过分析用户在当前会话中的搜索记录，判断用户的搜索目的，投放和用户目的相关的广告。

+ 个性化展示广告 我们经常在很多网站看到大量展示广告（就是那些大的横幅图片），它们是根据用户的兴趣，对不同用户投放不同的展示广告。雅虎是这方面研究的代表。

## 1.3 推荐系统评测

> 看到这就想到最近美团爆出杀熟的操作。三方共赢这种美好的愿望还是想想就好，哈哈。

​	一个完整的推荐系统一般存在3个参与方：

+ 用户
+ 物品提供者
+ 提供推荐系统的网站

​	在评测一个推荐算法时，需要同时考虑三方的利益，一个好的推荐系统是能够令三方共赢的系统。

### 1.3.1 推荐系统实验方法

在推荐系统中，主要有3种评测推荐效果的实验方法：

+ 离线实验（offline experiment）
+ 用户调查（user study）
+ 在线实验（online experiment）

#### 1. 离线实验

离线实验的方法一般由如下几个步骤构成：

1. 通过日志系统获得用户行为数据，并按照一定格式生成一个标准的数据集；

2. 将数据集按照一定的规则分成训练集和测试集；

3. 在训练集上训练用户兴趣模型，在测试集上进行预测；

4. 通过事先定义的离线指标评测算法在测试集上的预测结果。

从上面的步骤可以看到，**推荐系统的离线实验都是在数据集上完成的**，也就是说它不需要一个实际的系统来供它实验，而只要有一个从实际系统日志中提取的数据集即可。这种实验方法的好处是不需要真实用户参与，可以直接快速地计算出来，从而方便、快速地测试大量不同的算法。

它的**主要缺点是无法获得很多商业上关注的指标，如点击率、转化率等**，而找到和商业指标非常相关的离线指标也是很困难的事情。

| 优点                     | 缺点                             |
| ------------------------ | -------------------------------- |
| 不需要对实际系统的控制权 | 无法计算商业上关心的指标         |
| 不需要用户参与实验       | 离线实验的指标和商业指标存在差异 |
| 速度快，可以测试大量算法 |                                  |

#### 2. 用户调查

​	注意，离线实验的指标和实际的商业指标存在差距，比如预测准确率和用户满意度之间就存在很大差别，**高预测准确率不等于高用户满意度**。

​	用户调查的优缺点也很明显。它的优点是可以获得很多体现用户主观感受的指标，相对在线实验风险很低，出现错误后很容易弥补。缺点是招募测试用户代价较大，很难组织大规模的测试用户，因此会使测试结果的统计意义不足。此外，在很多时候设计双盲实验非常困难，而且用户在测试环境下的行为和真实环境下的行为可能有所不同，因而在测试环境下收集的测试指标可能在真实环境下无法重现。

#### 3. 在线实验

> [黄一能：什么是科学的AB测试？谈谈分层实验和流量正交 ](https://www.sohu.com/a/343208894_713733)
>
> 科学的AB实验要求保证每次实验只有一个变量，各组其他所有元素都必须保持一致。如果每个变量都独立切分流量会大大制约实验的效率，一是实验流量变少，得出显著结果的时间会拉长。二是可以并行的实验量受到了制约。如果不切分流量实验，无法验证效果的变化究竟是那个改动带来的。
>
> [AB测试中两个常见的问题，谈谈流量分层和置信度](https://zhuanlan.zhihu.com/p/108317075)

​	在完成离线实验和必要的用户调查后，可以将推荐系统上线做**AB测试**，将它和旧的算法进行比较。

​	AB测试是一种很常用的在线评测算法的实验方法。它通过一定的规则将用户随机分成几组，并对不同组的用户采用不同的算法，然后通过统计不同组用户的各种不同的评测指标比较不同算法，比如可以统计不同组用户的点击率，通过点击率比较不同算法的性能。

​	网站http://www.abtests.com/，给出了很多通过实际AB测试提高网站用户满意度的例子，从中我们可以学习到如何进行合理的AB测试。

​	**AB测试的优点是可以公平获得不同算法实际在线时的性能指标**，包括商业上关注的指标。AB测试的**缺点主要是周期比较长**，必须进行长期的实验才能得到可靠的结果。因此一般不会用AB测试测试所有的算法，而只是用它测试那些在离线实验和用户调查中表现很好的算法。

​	切分流量是AB测试中的关键，不同的层以及控制这些层的团队需要从一个统一的地方获得自己AB测试的流量，而不同层之间的流量应该是正交的。

​	<small>下图是一个简单的AB测试系统。用户进入网站后，流量分配系统决定用户是否需要被进行AB测试，如果需要的话，流量分配系统会给用户打上在测试中属于什么分组的标签。然后用户浏览网页，而用户在浏览网页时的行为都会被通过日志系统发回后台的日志数据库。此时，如果用户有测试分组的标签，那么该标签也会被发回后台数据库。在后台，实验人员的工作首先是配置流量分配系统，决定满足什么条件的用户参加什么样的测试。其次，实验人员需要统计日志数据库中的数据，通过评测系统生成不同分组用户的实验报告，并比较和评测实验结果。</small>

![img](http://www.ituring.com.cn/figures/2012/tuijinxitongshijian/05.D%2001%20Z/image23.png)



----

一般来说，一个新的推荐算法最终上线，需要完成上面所说的3个实验。

+ 首先，需要通过离线实验证明它在很多离线指标上优于现有的算法。
+ 然后，需要通过用户调查确定它的用户满意度不低于现有的算法。

+ 最后，通过在线的AB测试确定它在我们关心的指标上优于现有的算法。

### 1.3.2 评测指标

#### 1. 用户满意度

​	用户满意度没有办法离线计算，只能通过用户调查或者在线实验获得。

​	用户调查获得用户满意度主要是通过调查问卷的形式。而在线系统中，用户满意度主要通过一些对用户行为的统计得到。更一般的情况下，我们可以用点击率、用户停留时间和转化率等指标度量用户的满意度。

#### 2. 预测准确度

​	预测准确度度量一个推荐系统或者推荐算法预测用户行为的能力。该指标可以通过离线实验计算。

​	在计算该指标时需要有一个离线的数据集，该数据集包含用户的历史行为记录。然后，将该数据集通过时间分成训练集和测试集。最后，通过在训练集上建立用户的行为和兴趣模型预测用户在测试集上的行为，并计算预测行为和测试集上实际行为的重合度作为预测准确度。

##### 评分预测

​	预测用户对物品评分的行为称为评分预测。

##### TopN推荐

​	网站在提供推荐服务时，一般是给用户一个个性化的推荐列表，这种推荐叫做**TopN推荐**。TopN推荐的预测准确率一般通过准确率（precision）/召回率（recall）度量。

​	有的时候，为了全面评测TopN推荐的准确率和召回率，一般会选取不同的推荐列表长度N，计算出一组准确率/召回率，然后画出准确率/召回率曲线（precision/recall curve）。

##### 关于评分预测和TopN推荐的讨论

​	评分预测一直是推荐系统研究的热点，绝大多数推荐系统的研究都是基于用户评分数据的评分预测。

#### 3. 覆盖率

> [请问什么是基尼系数，怎样计算出来的？](https://zhidao.baidu.com/question/1797381608016293707.html)

​	覆盖率（coverage）描述一个推荐系统对物品长尾的发掘能力。覆盖率是一个内容提供商会关心的指标。

​	以图书推荐为例，出版社可能会很关心他们的书有没有被推荐给用户。覆盖率为100%的推荐系统可以将每个物品都推荐给至少一个用户。此外，从上面的定义也可以看到，热门排行榜的推荐覆盖率是很低的，它只会推荐那些热门的物品，这些物品在总物品中占的比例很小。一个好的推荐系统不仅需要有比较高的用户满意度，也要有较高的覆盖率。

​	可以通过研究物品在推荐列表中出现次数的分布描述推荐系统挖掘长尾的能力。如果这个分布比较平，那么说明推荐系统的覆盖率较高，而如果这个分布较陡峭，说明推荐系统的覆盖率较低。

​	社会学领域有一个著名的**马太效应，即所谓强者更强，弱者更弱的效应**。如果一个系统会增大热门物品和非热门物品的流行度差距，让热门的物品更加热门，不热门的物品更加不热门，那么这个系统就有马太效应。

​	推荐系统的初衷是希望消除马太效应，使得各种物品都能被展示给对它们感兴趣的某一类人群。但是，很多研究表明现在主流的推荐算法（比如协同过滤算法）是具有马太效应的。**评测推荐系统是否具有马太效应的简单办法就是使用基尼系数**。（如果G1是从初始用户行为中计算出的物品流行度的基尼系数，G2是从推荐列表中计算出的物品流行度的基尼系数，那么如果G2 > G1，就说明推荐算法具有马太效应。）

#### 4. 多样性

​	为了满足用户广泛的兴趣，推荐列表需要能够覆盖用户不同的兴趣领域，即推荐结果需要具有多样性。多样性推荐列表的好处用一句俗话表述就是“不在一棵树上吊死”。

​	**多样性描述了推荐列表中物品两两之间的不相似性。因此，多样性和相似性是对应的**。

#### 5. 新颖性

​	新颖的推荐是指给用户推荐那些他们以前没有听说过的物品。

​	O’scar Celma在博士论文“Music Recommendation and Discovery in the Long Tail”①中研究了新颖度的评测。评测新颖度的最简单方法是利用推荐结果的平均流行度，因为越不热门的物品越可能让用户觉得新颖。因此，**如果推荐结果中物品的平均热门程度较低，那么推荐结果就可能有比较高的新颖性**。

​	通过牺牲精度来提高多样性和新颖性是很容易的，而**困难的是如何在不牺牲精度的情况下提高多样性和新颖性**。

#### 6. 惊喜度

​	**如果推荐结果和用户的历史兴趣不相似，但却让用户觉得满意，那么就可以说推荐结果的惊喜度很高，而推荐的新颖性仅仅取决于用户是否听说过这个推荐结果**。

​	目前并没有什么公认的惊喜度指标定义方式，这里只给出一种定性的度量方式。上面提到，令用户惊喜的推荐结果是和用户历史上喜欢的物品不相似，但用户却觉得满意的推荐。那么，**定义惊喜度需要首先定义推荐结果和用户历史上喜欢的物品的相似度，其次需要定义用户对推荐结果的满意度**。

​	提高推荐惊喜度需要提高推荐结果的用户满意度，同时降低推荐结果和用户历史兴趣的相似度。

> 用户满意度只能通过问卷调查或者在线实验获得，而推荐结果和用户历史上喜欢的物品相似度一般可以用内容相似度定义。也就是说，如果获得了一个用户观看电影的历史，得到这些电影的演员和导演集合A，然后给用户推荐一个不属于集合A的导演和演员创作的电影，而用户表示非常满意，这样就实现了一个惊喜度很高的推荐。

#### 7. 信任度

​	同样的推荐结果，以让用户信任的方式推荐给用户就更能让用户产生购买欲，而以类似广告形式的方法推荐给用户就可能很难让用户产生购买的意愿。

​	提高推荐系统的信任度主要有两种方法。

+ 首先需要增加推荐系统的透明度（transparency），而增加推荐系统透明度的主要办法是提供推荐解释。只有让用户了解推荐系统的运行机制，让用户认同推荐系统的运行机制，才会提高用户对推荐系统的信任度。
+ 其次是考虑用户的社交网络信息，利用用户的好友信息给用户做推荐，并且用好友进行推荐解释。这是因为用户对他们的好友一般都比较信任，因此如果推荐的商品是好友购买过的，那么他们对推荐结果就会相对比较信任。

> Epinion为了防止垃圾评论或者广告评论影响用户的决策，在每条用户评论的右侧都显示了评论作者的信息，并且让用户判断是信任该评论人还是将他加入黑名单。如果网站具有Epinion的用户信任系统，那么可以在给用户做推荐时，尽量推荐他信任的其他用户评论过的物品。

#### 8. 实时性

​	很多推荐系统都会在离线状态每天计算一次用户推荐列表，然后于在线期间将推荐列表展示给用户。这种设计显然是无法满足实时性的。与用户行为相应的实时性，可以通过推荐列表的变化速率来评测。**如果推荐列表在用户有行为后变化不大，或者没有变化，说明推荐系统的实时性不高**。

​	实时性的第二个方面是推荐系统需要能够**将新加入系统的物品推荐给用户**。这主要考验了推荐系统处理物品**冷启动**的能力。

​	对于新物品推荐能力，我们可以利用用户推荐列表中有多大比例的物品是当天新加的来评测。

#### 9. 健壮性

​	任何一个能带来利益的算法系统都会被人攻击，这方面最典型的例子就是搜索引擎。搜索引擎的作弊和反作弊斗争异常激烈，这是因为如果能让自己的商品成为热门搜索词的第一个搜索果，会带来极大的商业利益。推荐系统目前也遇到了同样的作弊问题，而**健壮性（即robust,鲁棒性）指标衡量了一个推荐系统抗击作弊的能力**。

​	**算法健壮性的评测主要利用模拟攻击**。首先，给定一个数据集和一个算法，可以用这个算法给这个数据集中的用户生成推荐列表。然后，用常用的攻击方法向数据集中注入噪声数据，然后利用算法在注入噪声后的数据集上再次给用户生成推荐列表。最后，通过比较攻击前后推荐列表的相似度评测算法的健壮性。如果攻击后的推荐列表相对于攻击前没有发生大的变化，就说明算法比较健壮。

​	在实际系统中，提高系统的健壮性，除了选择健壮性高的算法，还有以下方法。

+ **设计推荐系统时尽量使用代价比较高的用户行为**。比如，如果有用户购买行为和用户浏览行为，那么主要应该使用用户购买行为，因为购买需要付费，所以攻击购买行为的代价远远大于攻击浏览行为。
+ 在使用数据前，进行攻击检测，从而对数据进行清理。

> 众所周知，绝大部分推荐系统都是通过分析用户的行为实现推荐算法的。
>
> 比如，亚马逊有一种推荐叫做“购买商品A的用户也经常购买的其他商品”。它的主要计算方法是统计购买商品A的用户购买其他商品的次数。那么，我们可以很简单地攻击这个算法，让自己的商品在这个推荐列表中获得比较高的排名，比如可以注册很多账号，用这些账号同时购买A和自己的商品。
>
> 还有一种攻击主要针对评分系统，比如豆瓣的电影评分。这种攻击很简单，就是雇用一批人给自己的商品非常高的评分，而评分行为是推荐系统依赖的重要用户行为。

#### 10. 商业目标

​	很多时候，网站评测推荐系统更加注重网站的商业目标是否达成，而商业目标和网站的盈利模式是息息相关的。一般来说，最本质的商业目标就是平均一个用户给公司带来的盈利。不过这种指标不是很难计算，只是计算一次需要比较大的代价。因此，很多公司会根据自己的盈利模式设计不同的商业目标。

​	不同的网站具有不同的商业目标。比如电子商务网站的目标可能是销售额，基于展示广告盈利的网站其商业目标可能是广告展示总数，基于点击广告盈利的网站其商业目标可能是广告点击总数。因此，设计推荐系统时需要考虑最终的商业目标，而网站使用推荐系统的目的除了满足用户发现内容的需求，也需要利用推荐系统加快实现商业上的指标。

#### 11. 总结

​	获取各种评测指标的途径

|            | 离线实验 | 问卷调查 | 在线实验 |
| ---------- | -------- | -------- | -------- |
| 用户满意度 | ✖️        | ☑️        | ⭕️        |
| 预测准确度 | ☑️        | ☑️        | ✖️        |
| 覆盖率     | ☑️        | ☑️        | ☑️        |
| 多样性     | ⭕️        | ☑️        | ⭕️        |
| 新颖性     | ⭕️        | ☑️        | ⭕️        |
| 惊喜度     | ✖️        | ☑️        | ✖️        |

​	对于可以离线优化的指标，书籍作者的建议是应该在给定覆盖率、多样性、新颖性等限制条件下，尽量优化预测准确度。

用一个数学公式表达，离线实验的优化目标是：

```none
最大化预测准确度
使得 覆盖率 > A
		多样性 > B
		新颖性 > C
其中，A、B、C的取值应该视不同的应用而定。
```

### 1.3.3 评测维度

​	增加评测维度的目的就是知道一个算法在什么情况下性能最好。这样可以为融合不同推荐算法取得最好的整体性能带来参考。

​	一般来说，评测维度分为如下3种。

+ 用户维度：主要包括用户的人口统计学信息、活跃度以及是不是新用户等。

+ 物品维度：包括物品的属性信息、流行度、平均分以及是不是新加入的物品等。

+ 时间维度：包括季节，是工作日还是周末，是白天还是晚上等。

​	如果能够在推荐系统评测报告中包含不同维度下的系统评测指标，就能帮我们全面地了解推荐系统性能，找到一个看上去比较弱的算法的优势，发现一个看上去比较强的算法的缺点。

# 2. 第2章 利用用户行为数据

> [数据挖掘中最经典的案例之一-啤酒与尿布是真实的案例吗？](https://www.zhihu.com/question/20567005)

​	实现个性化推荐的最理想情况是用户能在注册的时候主动告诉我们他喜欢什么，但这种方法有３个缺点：

+ 首先，现在的自然语言理解技术很难理解用户用来描述兴趣的自然语言；
+ 其次，用户的兴趣是不断变化的，但用户不会不停地更新兴趣描述；
+ 最后，很多时候用户并不知道自己喜欢什么，或者很难用语言描述自己喜欢什么。

​	因此，我们需要通过算法自动发掘用户行为数据，从用户的行为中推测出用户的兴趣，从而给用户推荐满足他们兴趣的物品。

​	啤酒和尿布的故事在互联网上被发扬光大。电子商务公司通过分析用户的购物车，找出诸如“购买A商品的用户都购买B商品”这种规律，同时在用户浏览A商品时直接为其展示购买A商品的用户都购买的其他商品。

​	基于用户行为分析的推荐算法是个性化推荐系统的重要算法，学术界一般将这种类型的算法称为**协同过滤算法**。顾名思义，协同过滤就是指用户可以齐心协力，通过不断地和网站互动，使自己的推荐列表能够不断过滤掉自己不感兴趣的物品，从而越来越满足自己的需求。

> 当当网在用户浏览《数据挖掘导论》时给用户推荐“购买本商品的顾客还买过”的书

## 2.1 用户行为数据简介

​	本章提到的个性化推荐算法都是基于用户行为数据分析设计的，因此本节将首先介绍用户行为数据。

​	用户行为数据在网站上最简单的存在形式就是日志。网站在运行过程中都产生大量原始日志（raw log），并将其存储在文件系统中。很多互联网业务会把多种原始日志按照用户行为汇总成会话日志（session log），其中每个 会话表示一次用户行为和对应的服务。比如，在搜索引擎和搜索广告系统中，服务会为每次查询生成一个展示日志（impression log），其中记录了查询和返回结果。如果用户点击了某个结果，这个点击信息会被服务器截获并存储在点击日志（click log）中。一个并行程序会周期性地归并展示日志和点击日志，得到的会话日志中每个消息是一个用户提交的查询、得到的结果以及点击。类似地，推荐系统和电子商务网站也会汇总原始日志生成描述用户行为的会话日志。会话日志通常存储在分布式数据仓库中，如支持离线分析的 Hadoop Hive和支持在线分析的Google Dremel。这些日志记录了用户的各种行为，如在电子商务网站中这些行为主要包括网页浏览、购买、点击、评分和评论等。

​	用户行为在个性化推荐系统中一般分两种：

+ 显性反馈行为（explicit feedback）
+ 隐性反馈行为（implicit feedback）

​	**显性反馈行为包括用户明确表示对物品喜好的行为**。

​	**隐性反馈行为指的是那些不能明确反应用户喜好的行为**。最具代表性的隐性反馈行为就是页面浏览行为。用户浏览一个物品的页面并不代表用户一定喜欢这个页面展示的物品，比如可能因为这个页面链接显示在首页，用户更容易点击它而已。相比显性反馈，隐性反馈虽然不明确，但数据量更大。在很多网站中，很多用户甚至只有隐性反馈数据，而没有显性反馈数据。

​	显性反馈数据和隐性反馈数据的比较

|          | 显性反馈数据 | 隐性反馈数据   |
| -------- | ------------ | -------------- |
| 用户兴趣 | 明确         | 不明确         |
| 数量     | 较少         | 庞大           |
| 存储     | 数据库       | 分布式文件系统 |
| 实时读取 | 实时         | 有延迟         |
| 正负反馈 | 都有         | **只有正反馈** |

​	各代表网站中显性反馈数据和隐性反馈数据的例子

|              | 显性反馈                   | 隐性反馈                               |
| ------------ | -------------------------- | -------------------------------------- |
| 视频网站     | 用户对视频的评分           | 用户观看视频的日志、浏览视频页面的日志 |
| 电子商务网站 | 用户对商品的评分           | 购买日志、浏览日志                     |
| 门户网站     | 用户对新闻的评分           | 阅读新闻的日志                         |
| 音乐网站     | 用户对音乐/歌手/专辑的评分 | 听歌的日志                             |

​	用户行为的统一表示

| 符号             | 说明                                                         |
| ---------------- | ------------------------------------------------------------ |
| user id          | 产生行为的用户的唯一标示                                     |
| item id          | 产生行为的用户的唯一标示                                     |
| behavior type    | 行为的种类（比如是购买还是浏览）                             |
| context          | 产生行为的上下文、包括时间和地点等                           |
| behavior weight  | 行为的权重（如果是观看视频的行为，那么这个权重可以是观看视频的时长；如果是打分行为，这个权重可以是分数） |
| behavior content | 行为的内容（如果是评论行为，那么就是评论的文本；如果是打标签的行为，就是标签） |

​	一般来说，不同的数据集包含不同的行为，目前比较有代表性的数据集有下面几个。

+ 无上下文信息的隐性反馈数据集：每一条行为记录仅仅包含用户ID和物品ID。

+ 无上下文信息的显性反馈数据集：每一条记录包含用户ID、物品ID和用户对物品的评分。

+ 有上下文信息的隐性反馈数据集：每一条记录包含用户ID、物品ID和用户对物品产生行为的时间戳。Lastfm数据集就是这种类型的数据集。

+ 有上下文信息的显性反馈数据集：每一条记录包含用户ID、物品ID、用户对物品的评分和评分行为发生的时间戳。Netflix Prize提供的就是这种类型的数据集。

​	本章使用的数据集基本都是第一种数据集，即无上下文信息的隐性反馈数据集。

> YouTube最早是用5分评分系统收集显性反馈的，但后来他们的研究人员统计了不同评分的评分数，结果发现，用户最常用的评分是5分，其次是1分，其他的分数很少有用户打。因此，后来YouTube就把评分系统改成了两档评分系统（喜欢/不喜欢）。
>
> YouTube的用户主要将精力放在看视频上，因此他们只有在特别不满或者特别满意时才会评分，因此二级评分系统就足够了。但如果是评论网站，用户主要将精力放在评论上，这时多级评分系统就是必要的。

## 2.2 用户行为分析

​	首先需要对用户行为数据进行分析，了解数据中蕴含的一般规律，这样才能对算法的设计起到指导作用。

### 2.2.1 用户活跃度和物品流行度的分布

> [什么是「长尾效应」 ？](https://www.zhihu.com/question/20027490/answer/259310914)

​	很多关于互联网数据的研究发现，互联网上的很多数据分布都满足一种称为Power Law的分布，这个分布在互联网领域也称**长尾分布**。

​	用户行为数据也蕴含着这种规律。

### 2.2.2 用户活跃度和物品流行度的关系

​	一般来说，不活跃的用户要么是新用户，要么是只来过网站一两次的老用户。那么，不同活跃度的用户喜欢的物品的流行度是否有差别？**一般认为，新用户倾向于浏览热门的物品**，因为他们对网站还不熟悉，只能点击首页的热门物品，而**老用户会逐渐开始浏览冷门的物品**。

​	**仅仅基于用户行为数据设计的推荐算法一般称为协同过滤算法**。学术界对协同过滤算法进行了深入研究，提出了很多方法，比如：

+ **基于邻域的方法**（neighborhood-based）
+ 隐语义模型（latent factor model）
+ 基于图的随机游走算法（random walk on graph）

​	在这些方法中，最著名的、**在业界得到最广泛应用的算法是基于邻域的方法**，而基于邻域的方法主要包含下面两种算法。

+ **基于用户的协同过滤算法：这种算法给用户推荐和他兴趣相似的其他用户喜欢的物品。**

+ **基于物品的协同过滤算法：这种算法给用户推荐和他之前喜欢的物品相似的物品。**

下面几节将首先介绍上面两种算法，然后再简单介绍隐语义模型和基于图的模型。

## 2.3 实验设计和算法评测

​	前文说过，评测推荐系统有3种方法——离线实验、用户调查和在线实验。本节将通过离线实验方法评测提到的算法。首先介绍用到的数据集，然后介绍采用的实验方法和评测指标。

### 2.3.1 数据集

​	本章采用GroupLens提供的MovieLens数据集介绍和评测各种算法。 MovieLens数据集有3个不同的版本，本章选用中等大小的数据集。该数据集包含6000多用户对4000多部电影的100万条评分。该数据集是一个评分数据集，用户可以给电影评5个不同等级的分数（1～5分）。**本章着重研究隐反馈数据集中的TopN推荐问题，因此忽略了数据集中的评分记录**。也就是说，TopN推荐的任务是预测用户会不会对某部电影评分，而不是预测用户在准备对某部电影评分的前提下会给电影评多少分。

### 2.3.2 实验设计

> [用简单易懂的语言描述「过拟合 overfitting」？](https://www.zhihu.com/question/32246256)

​	协同过滤算法的离线实验一般如下设计。首先，将用户行为数据集按照均匀分布随机分成M份（本章取M=8），挑选一份作为测试集，将剩下的M-1份作为训练集。然后在训练集上建立用户兴趣模型，并在测试集上对用户行为进行预测，统计出相应的评测指标。<u>为了保证评测指标并不是过拟合的结果，需要进行M次实验，并且每次都使用不同的测试集。然后将M次实验测出的评测指标的平均值作为最终的评测指标。</u>

​	下面的Python代码描述了将数据集随机分成训练集和测试集的过程：

```python
def SplitData(data, M, k, seed):
  test = []
  train = []
  random.seed(seed)
  for user, item in data:
    if random.randint(0,M) == k:
      test.append([user,item])
    else:
      train.append([user,item])
  return train, test
```

​	这里，每次实验选取不同的k（0 ≤ k ≤ M-1）和相同的随机数种子seed，进行M次实验就可以得到M个不同的训练集和测试集，然后分别进行实验，用M次实验的平均值作为最后的评测指标。这样做主要是防止某次实验的结果是过拟合的结果（over fitting），**但如果数据集够大，模型够简单，为了快速通过离线实验初步地选择算法，也可以只进行一次实验**。

### 2.3.3 评测指标

> [如何解释召回率与精确率？](https://www.zhihu.com/question/19645541)
>
> 召回率 (Recall)：正样本有多少被找出来了（召回了多少）。
>
> 精确率 (Precision)：你认为的正样本，有多少猜对了（猜的精确性如何）。

​	**召回率描述有多少比例的用户—物品评分记录包含在最终的推荐列表中，而准确率描述最终的推荐列表中有多少比例是发生过的用户—物品评分记录**。下面两段代码给出了召回率和准确率的计算方法。

```python
def Recall(train, test, N):
  hit = 0
  all = 0
  for user in train.keys():
    tu = test[user]
    rank = GetRecommendation(user, N)
    for item, pui in rank:
      if item in tu:
        hit += 1
        all += len(tu)
  return hit / (all * 1.0)
def Precision(train, test, N):
  hit = 0
  all = 0
  for user in train.keys():
    tu = test[user]
    rank = GetRecommendation(user, N)
      for item, pui in rank:
        if item in tu:
          hit += 1
      all += N
  return hit / (all * 1.0)
```

​	除了评测推荐算法的精度，本章还计算了算法的覆盖率，**覆盖率反映了推荐算法发掘长尾的能力**，覆盖率越高，说明推荐算法越能够将长尾中的物品推荐给用户。

​	如果所有的物品都被推荐给至少一个用户，那么覆盖率就是100%。如下代码可以用来计算推荐算法的覆盖率：

```python
def Coverage(train, test, N):
  recommend_items = set()
  all_items = set()
  for user in train.keys():
    for item in train[user].keys():
      all_items.add(item)
    rank = GetRecommendation(user, N)
    for item, pui in rank:
      recommend_items.add(item)
  return len(recommend_items) / (len(all_items) * 1.0)
```

​	最后，我们还需要评测推荐的新颖度，这里用推荐列表中物品的平均流行度度量推荐结果的新颖度。如果推荐出的物品都很热门，说明推荐的新颖度较低，否则说明推荐结果比较新颖。

```python
def Popularity(train, test, N):
  item_popularity = dict()
  for user, items in train.items():
    for item in items.keys()
    	if item not in item_popularity:
      	item_popularity[item] = 0
      item_popularity[item] += 1
  ret = 0
  n = 0
  for user in train.keys():
    rank = GetRecommendation(user, N)
    for item, pui in rank:
      ret += math.log(1 + item_popularity[item])
      n += 1
  ret /= n * 1.0
  return ret
```

​	这里，在计算平均流行度时对每个物品的流行度取对数，这是因为物品的流行度分布满足长尾分布，在取对数后，流行度的平均值更加稳定。

> [在统计学中为什么要对变量取对数？](https://www.zhihu.com/question/22012482)
>
> 要研究A和B的关系，可以先研究 lnA和B的关系，因为令 z=lnA，那么 z和B的关系搞明白了，只要取 A=e^z，则 A和B的关系也出来了。所以如果你要研究A和B的关系，那么研究 “A的变换”和“B的变换”之间的关系也是可以的。
>
> 统计学中你要使用某个方法，就要满足这个方法的条件，如果你所研究的变量不满足条件，但是变量进行变换后就满足条件了，那么就可以进行变换。通常 “对数变换” 使用的最频繁，因为对数变换后你会神奇的发现条件就满足了。
>
> 比如一个右偏非负的数据（最常见的就是工资，财富），不满足正态，但是取对数后就符合正态了。
>
> 取对数还有其他的好处，其中一个就是能把大的数变小。变小的同时数据的方差也变小。比如动物的体重和身高。有老鼠，有大象，有恐龙。数据出来后你会发现恐龙，大象的数据非常大，另外方差也特别大。大象，恐龙的数据看起来就像是异常值，但是它们不是异常值，这种数据分析起来非常不好处理，怎么办？身高体重都取对数，变换后你会发现豁然开朗！
>
> 总的来说，取对数就是为了把不满足的条件变成满足或者让我们分析的结果变得更好一点。

## 2.4 基于邻域的算法

​	基于邻域的算法是推荐系统中最基本的算法，该算法不仅在学术界得到了深入研究，而且在业界得到了广泛应用。基于邻域的算法分为两大类，一类是基于用户的协同过滤算法，另一类是基于物品的协同过滤算法。下面几节将对这两种算法进行深入介绍，对比它们的优缺点并提出改进方案。

### 2.4.1 基于用户的协同过滤算法

​	**基于用户的协同过滤算法是推荐系统中最古老的算法**。可以不夸张地说，这个算法的诞生标志了推荐系统的诞生。该算法在1992年被提出，并应用于邮件过滤系统，1994年被GroupLens用于新闻过滤。在此之后直到200年，该算法都是推荐系统领域最著名的算法。本节将对该算法进行详细介绍，首先介绍最基础的算法，然后在此基础上提出不同的改进方法，并通过真实的数据集进行评测。

#### 1. 基础算法

​	基于用户的协同过滤算法主要包括两个步骤。

1. 找到和目标用户兴趣相似的用户集合。

2. 找到这个集合中的用户喜欢的，且目标用户没有听说过的物品推荐给目标用户。

步骤(1)的关键就是计算两个用户的兴趣相似度。这里，协同过滤算法主要**利用行为的相似度计算兴趣的相似度**。

参数K是UserCF的一个重要参数，它的调整对推荐算法的各种指标都会产生一定的影响。

+ 准确率和召回率：可以看到，推荐系统的精度指标（准确率和召回率）并不和参数K成线性关系。在MovieLens数据集中，选择K=80左右会获得比较高的准确率和召回率。因此选择合适的K对于获得高的推荐系统精度比较重要。当然，推荐结果的精度对K也不是特别敏感，只要选在一定的区域内，就可以获得不错的精度。

+ 流行度：可以看到，在3个数据集上K越大则UserCF推荐结果就越热门。这是因为K决定了UserCF在给你做推荐时参考多少和你兴趣相似的其他用户的兴趣，那么如果K越大，参考的人越多，结果就越来越趋近于全局热门的物品。

+ 覆盖率：可以看到，在3个数据集上，K越大则UserCF推荐结果的覆盖率越低。覆盖率的降低是因为流行度的增加，随着流行度增加，UserCF越来越倾向于推荐热门的物品，从而对长尾物品的推荐越来越少，因此造成了覆盖率的降低。

#### 2. 用户相似度计算的改进

​	上一节介绍了计算用户兴趣相似度的最简单的公式（余弦相似度公式），但这个公式过于粗糙，本节将讨论如何改进该公式来提高UserCF的推荐性能。

​	**两个用户对冷门物品采取过同样的行为更能说明他们兴趣的相似度**。

#### 3. 实际在线系统使用UserCF的例子

​	**相比我们后面要讨论的基于物品的协同过滤算法（ItemCF）， UserCF在目前的实际应用中使用并不多**。

> Digg在博客中公布了使用推荐系统后的效果，主要指标如下所示。
>
> + 用户反馈增加：用户“顶”和“踩”的行为增加了40%。
>
> + 平均每个用户将从34个具相似兴趣的好友那儿获得200条推荐结果。
>
> + 用户和好友的交互活跃度增加了24%。
>
> + 用户评论增加了11%。
>
> 上面只是对比了使用推荐系统后和使用推荐系统前的结果，并非AB测试的结果，因此还不完全具有说服力，但还是部分证明了推荐系统的有效性。

### 2.4.2 基于物品的协同过滤算法

​	**基于物品的协同过滤（item-based collaborative filtering）算法是目前业界应用最多的算法**。无论是亚马逊网，还是Netflix、Hulu、YouTube，其推荐算法的基础都是该算法。本节将从基础的算法开始介绍，然后提出算法的改进方法，并通过实际数据集评测该算法。

#### 1. 基础算法

​	基于用户的协同过滤算法在一些网站（如Digg）中得到了应用，但该算法有一些缺点。

+ 首先，**随着网站的用户数目越来越大，计算用户兴趣相似度矩阵将越来越困难，其运算时间复杂度和空间复杂度的增长和用户数的增长近似于平方关系。**
+ 其次，**基于用户的协同过滤很难对推荐结果作出解释**。

​	因此，著名的电子商务公司亚马逊提出了另一个算法——基于物品的协同过滤算法。

​	**基于物品的协同过滤算法（简称ItemCF）给用户推荐那些和他们之前喜欢的物品相似的物品**。比如，该算法会因为你购买过《数据挖掘导论》而给你推荐《机器学习》。不过，ItemCF算法并不利用物品的内容属性计算物品之间的相似度，它主要通过分析用户的行为记录计算物品之间的相似度。

​	该算法认为，**物品A和物品B具有很大的相似度是因为喜欢物品A的用户大都也喜欢物品B。**

​	基于物品的协同过滤算法可以利用用户的历史行为给推荐结果提供推荐解释，比如给用户推荐《天龙八部》的解释可以是因为用户之前喜欢《射雕英雄传》。

> + 亚马逊在iPhone商品界面上提供的与iPhone相关的商品，而相关商品都是购买iPhone的用户也经常购买的其他商品。
> + Hulu在个性化视频推荐利用ItemCF给每个推荐结果提供了一个推荐解释，而用于解释的视频都是用户之前观看或者收藏过的视频。

基于物品的协同过滤算法主要分为两步。

1. 计算物品之间的相似度。

2. 根据物品的相似度和用户的历史行为给用户生成推荐列表。

​	在协同过滤中两个物品产生相似度是因为它们共同被很多用户喜欢，也就是说每个用户都可以通过他们的历史兴趣列表给物品“贡献”相似度。这里面蕴涵着一个假设，<u>就是每个用户的兴趣都局限在某几个方面，因此如果两个物品属于一个用户的兴趣列表，那么这两个物品可能就属于有限的几个领域，而如果两个物品属于很多用户的兴趣列表，那么它们就可能属于同一个领域，因而有很大的相似度</u>。

​	ItemCF通过公式计算用户对一个物品的兴趣，**和用户历史上感兴趣的物品越相似的物品，越有可能在用户的推荐列表中获得比较高的排名**。

​	**ItemCF的一个优势就是可以提供推荐解释，即利用用户历史上喜欢的物品为现在的推荐结果进行解释**。

​	在MovieLens数据集上ItemCF算法离线实验的各项性能指标的评测结果。

+ 精度（准确率和召回率）：可以看到ItemCF推荐结果的精度也是不和K成正相关或者负相关的，因此选择合适的K对获得最高精度是非常重要的。

+ 流行度：和UserCF不同，参数K对ItemCF推荐结果流行度的影响也不是完全正相关的。随着K的增加，结果流行度会逐渐提高，但当K增加到一定程度，流行度就不会再有明显变化。

+ 覆盖率：K增加会降低系统的覆盖率。

#### 2. 用户活跃度对物品相似度的影响

​	从前面的讨论可以看到，在协同过滤中两个物品产生相似度是因为它们共同出现在很多用户的兴趣列表中。换句话说，每个用户的兴趣列表都对物品的相似度产生贡献。那么，是不是每个用户的贡献都相同呢？

​	假设有这么一个用户，他是开书店的，并且买了当当网上80%的书准备用来自己卖。那么，他的购物车里包含当当网80%的书。假设当当网有100万本书，也就是说他买了80万本。从前面对ItemCF的讨论可以看到，这意味着因为存在这么一个用户，有80万本书两两之间就产生了相似度，也就是说，内存里即将诞生一个80万乘80万的稠密矩阵。

​	另外可以看到，这个用户虽然活跃，但是买这些书并非都是出于自身的兴趣，而且这些书覆盖了当当网图书的很多领域，所以**这个用户对于他所购买书的两两相似度的贡献应该远远小于一个只买了十几本自己喜欢的书的文学青年**。

​	John S. Breese在论文中提出了一个称为IUF（Inverse User Frequence），即用户活跃度对数的倒数的参数，他也认为**活跃用户对物品相似度的贡献应该小于不活跃的用户**。

​	**对于很多过于活跃的用户，比如上面那位买了当当网80%图书的用户，为了避免相似度矩阵过于稠密，我们在实际计算中一般直接忽略他的兴趣列表，而不将其纳入到相似度计算的数据集中**。

#### 3. 物品相似度的归一化

​	Karypis在研究中发现如果将ItemCF的相似度矩阵按最大值归一化，可以提高推荐的准确率。

​	**归一化的好处不仅仅在于增加推荐的准确度，它还可以提高推荐的覆盖率和多样性**。

​	对于两个不同的类，什么样的类其类内物品之间的相似度高，什么样的类其类内物品相似度低呢？**一般来说，热门的类其类内物品相似度一般比较大**。如果不进行归一化，就会推荐比较热门的类里面的物品，而这些物品也是比较热门的。因此，推荐的覆盖率就比较低。相反，如果进行相似度的归一化，则可以提高推荐系统的覆盖率。

> 假设物品分为两类——A和B，A类物品之间的相似度为0.5，B类物品之间的相似度为0.6，而A类物品和B类物品之间的相似度是0.2。在这种情况下，如果一个用户喜欢了5个A类物品和5个B类物品，用ItemCF给他进行推荐，推荐的就都是B类物品，因为B类物品之间的相似度大。但如果归一化之后，A类物品之间的相似度变成了1，B类物品之间的相似度也是1，那么这种情况下，用户如果喜欢5个A类物品和5个B类物品，那么他的推荐列表中A类物品和B类物品的数目也应该是大致相等的。从这个例子可以看出，相似度的归一化可以提高推荐的多样性。

### 2.4.3 UserCF和ItemCF的综合比较

​	UserCF是推荐系统领域较为古老的算法，1992年就已经在电子邮件的个性化推荐系统Tapestry中得到了应用，1994年被GroupLens用来实现新闻的个性化推荐，后来被著名的文章分享网站Digg用来给用户推荐个性化的网络文章。ItemCF则是相对比较新的算法，在著名的电子商务网站亚马逊和DVD租赁网站Netflix中得到了广泛应用。

+ **UserCF给用户推荐那些和他有共同兴趣爱好的用户喜欢的物品**
+ **ItemCF给用户推荐那些和他之前喜欢的物品类似的物品**

​	从这个算法的原理可以看到，UserCF的推荐结果着重于反映和用户兴趣相似的小群体的热点，而ItemCF的推荐结果着重于维系用户的历史兴趣。换句话说，**UserCF的推荐更社会化，反映了用户所在的小型兴趣群体中物品的热门程度，而ItemCF的推荐更加个性化，反映了用户自己的兴趣传承**。

​	UserCF适合用于新闻推荐的另一个原因是从技术角度考量的。因为作为一种物品，新闻的更新非常快，每时每刻都有新内容出现，而ItemCF需要维护一张物品相关度的表，如果物品更新很快，那么这张表也需要很快更新，这在技术上很难实现。**绝大多数物品相关度表都只能做到一天一次更新**，这在新闻领域是不可以接受的。而UserCF只需要用户相似性表，虽然UserCF对于新用户也需要更新相似度表，但**在新闻网站中，物品的更新速度远远快于新用户的加入速度**，而且对于新用户，完全可以给他推荐最热门的新闻，因此UserCF显然是利大于弊。

​	但是，在图书、电子商务和电影网站，比如亚马逊、豆瓣、Netflix中，ItemCF则能极大地发挥优势。首先，在这些网站中，用户的兴趣是比较固定和持久的。一个技术人员可能都是在购买技术方面的书，而且他们对书的热门程度并不是那么敏感，事实上**越是资深的技术人员，他们看的书就越可能不热门**。此外，这些系统中的用户大都不太需要流行度来辅助他们判断一个物品的好坏，而是可以通过自己熟悉领域的知识自己判断物品的质量。因此，这些网站中个性化推荐的任务是**帮助用户发现和他研究领域相关的物品**。因此，ItemCF算法成为了这些网站的首选算法。此外，**这些网站的物品更新速度不会特别快，一天一次更新物品相似度矩阵对它们来说不会造成太大的损失**，是可以接受的。

​	同时，从技术上考虑：

+ **UserCF需要维护一个用户相似度的矩阵**
+ **ItemCF需要维护一个物品相似度矩阵**。

​	从存储的角度说，如果用户很多，那么维护用户兴趣相似度矩阵需要很大的空间，同理，如果物品很多，那么维护物品相似度矩阵代价较大。

​	在早期的研究中，大部分研究人员都是让少量的用户对大量的物品进行评价，然后研究用户兴趣的模式。那么，对于他们来说，因为用户很少，计算用户兴趣相似度是最快也是最简单的方法。但在实际的互联网中，用户数目往往非常庞大，而在图书、电子商务网站中，物品的数目则是比较少的。此外，物品的相似度相对于用户的兴趣一般比较稳定，因此使用ItemCF是比较好的选择。当然，新闻网站是个例外，在那儿，物品的相似度变化很快，物品数目庞大，相反用户兴趣则相对固定（都是喜欢看热门的），所以新闻网站的个性化推荐使用UserCF算法的更多。

​	UserCF和ItemCF优缺点的对比

<table>
  <tr>
    <th></th>
    <th>UserCF</th>
    <th>ItemCF</th>
  </tr>
  <tr>
    <td>性能</td>
    <td>
      <p>
        适用于用户较少的场合，如果用户很多，计算用户相似度矩阵代价很大
      </p>
    </td>
    <td>
      <p>
        适用于物品数明显小于用户数的场合，如果物品很多（网页），计算物品相似度矩阵代价很大
      </p>
    </td>
  </tr>
  <tr>
    <td>领域</td>
    <td>时效性较强，用户个性化兴趣不太明显的领域</td>
    <td>长尾物品丰富，用户个性化需求强烈的领域</td>
  </tr>
  <tr>
    <td>实时性</td>
    <td>用户有新行为，不一定造成推荐结果的立即变化</td>
    <td>用户有新行为，一定会导致推荐结果的实时变化</td>
  </tr>
  <tr>
    <td>冷启动</td>
    <td>
      <p>
        在新用户对很少的物品产生行为后，不能立即对他进行个性化推荐，因为用户相似度表是每隔一段时间离线计算的
        <br/>
        新物品上线后一段时间，一旦有用户对物品产生行为，就可以将新物品推荐给和对它产生行为的用户兴趣相似的其他用户
      </p>
    </td>
    <td>
      <p>
        新用户只要对一个物品产生行为，就可以给他推荐和该物品相关的其他物品
        <br/>
        但没有办法在不离线更新物品相似度表的情况下将新物品推荐给用户
      </p>
    </td>
  </tr>
  <tr>
    <td>推荐理由</td>
    <td>很难提供令用户信服的推荐解释</td>
    <td>利用用户的历史行为给用户做推荐解释，可以令用户比较信服</td>
  </tr>
</table>

​	首先要指出的是，**离线实验的性能在选择推荐算法时并不起决定作用**。

+ 首先应该满足产品的需求，比如如果需要提供推荐解释，那么可能得选择ItemCF算法。
+ 其次，需要看实现代价，比如若用户太多，很难计算用户相似度矩阵，这个时候可能不得不抛弃UserCF算法。
+ 最后，离线指标和点击率等在线指标不一定成正比。

​	 而且，这里对比的是最原始的UserCF和ItemCF算法，这两种算法都可以进行各种各样的改进。**一般来说，这两种算法经过优化后，最终得到的离线性能是近似的**。

​	下一节将分析为什么原始ItemCF算法的覆盖率和新颖度都不高。

#### 哈利波特问题

​	亚马逊网的研究人员在设计ItemCF算法之初发现ItemCF算法计算出的图书相关表存在一个问题，就是很多书都和《哈利波特》相关。也就是说，购买任何一本书的人似乎都会购买《哈利波特》。后来他们研究发现，主要是因为《哈利波特》太热门了，确实是购买任何一本书的人几乎都会购买它。

​	每个用户一般都会在不同的领域喜欢一种物品。以电视为例，看新闻联播是父辈每天的必修课，他们每天基本就看新闻联播，而且每天不看别的新闻，就看这一种新闻。此外，他们很多都是电视剧迷，都会看央视一套8点的电视剧。那么，最终结果就是黄金时间的电视剧都和新闻联播相似，而新闻联播和其他新闻的相似度很低。

​	上面的问题换句话说就是，**两个不同领域的最热门物品之间往往具有比较高的相似度**。<u>这个时候，仅仅靠用户行为数据是不能解决这个问题的，因为用户的行为表示这种物品之间应该相似度很高。此时，我们只能依靠引入物品的内容数据解决这个问题，比如对不同领域的物品降低权重等</u>。这些就不是协同过滤讨论的范畴了。

## 2.5 隐语义模型

> [最小推荐系统：隐语义模型(Latent Factor Model)](https://zhuanlan.zhihu.com/p/150285625)

​	自从Netflix Prize比赛举办以来，LFM（latent factor model）**隐语义模型**逐渐成为推荐系统领域耳熟能详的名词。其实该算法最早在文本挖掘领域被提出，用于找到文本的隐含语义。相关的名词有LSI、pLSA、LDA和Topic Model。本节将对隐含语义模型在Top-N推荐中的应用进行详细介绍，并通过实际的数据评测该模型。

### 2.5.1 基础算法

​	隐语义模型是最近几年推荐系统领域最为热门的研究话题，它的核心思想是**通过隐含特征(latent factor)联系用户兴趣和物品**。

​	通过一个例子来理解一下这个模型。用户A的兴趣涉及侦探小说、科普图书以及一些计算机技术书，而用户B的兴趣比较集中在数学和机器学习方面。

​	如何给A和B推荐图书呢？

+ 对于UserCF，首先需要找到和他们看了同样书的其他用户（兴趣相似的用户），然后给他们推荐那些用户喜欢的其他书。

+ 对于ItemCF，需要给他们推荐和他们已经看的书相似的书，比如作者B看了很多关于数据挖掘的书，可以给他推荐机器学习或者模式识别方面的书。

​	还有一种方法，可以对书和物品的兴趣进行分类。**对于某个用户，首先得到他的兴趣分类，然后从分类中挑选他可能喜欢的物品**。

​	总结一下，这个**基于兴趣分类**的方法大概需要解决3个问题。

+ 如何给物品进行分类？

+ 如何确定用户对哪些类的物品感兴趣，以及感兴趣的程度？

+ 对于一个给定的类，选择哪些属于这个类的物品推荐给用户，以及如何确定这些物品在一个类中的权重？

​	对于第一个问题的简单解决方案是找编辑给物品分类。以图书为例，每本书出版时，编辑都会给书一个分类。为了给图书分类，出版界普遍遵循中国图书分类法。但是，即使有很系统的分类体系，编辑给出的分类仍然具有以下缺点。

+ 编辑的意见<u>不能代表各种用户的意见</u>。比如，对于《具体数学》应该属于什么分类，有人认为应该属于数学，有些人认为应该属于计算机。从内容看，这本书是关于数学的，但从用户看，这本书的读大部分是做计算机出身的。<u>编辑的分类大部分是从书的内容出发，而不是从书的读者群出发</u>。

+ 编辑**很难控制分类的粒度**。我们知道分类是有不同粒度的，《数据挖掘导论》在粗粒度的分类中可能属于计算机技术，但在细粒度的分类中可能属于数据挖掘。**对于不同的用户，我们可能需要不同的粒度。比如对于一位初学者，我们粗粒度地给他做推荐就可以了，而对于一名资深研究人员，我们就需要深入到他的很细分的领域给他做个性化推荐**。

+ 编辑很难给一个物品多个分类。有的书不仅属于一个类，而是**可能属于很多的类**。

+ 编辑很难给出多维度的分类。我们知道，分类是可以有很多维度的，比如按照作者分类、按照译者分类、按照出版社分类。比如不同的用户看《具体数学》原因可能不同，有些人是因为它是数学方面的书所以才看的，而有些人是因为它是大师Knuth的著作所以才去看，因此**在不同人的眼中这本书属于不同的分类**。

+ 编辑很难决定一个物品在某一个**分类中的权重**。比如编辑可以很容易地决定《数据挖掘导论》属于数据挖掘类图书，但这本书在这类书中的定位是什么样的，编辑就很难给出一个准确的数字来表示。

​	为了解决上面的问题，研究人员提出：为什么我们不从数据出发，自动地找到那些类，然后进行个性化推荐？于是，隐含语义分析技术（latent variable analysis）出现了。隐含语义分析技术因为采取**基于用户行为统计的自动聚类**，较好地解决了上面提出的5个问题。

+ 编辑的意见不能代表各种用户的意见，但**隐含语义分析技术的分类来自对用户行为的统计，代表了用户对物品分类的看法**。**隐含语义分析技术和ItemCF在物品分类方面的思想类似，如果两个物品被很多用户同时喜欢，那么这两个物品就很有可能属于同一个类**。

+ 编辑很难控制分类的粒度，但**隐含语义分析技术允许我们指定最终有多少个分类**，这个数字越大，分类的粒度就会越细，反正分类粒度就越粗。

+ 编辑很难给一个物品多个分类，但**隐含语义分析技术会计算出物品属于每个类的权重**，因此每个物品都不是硬性地被分到某一个类中。

+ 编辑很难给出多维度的分类，但**隐含语义分析技术给出的每个分类都不是同一个维度的，它是基于用户的共同兴趣计算出来的**，如果用户的共同兴趣是某一个维度，那么LFM给出的类也是相同的维度。

+ 编辑很难决定一个物品在某一个分类中的权重，但**隐含语义分析技术可以通过统计用户行为决定物品在每个类中的权重**，如果喜欢某个类的用户都会喜欢某个物品，那么这个物品在这个类中的权重就可能比较高。

​	推荐系统的用户行为分为显性反馈和隐性反馈。**LFM在显性反馈数据（也就是评分数据）上解决评分预测问题并达到了很好的精度**。不过本章主要讨论的是隐性反馈数据集，这种数据集的特点是只有正样本（用户喜欢什么物品），而没有负样本（用户对什么物品不感兴趣）。

​	那么，**在隐性反馈数据集上应用LFM解决TopN推荐的第一个关键问题就是如何给每个用户生成负样本**。

​	对于这个问题，Rong Pan在文章中进行了深入探讨。他对比了如下几种方法。

+ 对于一个用户，用他所有没有过行为的物品作为负样本。

+ 对于一个用户，从他没有过行为的物品中均匀采样出一些物品作为负样本。

+ 对于一个用户，从他没有过行为的物品中采样出一些物品作为负样本，但采样时，保证每个用户的正负样本数目相当。

+ 对于一个用户，从他没有过行为的物品中采样出一些物品作为负样本，但采样时，偏重采样不热门的物品。

​	对于第一种方法，它的明显缺点是负样本太多，正负样本数目相差悬殊，因而计算复杂度很高，最终结果的精度也很差。对于另外3种方法，Rong Pan在文章中表示第三种好于第二种，而第二种好于第四种。

​	后来，通过2011年的KDD Cup的Yahoo! Music推荐系统比赛，我们发现对负样本采样时应该遵循以下原则：

+ **对每个用户，要保证正负样本的平衡（数目相似）。**
+ **对每个用户采样负样本时，要选取那些很热门，而用户却没有行为的物品。**

​	**一般认为，很热门而用户却没有行为更加代表用户对这个物品不感兴趣。因为对于冷门的物品，用户可能是压根没在网站中发现这个物品，所以谈不上是否感兴趣**。

​	在LFM中，重要的参数有4个：

+ 隐特征的个数F；

+ 学习速率alpha；

+ 正则化参数lambda；

+ **负样本/正样本比例 ratio。**

​	通过实验发现，**ratio参数对LFM的性能影响最大**。

​	随着负样本数目的增加，LFM的准确率和召回率有明显提高。不过当ratio>10以后，准确率和召回率基本就比较稳定了。同时，随着负样本数目的增加，覆盖率不断降低，而推荐结果的流行度不断增加，说明ratio参数控制了推荐算法发掘长尾的能力。如果将LFM的结果与前面ItemCF和UserCF算法的性能相比，可以发现LFM在所有指标上都优于UserCF和ItemCF。当然，这只是在MovieLens一个数据集上的结果，我们也发现，<u>当数据集非常稀疏时，LFM的性能会明显下降，甚至不如UserCF和ItemCF的性能</u>。

### 2.5.2 基于LFM的实际系统的例子

​	雅虎的研究人员公布过一个使用LFM进行雅虎首页个性化设计的方案①。本节将简单介绍他们的设计并讨论他们的设计方案。

​	雅虎首页的界面，包括不同的模块，比如左侧的分类导航列表、中间的热门新闻列表、右侧的最近热门话题列表。雅虎的研究人员认为这3个模块都可以进行一定的个性化，可以根据用户的兴趣给他们展示不同的内容。

​	当然，雅虎的研究人员在上面的模型基础上进行了一些修改，利用了一些改进的LFM模型。这些模型主要来自Netflix Prize比赛，因此我们会在第8章详细讨论这些模型。

​	但是，**LFM模型在实际使用中有一个困难，那就是它很难实现实时的推荐**。

​	经典的LFM模型每次训练时都**需要扫描所有的用户行为记录**，这样才能计算出用户隐类向量（pu）和物品隐类向量（qi）。而且LFM的训练需要在用户行为记录上**反复迭代才能获得比较好的性能**。因此，LFM的每次训练都很耗时，一般在实际应用中只能每天训练一次，并且计算出所有用户的推荐结果。

​	**LFM模型不能因为用户行为的变化实时地调整推荐结果来满足用户最近的行为**。

​	实时性在雅虎的首页个性化推荐系统中非常重要。为了解决传统LFM不能实时化，而产品需要实时性的矛盾，雅虎的研究人员提出了一个解决方案。

​	他们的解决方案分为两个部分。首先，他们利用新闻链接的内容属性（关键词、类别等）得到链接i的内容特征向量y<sub>i</sub>。其次，他们会实时地收集用户对链接的行为，并且用这些数据得到链接i的隐特征向量q<sub>i</sub>。然后，他们会利用如下公式预测用户u是否会单击链接i：
$$
r_{ui} = x^T_u . y_i + p^T_u . q_i
$$
​	其中，y<sub>i</sub>是根据物品的内容属性直接生成的，x<sub>uk</sub>是用户u对内容特征k的兴趣程度，用户向量x<sub>u</sub>可以根据历史行为记录获得，而且每天只需要计算一次。而p<sub>u</sub>、q<sub>i</sub>是根据实时拿到的用户最近几小时的行为训练LFM获得的。因此，对于一个新加入的物品i，可以通过x<sup>T</sup><sub>u</sub> \* y<sub>i</sub>估计用户u对物品i的兴趣，然后经过几个小时后，就可以通过p<sup>T</sup><sub>u</sub> \* q<sub>i</sub> 得到更加准确的预测值。

​	上面的讨论只是简单阐述了雅虎所用的方法，关于雅虎具体的方法可以参考他们的报告。

### 2.5.3 LFM和基于邻域的方法的比较

​	**LFM是一种基于机器学习的方法**，具有比较好的理论基础。这个方法和基于邻域的方法（比如UserCF、ItemCF）相比，各有优缺点。下面将从不同的方面对比LFM和基于邻域的方法。

+ 理论基础：LFM具有比较好的理论基础，它是一种学习方法，通过优化一个设定的指标
  建立最优的模型。**基于邻域的方法更多的是一种基于统计的方法，并没有学习过程**。

+ 离线计算的空间复杂度：**基于邻域的方法需要维护一张离线的相关表**。在离线计算相关
  表的过程中，如果用户/物品数很多，将会占据很大的内存。假设有M个用户和N个物品，
  在计算相关表的过程中，我们可能会获得一张比较稠密的临时相关表（尽管最终我们对
  每个物品只保留K个最相关的物品，但在中间计算过程中稠密的相关表是不可避免的），
  那么假设是用户相关表，则需要O(M\*M)的空间，而对于物品相关表，则需要O(N\*N)的空
  间。而LFM在建模过程中，如果是F个隐类，那么它需要的存储空间是O(F*(M+N))，这在
  M和N很大时可以很好地节省离线计算的内存。**在Netflix Prize中，因为用户数很庞大**
  **（40多万），很少有人使用UserCF算法（据说需要30 GB左右的内存），而LFM由于大量节**
  **省了训练过程中的内存（只需要4 GB），从而成为Netflix Prize中最流行的算法**。

+ 离线计算的时间复杂度：假设有M个用户、N个物品、K条用户对物品的行为记录。那么，
  UserCF计算用户相关表的时间复杂度是O(N * (K/N)^2)，而ItemCF计算物品相关表的时间
  复杂度是O(M*(K/M)^2)。而对于LFM，如果用F个隐类，迭代S次，那么它的计算复杂度
  是O(K * F * S)。那么，如果K/N > F*S，则代表UserCF的时间复杂度低于LFM，如果
  K/M>F\*S，则说明ItemCF的时间复杂度低于LFM。**在一般情况下，LFM的时间复杂度要**
  **稍微高于UserCF和ItemCF，这主要是因为该算法需要多次迭代**。但总体上，这两种算法
  在时间复杂度上没有质的差别。

+ 在线实时推荐：UserCF和ItemCF在线服务算法需要将相关表缓存在内存中，然后可以在
  线进行实时的预测。以ItemCF算法为例，一旦用户喜欢了新的物品，就可以通过查询内
  存中的相关表将和该物品相似的其他物品推荐给用户。因此，一旦用户有了新的行为，
  而且该行为被实时地记录到后台的数据库系统中，他的推荐列表就会发生变化。而从LFM
  的预测公式可以看到，**LFM在给用户生成推荐列表时，需要计算用户对所有物品的兴趣**
  **权重，然后排名，返回权重最大的N个物品**。那么，在物品数很多时，这一过程的时间
  复杂度非常高，可达O(M\*N\*F)。因此，**LFM不太适合用于物品数非常庞大的系统，如**
  **果要用，我们也需要一个比较快的算法给用户先计算一个比较小的候选列表，然后再用**
  **LFM重新排名。**另一方面，**LFM在生成一个用户推荐列表时速度太慢，因此不能在线实**
  **时计算，而需要离线将所有用户的推荐结果事先计算好存储在数据库中**。因此，**LFM不**
  **能进行在线实时推荐**，也就是说，当用户有了新的行为后，他的推荐列表不会发生变化。

+ 推荐解释：**ItemCF算法支持很好的推荐解释，它可以利用用户的历史行为解释推荐结果。**
  但LFM无法提供这样的解释，它计算出的隐类虽然在语义上确实代表了一类兴趣和物品，
  却很难用自然语言描述并生成解释展现给用户。

## 2.6 基于图的模型

​	用户行为很容易用二分图表示，因此很多图的算法都可以用到推荐系统中。本节将重点讨论如何将用户行为用图表示，并利用图的算法给用户进行个性化推荐。

