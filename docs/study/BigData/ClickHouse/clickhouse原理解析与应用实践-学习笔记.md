# clickhouse原理解析与应用实践-学习笔记

# 1. ClickHouse的前世今生

## 1.1 传统BI系统之殇

> + [ERP系统_百度百科 (baidu.com)](https://baike.baidu.com/item/ERP系统/1569198?fr=aladdin)
>
>   ERP系统是企业资源计划（Enterprise Resource Planning）的简称，是指建立在信息技术基础上，集信息技术与先进管理思想于一身，以系统化的[管理思想](https://baike.baidu.com/item/管理思想/2555826)，为企业员工及决策层提供决策手段的管理平台。
>
> + [客户关系管理（管理学词汇CRM）_百度百科 (baidu.com)](https://baike.baidu.com/item/客户关系管理/254554?fromtitle=CRM&fromid=165070&fr=aladdin)
>
>   客户关系管理是指[企业](https://baike.baidu.com/item/企业/707680)为提高核心竞争力，利用相应的信息技术以及[互联网技术](https://baike.baidu.com/item/互联网技术/617749)协调企业与顾客间在[销售](https://baike.baidu.com/item/销售/239410)、[营销](https://baike.baidu.com/item/营销/150434)和服务上的交互，从而提升其[管理方式](https://baike.baidu.com/item/管理方式/260899)，向客户提供创新式的个性化的客户交互和服务的过程。其最终目标是吸引新客户、保留老客户以及将已有客户转为忠实[客户](https://baike.baidu.com/item/客户/1598984)，增加市场。
>
> + [OLTP_百度百科 (baidu.com)](https://baike.baidu.com/item/OLTP/5019563?fr=aladdin)
>
>   On-Line Transaction Processing[联机事务处理](https://baike.baidu.com/item/联机事务处理)过程(OLTP)，也称为**面向交易的处理过程**，其基本特征是前台接收的用户数据可以立即传送到计算中心进行处理，并在很短的时间内给出处理结果，是对用户操作快速响应的方式之一。
>
> + [数据孤岛_百度百科 (baidu.com)](https://baike.baidu.com/item/数据孤岛/10305414?fr=aladdin)
>
>   数据孤岛在企业信息化中,还有很多类似的描述,如"数据的污染"等比较形象的说法，专业人士把数据孤岛分为物理性和逻辑性两种。**物理性的数据孤岛指的是，数据在不同部门相互独立存储，独立维护，彼此间相互孤立，形成了物理上的孤岛**。
>
> + [数据仓库_百度百科 (baidu.com)](https://baike.baidu.com/item/数据仓库/381916?fr=aladdin)
>
>   数据仓库，英文名称为Data Warehouse，可简写为[DW](https://baike.baidu.com/item/DW/1264123)或DWH。数据仓库，是为[企业](https://baike.baidu.com/item/企业/707680)所有级别的决策制定过程，提供所有类型数据支持的战略[集合](https://baike.baidu.com/item/集合)。它是单个数据存储，出于分析性报告和决策支持目的而创建。 为需要业务智能的企业，提供指导业务流程改进、监视时间、成本、质量以及控制。
>
> + [商业智能_百度百科 (baidu.com)](https://baike.baidu.com/item/商业智能/406141?fromtitle=BI&fromid=4579902&fr=aladdin)
>
>   商业智能（Business Intelligence，简称：BI），又称商业智慧或商务智能，指用现代[数据仓库技术](https://baike.baidu.com/item/数据仓库技术/10292797)、线上分析处理技术、数据挖掘和数据展现技术进行数据分析以实现商业价值。
>
>   商业智能的概念在1996年最早由[加特纳](https://baike.baidu.com/item/加特纳)集团（Gartner Group）提出，加特纳集团将商业智能定义为：商业智能描述了一系列的概念和方法，通过应用基于事实的支持系统来辅助商业决策的制定。商业智能技术提供使企业迅速分析数据的技术和方法，包括收集、管理和分析数据，将这些数据转化为有用的信息，然后分发到企业各处。
>
> + [联机分析处理_百度百科 (baidu.com)](https://baike.baidu.com/item/联机分析处理?fromtitle=OLAP&fromid=1049009)
>
>   联机分析处理OLAP是一种[软件技术](https://baike.baidu.com/item/软件技术/3313113)，它使分析人员能够迅速、一致、交互地从各个方面观察信息，以达到深入理解数据的目的。它具有FASMI(Fast Analysis of Shared Multidimensional Information)，即共享多维信息的快速分析的特征。其中F是快速性(Fast)，指系统能在数秒内对用户的多数分析要求做出反应；A是可分析性(Analysis)，指用户无需编程就可以定义新的专门计算，将其作为分析的一部 分，并以用户所希望的方式给出报告；M是多维性(Multi—dimensional)，指提供对[数据分析](https://baike.baidu.com/item/数据分析/6577123)的多维视图和分析；I是信息性(Information)，指能及时获得信息，并且管理大容量信息。

​	诸如ERP、CRM这类系统，可以看作<u>线下工作线上化</u>的过程，这也是IT时代的主要特征之一，通常我们把这类系统称为**联机事务处理（OLTP）**系统。

​	为了解决**数据孤岛**的问题，人们提出了**数据仓库**的概念。即通过引入一个专门用于分析类场景的数据库，将分散的数据统一汇聚到一处。借助数据仓库的概念，用户第一次拥有了站在企业全局鸟瞰一切数据的视角。

​	随着这个概念被进一步完善，<u>一类统一面向数据仓库，专注于提供数据分析、决策类功能的系统</u>与解决方案应运而生。最终于20世纪90年代，有人第一次提出了**BI（商业智能）**系统的概念。<u>自此以后，人们通常用BI一词指代这类分析系统</u>。相对于联机事务处理系统，我们把这类BI系统称为**联机分析（OLAP）系统**。

​	**传统BI系统**的设计初衷虽然很好，但实际的应用效果却不能完全令人满意。

+ 传统BI系统<u>对企业的信息化水平要求较高</u>。按照传统BI系统的设计思路，通常只有中大型企业才有能力实施。因为它的定位是站在企业视角通盘分析并辅助决策的，所以如果企业的信息化水平不高，基础设施不完善，想要实施BI系统根本无从谈起。这已然把许多潜在用户挡在了门外。
+ 狭小的受众制约了传统BI系统发展的生命力。传统BI系统的<u>主要受众是企业中的管理层或决策层</u>。这类用户虽然通常具有较高的话语权和决策权，但用户基数相对较小。同时他们对系统的参与度和使用度不高，久而久之这类所谓的BI系统就沦为了领导视察、演示的“特供系统”了。

+ <u>冗长的研发过程</u>滞后了需求的响应时效。传统BI系统需要大量IT人员的参与，用户的任何想法，哪怕小到只是想把一张用饼图展示的页面换成柱状图展示，可能都需要依靠IT人员来实现。一个分析需求从由用户大脑中产生到最终实现，可能需要几周甚至几个月的时间。这种严重的滞后性仿佛将人类带回到了飞鸽传书的古代。

## 1.2 现代BI系统的新思潮

> + [saas平台_百度百科 (baidu.com)](https://baike.baidu.com/item/saas平台/2147529?fr=aladdin)	=>	软件服务化(Software as a Service)
>
>   [SaaS](https://baike.baidu.com/item/SaaS)平台是运营saas软件的平台。SaaS提供商为企业搭建信息化所需要的所有[网络基础设施](https://baike.baidu.com/item/网络基础设施/5183560)及软件、硬件运作平台，并负责所有前期的实施、后期的维护等一系列服务，企业无需购买软硬件、建设[机房](https://baike.baidu.com/item/机房/5066792)、招聘IT人员，即可通过[互联网](https://baike.baidu.com/item/互联网/199186)使用信息系统。SaaS 是一种软件布局模型，其应用专为[网络](https://baike.baidu.com/item/网络/143243)交付而设计，便于用户通过互联网托管、部署及接入。
>
> + [数据立方_百度百科 (baidu.com)](https://baike.baidu.com/item/数据立方/13237096?fromtitle=数据立方体&fromid=9851963&fr=aladdin)
>
>   我们以B+树的结构建立了字段的索引，每个B+树结构的字段索引相当于一个数据平面，这样一个全局数据表与其多个重要字段的索引就组成了一个类似于立方体的数据组织结构，我们称之为“ 数据立方(DataCube)”。

​	SaaS模式的兴起，为传统企业软件系统的商业模式带来了新的思路，这是一次新的技术普惠。一方面，<u>SaaS模式将之前只服务于中大型企业的软件系统放到了互联网，扩展了它的受众；另一方面，由于互联网用户的基本特征和软件诉求，又倒逼了这些软件系统在方方面面进行革新与升级</u>。

​	技术普惠，导致现代BI系统在设计思路上发生了天翻地覆的变化。

+ 变轻：无需强制捆绑企业级数据仓库，仅Excel也可进行数据分析
+ 多元化：简单图形界面操作，无需IT专业人士操作
+ 用户体验更好：虽然仍私有化部署在企业内部，但是应答更快、操作更简单。

​	如果说SaaS化这波技术普惠为现代BI系统带来了新的思路与契机，那么背后的技术创新则保障了其思想的落地。**在传统BI系统的体系中，背后是传统的关系型数据库技术（OLTP数据库）**。

​	为了能够解决海量数据下分析查询的性能问题，人们绞尽脑汁，在数据仓库的基础上衍生出众多概念，例如：对数据进行分层，通过层层递进形成数据集市，从而减少最终查询的数据体量；提出**数据立方体**的概念，通过对数据进行预先处理，以空间换时间，提升查询性能。然而无论如何努力，设计的局限始终是无法突破的瓶颈。

​	<u>OLTP技术由诞生的那一刻起就注定不是为数据分析而生的</u>，于是很多人将目光投向了新的方向。

​	2003年起，Google陆续发表的三篇论文开启了大数据的技术普惠，Hadoop生态由此开始一发不可收拾，数据分析开启了新纪元。<u>从某种角度来看，以使用Hadoop生态为代表的这类非传统关系型数据库技术所实现的BI系统，可以称为现代BI系统</u>。换装了大马力发动机的现代BI系统在面对海量数据分析的场景时，显得更加游刃有余。然而Hadoop技术也不是银弹，在现代BI系统的构建中仍然面临诸多挑战。在海量数据下要实现多维分析的实时应答，仍旧困难重重。（现代BI系统的典型应用场景是**多维分析**，某些时候可以直接使用OLAP指代这类场景。）

## 1.3 OLAP常见架构分类

> [ClickHouse原理解析与应用实践-朱凯-微信读书 (qq.com)](https://weread.qq.com/web/reader/03532e3071e24e90035375dk6f4322302126f4922f45dec)	=>	图文来源

​	OLAP名为联机分析，又可以称为多维分析，是由关系型数据库之父埃德加·科德（Edgar Frank Codd）于1993年提出的概念。

​	为了更好地理解多维分析的概念，可以使用一个立方体的图像具象化操作。如下图所示，对于一张销售明细表，数据立方体可以进行如下操作。

+ 下钻：从高层次向低层次明细数据穿透。例如从“省”下钻到“市”，从“湖北省”穿透到“武汉”和“宜昌”。

+ 上卷：和下钻相反，从低层次向高层次汇聚。例如从“市”汇聚成“省”，将“武汉”“宜昌”汇聚成“湖北”。

+ 切片：观察立方体的一层，将一个或多个维度设为单个固定值，然后观察剩余的维度，例如将商品维度固定为“足球”。

+ 切块：与切片类似，只是将单个固定值变成多个值。例如将商品维度固定成“足球”“篮球”和“乒乓球”。

+ 旋转：旋转立方体的一面，如果要将数据映射到一张二维表，那么就要进行旋转，这就等同于行列置换。

![img](https://res.weread.qq.com/wrepub/epub_31608464_2)

为了实现上述这些操作，将常见的OLAP架构大致分成三类（ROLAP、MOLAP、HOLAP）。

+ ROLAP（Relational OLAP，关系型OLAP）

  顾名思义，它直接使用关系模型构建，数据模型常使用星型模型或者雪花模型。这是最先能够想到，也是最为直接的实现方法。因为<u>OLAP概念在最初提出的时候，就是建立在关系型数据库之上的</u>。**多维分析的操作，可以直接转换成SQL查询**。例如，通过上卷操作查看省份的销售额，就可以转换成类似下面的SQL语句：

  `SELECT SUM（价格）FROM 销售数据表 GROUP BY 省`

+ MOLAP（Multidimensional OLAP，多维型OLAP）

  它的出现是为了**缓解ROLAP性能问题**。MOLAP使用多维数组的形式保存数据，其核心思想是借助预先聚合结果，使用空间换取时间的形式最终提升查询性能。也就是说，用更多的存储空间换得查询时间的减少。**其具体的实现方式是依托立方体模型的概念**。

  **首先，对需要分析的数据进行建模，框定需要分析的维度字段；然后，通过预处理的形式，对各种维度进行组合并事先聚合；最后，将聚合结果以某种索引或者缓存的形式保存起来（通常只保留聚合后的结果，不存储明细数据）**。这样一来，在随后的查询过程中，就可以直接利用结果返回数据。

  但是这种架构也并不完美。**维度预处理可能会导致数据的膨胀**。

  这里可以做一次简单的计算，以图1-1中所示的销售明细表为例。如果数据立方体包含了5个维度（字段），那么维度组合的方式则有2<sup>5</sup> （2<sup>n</sup> ，n=维度个数）个。例如，省和市两个维度的组合就有<湖北，武汉>、<湖北、宜昌>、<武汉、湖北>、<宜昌、湖北>等。可想而知，当维度数据基数较高的时候，（高基数意味着重复相同的数据少。）其立方体预聚合后的数据量可能会达到10到20倍的膨胀。一张千万级别的数据表，就有可能膨胀到亿级别的体量。人们意识到这个问题之后，虽然也实现了一些能够降低膨胀率的优化手段，但并不能完全避免。

  另外，由于**使用了预处理的形式，数据立方体会有一定的滞后性，不能实时进行数据分析**。而且，**立方体只保留了聚合后的结果数据，导致无法查询明细数据**。

+ HOLAP（Hybrid OLAP，混合架构的OLAP）

  这种思路可以理解成ROLAP和MOLAP两者的集成。这里不再展开，我们重点关注ROLAP和MOLAP。

## 1.4 OLAP实现技术的演进

​	在介绍了OLAP几种主要的架构之后，再来看看它们背后技术的演进过程。我把这个演进过程简单划分成两个阶段。

1. 传统关系型数据库阶段

   在这个阶段中，OLAP主要基于以Oracle、MySQL为代表的一众关系型数据实现。

   + **在ROLAP架构下，直接使用这些数据库作为存储与计算的载体**；
   + **在MOLAP架构下，则借助物化视图的形式实现数据立方体**。

   在这个时期，不论是ROLAP还是MOLAP，在数据体量大、维度数目多的情况下都存在严重的性能问题，甚至存在根本查询不出结果的情况。

2. 大数据技术阶段

   由于大数据处理技术的普及，人们开始使用大数据技术重构ROLAP和MOLAP。

   + 以ROLAP架构为例，传统关系型数据库就被Hive和SparkSQL这类新兴技术所取代。虽然，以Spark为代表的分布式计算系统，相比Oracle这类传统数据库而言，在面向海量数据的处理性能方面已经优秀很多，但是直接把它们作为面向终端用户的在线查询系统还是太慢了。我们的用户普遍缺乏耐心，如果一个查询响应需要<u>几十秒甚至数分钟</u>才能返回，那这套方案就完全行不通。
   + 再看MOLAP架构，MOLAP背后也转为依托MapReduce或Spark这类新兴技术，将其作为立方体的计算引擎，加速立方体的构建过程。其预聚合结果的存储载体也转向HBase这类高性能分布式数据库。大数据技术阶段，主流MOLAP架构已经能够在亿万级数据的体量下，实现<u>毫秒级</u>的查询响应时间。尽管如此，**MOLAP架构依然存在维度爆炸、数据同步实时性不高的问题**。

​	不难发现，虽然OLAP在经历了大数据技术的洗礼之后，其各方面性能已经有了脱胎换骨式的改观，但不论是ROLAP还是MOLAP，仍然存在各自的痛点。

​	如果单纯从模型角度考虑，很明显ROLAP架构更胜一筹。因为关系模型拥有最好的“群众基础”，也更简单且容易理解。它直接面向明细数据查询，由于不需要预处理，也就自然没有预处理带来的负面影响（维度组合爆炸、数据实时性、更新问题）。那是否存在这样一种技术，它既使用ROLAP模型，同时又拥有比肩MOLAP的性能呢？

## 1.5 一匹横空出世的黑马

​	上文曾提及，以Spark为代表的新一代ROLAP方案虽然可以一站式处理海量数据，但<u>无法真正做到实时应答和高并发</u>，它更适合作为一个后端的查询系统。而<u>新一代的MOLAP方案虽然解决了大部分查询性能的瓶颈问题，能够做到实时应答，但数据膨胀和预处理等问题依然没有被很好解决</u>。除了上述两类方案之外，也有一种另辟蹊径的选择，即摒弃ROLAP和MOALP转而<u>使用搜索引擎来实现OLAP查询，ElasticSearch是这类方案的代表</u>。<u>ElasticSearch支持实时更新，在**百万级**别数据的场景下可以做到实时聚合查询</u>，但是随着数据体量的继续增大，它的查询性能也将捉襟见肘。

​	难道真的是鱼与熊掌不可兼得了吗？直到有一天，在查阅一份Spark性能报告的时候，我不经意间看到了一篇性能对比的博文。Spark的对手是一个我从来没有见过的陌生名字，在10亿条测试数据的体量下，Spark这个我心目中的绝对王者，居然被对手打得落花流水，查询响应时间竟然比对手慢数90%之多。而对手居然只使用了一台配有i5 CPU、16GB内存和SSD磁盘的普通PC电脑。我揉了揉眼睛，定了定神，这不是做梦。ClickHouse就这样进入了我的视野。

### 1.5.1 天下武功唯快不破

​	我对ClickHouse的最初印象极为深刻，其具有**ROLAP**、**在线实时查询**、**完整的DBMS**、**列式存储**、**不需要任何数据预处理**、**支持批量更新**、**拥有非常完善的SQL支持和函数**、**支持高可用**、**不依赖Hadoop复杂生态**、**开箱即用**等许多特点。特别是它那夸张的查询性能，我想大多数刚接触ClickHouse的人也一定会因为它的性能指标而动容。在一系列官方公布的基准测试对比中，ClickHouse都遥遥领先对手，这其中不乏一些我们耳熟能详的名字。

​	所有用于对比的数据库都使用了相同配置的服务器，在单个节点的情况下，对一张拥有133个字段的数据表分别在1000万、1亿和10亿三种数据体量下执行基准测试，基准测试的范围涵盖43项SQL查询。在1亿数据集体量的情况下，ClickHouse的平均响应速度是Vertica的2.63倍、InfiniDB的17倍、MonetDB的27倍、Hive的126倍、MySQL的429倍以及Greenplum的10倍。详细的测试结果可以查阅[Performance comparison of database management systems (clickhouse.tech)](https://clickhouse.tech/benchmark/dbms/)。

### 1.5.2 社区活跃

​	基本保持着每个月发布一次版本的更新频率。

## 1.6 ClickHouse的发展历程

### 1.6.1 顺理成章的MySQL时期

​	作为一款在线流量分析产品，对其功能的要求自然是分析流量了。早期的Yandex.Metrica以提供固定报表的形式帮助用户进行分析，例如分析访问者使用的设备、访问者来源的分布之类。其实这也是早期分析类产品的典型特征之一，分析维度和场景是固定的，新的分析需求往往需要IT人员参与。

​	<u>从技术角度来看，当时还处于关系型数据库称霸的时期，所以Yandex在内部其他产品中使用了MySQL数据库作为统计信息系统的底层存储软件</u>。Yandex.Metrica的第一版架构顺理成章延续了这套内部稳定成熟的MySQL方案，并将其作为它的数据存储和分析引擎的解决方案。

​	因为Yandex内部的这套MySQL方案<u>使用了MyISAM表引擎</u>，所以Yandex.Metrica也延续了表引擎的选择。这类分析场景更关注数据写入和查询的性能，不关心事务操作（MyISAM表引擎不支持事务特性）。<u>相比InnoDB表引擎，MyISAM表引擎在分析场景中具有更好的性能</u>。

​	**业内有一个常识性的认知，按顺序存储的数据会拥有更高的查询性能**。<u>因为读取顺序文件会用更少的磁盘寻道和旋转延迟时间（这里主要指机械磁盘），同时顺序读取也能利用操作系统层面文件缓存的预读功能，所以数据库的查询性能与数据在物理磁盘上的存储顺序息息相关。然而这套MySQL方案无法做到顺序存储</u>。

​	MyISAM表引擎使用B+树结构存储索引，而数据则使用另外单独的存储文件（InnoDB表引擎使用B+树同时存储索引和数据，数据直接挂载在叶子节点中）。如果只考虑单线程的写入场景，并且在写入过程中不涉及数据删除或者更新操作，那么数据会依次按照写入的顺序被写入文件并落至磁盘。然而现实的场景不可能如此简单。

​	流量的数据采集链路是这样的：<u>网站端的应用程序首先通过Yandex提供的站点SDK实时采集数据并发送到远端的接收系统，再由接收系统将数据写入MySQL集群</u>。整个过程都是实时进行的，并且数据接收系统是一个**分布式**系统，所以它们会**并行、随机**将数据写入MySQL集群。这最终导致了数据在磁盘中是完全随机存储的，并且会**产生大量的磁盘碎片**。

​	市面上一块典型的7200转SATA磁盘的IOPS（每秒能处理的请求数）仅为100左右，也就是说每秒只能执行100次随机读取。假设一次随机读取返回10行数据，那么查询100000行记录则需要至少100秒，这种响应时间显然是不可接受的。

​	**RAID可以提高磁盘IOPS性能，但并不能解决根本问题。SSD随机读取性能很高，但是考虑到硬件成本和集群规模，不可能全部采取SSD存储**。

​	随着时间的推移，MySQL中的数据越来越多（截至2011年，存储的数据超过5800亿行）。虽然Yandex又额外做了许多优化，成功地将90%的分析报告控制在26秒内返回，但是这套技术方案越来越显得力不从心。

### 1.6.2 另辟蹊径的Metrage时期

> + [LSM 算法的原理是什么？ - 知乎 (zhihu.com)](https://www.zhihu.com/question/19887265)
>
> + [Log Structured Merge Trees(LSM) 原理 - LSM - 软件开发 - 深度开源 (open-open.com)](https://www.open-open.com/lib/view/open1424916275249.html)
>
>   + LSM比传统B+树、ISAM有更好的写操作吞吐量（通过消去随机的本地更新操作来实现该目标）
>
>   + 传统注重写性能的方法，即**文件存储**（顺序写代替随机写：kafka等），但是读数据前需要维护**倒排索引**来加速读过程
>
>   + 满足复杂读场景（性能好）的传统方案：
>
>     + 二分查找: 将文件数据有序保存，使用二分查找来完成特定key的查找。
>     + 哈希：用哈希将数据分割为不同的bucket
>     + B+树：使用B+树 或者 ISAM 等方法，可以减少外部文件的读取
>     + 外部文件： 将数据保存为日志，并创建一个hash或者查找树映射相应的文件
>
>     上诉方案能够提高读性能，但是丢失了文件系统的写性能。
>
>     并且维护Hash、B+树时，时常需要更新文件系统中的特定部分（随机读写），这类操作较慢，也是我们需要尽量减少的。
>
>   所以这就是 LSM 被发明的原理， <u>LSM 使用一种不同于上述四种的方法，保持了日志文件写性能，以及微小的读操作性能损失。**本质上就是让所有的操作顺序化，而不是像散弹枪一样随机读写**</u>。
>
>   + 其他具体的描述看原文.....
>
>   + 关于LSM的思考：
>
>     + LSM有更好的写性能，同时LSM还有其它一些好处。 
>
>       **sstable文件是不可修改的，这让对他们的锁操作非常简单**。一般来说，唯一的竞争资源就是 memtable，相对来说需要相对复杂的锁机制来管理在不同的级别。
>
>     + 所以最后的问题很可能是**以写为导向的压力预期**如何。
>
>       如果你对LSM带来的写性能的提高很敏感，这将会很重要。大型互联网企业似乎很看中这个问题。 <u>Yahoo 提出因为事件日志的增加和手机数据的增加，工作场景为从 read-heavy 到 read-write。许多传统数据库产品似乎更青睐读优化文件结构。</u>
>
>     + 因为可用的内存的增加，通过操作系统提供的大文件缓存，读操作自然会被优化。
>
>       **写性能（内存不可提高）因此变成了主要的关注点**，所以采取其它的方法，<u>硬件提升为读性能做的更多，相对于写来说。因此选择一个**写优化的文件结构**很有意义</u>。
>
>     理所当然的，LSM的实现，像LevelDB和Cassandra提供了更好的写性能，相对于单树结构的策略。
>
>   + 上述文章内的**总结**（原文自带的总结，非原创）：
>
>     ​	所以， LSM 是日志和传统的单文件索引（B+ tree，Hash Index）的中立，他提供一个机制来管理更小的独立的索引文件(sstable)。
>
>     ​	**通过管理一组索引文件而不是单一的索引文件，LSM 将B+树等结构昂贵的随机IO变的更快，而代价就是读操作要处理大量的索引文件(sstable)而不是一个，另外还是一些IO被合并操作消耗。**
>
>     ​	如果还有不明白的，这还有一些其它的好的介绍。 [here](https://www.open-open.com/misc/goto?guid=4959627134870208906) and [here](https://www.open-open.com/misc/goto?guid=4958194564427775209)
>
> + [LSM、B 树、B+树、B*对比 - 简书 (jianshu.com)](https://www.jianshu.com/p/3fb899684392) => 图文并茂，推荐阅读（<= 下面文字来自原文）
>
>   ​	LSM树（Log-Structured MergeTree）存储引擎和B+树存储引擎一样，同样支持增、删、读、改、顺序扫描操作。而且通过批量存储技术规避磁盘随机写入问题。当然凡事有利有弊，LSM树和B+树相比，LSM树牺牲了部分读性能，用来大幅提高写性能。
>
>   + LSM树核心思想的核心就是放弃部分读能力，换取写入的最大化能力。LSM Tree ，这个概念就是结构化合并树的意思，它的核心思路其实非常简单，就是假定内存足够大，因此不需要每次有数据更新就必须将数据写入到磁盘中，而可以先将最新的数据驻留在内存中，等到积累到足够多之后，再使用归并排序的方式将内存内的数据合并追加到磁盘队尾(因为所有待排序的树都是有序的，可以通过合并排序的方式快速合并到一起)。
>
>   + 日志结构的合并树（LSM-tree）是一种基于硬盘的数据结构，与B+tree相比，能显著地减少硬盘磁盘臂的开销，并能在较长的时间提供对文件的高速插入（删除）。**然而LSM-tree在某些情况下，特别是在查询需要快速响应时性能不佳。**通常LSM-tree适用于索引插入比检索更频繁的应用系统。
>
>   + LSM树和B+树的差异主要在于读性能和写性能进行权衡。在牺牲的同时寻找其余补救方案：
>
>     1. LSM具有批量特性，存储延迟。当写读比例很大的时候（写比读多），LSM树相比于B树有更好的性能。因为**随着insert操作，为了维护B+树结构，节点分裂。读磁盘的随机读写概率会变大，性能会逐渐减弱**。
>
>     2. B树的写入过程：对B树的写入过程是一次原位写入的过程，主要分为两个部分，首先是查找到对应的块的位置，然后将新数据写入到刚才查找到的数据块中，然后再查找到块所对应的磁盘物理位置，将数据写入去。当然，在内存比较充足的时候，因为B树的一部分可以被缓存在内存中，所以查找块的过程有一定概率可以在内存内完成，不过为了表述清晰，我们就假定内存很小，只够存一个B树块大小的数据吧。可以看到，在上面的模式中，需要两次随机寻道（一次查找，一次原位写），才能够完成一次数据的写入，代价还是很高的。
>
>     3. LSM优化方式：
>
>        a. **Bloom filter**: 就是个带随机概率的bitmap,可以快速的告诉你，某一个小的有序结构里有没有指定的那个数据的。于是就可以不用二分查找，而只需简单的计算几次就能知道数据是否在某个小集合里啦。效率得到了提升，但付出的是空间代价。
>         b. compact:小树合并为大树:因为小树性能有问题，所以要有个进程不断地将小树合并到大树上，这样大部分的老数据查询也可以直接使用log2N的方式找到，不需要再进行(N/m)*log2n的查询了

​	由于MySQL带来的局限性，Yandex自研了一套全新的系统并命名为Metrage。Metrage在设计上与MySQL完全不同，它选择了另外一条截然不同的道路。

+ 首先，**在数据模型层面，它使用Key-Value模型（键值对）**代替了关系模型；
+ 其次，**在索引层面，它使用LSM树代替了B+树**；
+ 最后，**在数据处理层面，由实时查询的方式改为了预处理的方式**。 

​	LSM树也是一种非常流行的索引结构，发源于Google的BigTable，**现在最具代表性的使用LSM树索引结构的系统是HBase**。

​	LSM本质上可以看作将原本的一棵大树拆成了许多棵小树，每一批次写入的数据都会经历如下过程。

+ 首先，会在内存中构建出一棵小树，构建完毕即算写入成功（这里会通过**预写日志**的形式，防止因内存故障而导致的数据丢失）。写入动作只发生在内存中，不涉及磁盘操作，所以极大地提升了数据写入性能。
+ 其次，**小树在构建的过程中会进行排序**，这样就保证了数据的有序性。
+ 最后，当内存中小树的数量达到某个阈值时，就会借助后台线程将小树刷入磁盘并生成一个小的数据段。**在每个数据段中，数据局部有序**。也正因为数据有序，所以能够进一步使用稀疏索引来优化查询性能。

​	借助LSM树索引，可使得Metrage引擎在软硬件层面同时得到优化（**磁盘顺序读取、预读缓存、稀疏索引**等），最终有效提高系统的综合性能。

​	如果仅拥有索引结构的优化，还不足以从根本上解决性能问题。Metrage设计的第二个重大转变是通过**预处理**的方式，<u>将需要分析的数据预先聚合</u>。这种做法类似数据立方体的思想，

+ 首先对分析的具体场景实施立方体建模，框定所需的维度和度量以形成数据立方体；
+ 接着预先计算立方体内的所有维度组合；
+ 最后将聚合的结果数据按照Key-Value的形式存储。

​	这样一来，对于固定分析场景，就可以直接利用数据立方体的聚合结果立即返回相关数据。这套系统的实现思路和现今的一些MOLAP系统如出一辙。

​	通过上述一系列的转变，Metrage为Yandex.Metrica的性能带来了革命性提升。截至2015年，在Metrage内存储了超过3万亿行的数据，其集群规模超过了60台服务器，查询性能也由先前的26秒降低到了惊人的1秒以内。

​	**然而，使用立方体这类预先聚合的思路会带来一个新的问题，那就是维度组合爆炸，因为需要预先对所有的维度组合进行计算**。

​	那么**维度组合的方式具体有多少种呢？它的计算公式是2<sup>N</sup> （N=维度数量）**。

​	可以做一次简单的计算，例如5个维度的组合方式会有2<sup>5</sup></sup> =32种，而9个维度的组合方式则会多达2<sup>9</sup> =512种，这是一种指数级的增长方式。**维度组合的爆炸会直接导致数据膨胀，有时候这种膨胀可能会多达10～20倍**。

### 1.6.3 自我突破的OLAPServer时期

