# 数据密集型应用系统设计-学习笔记

# 第一部分 数据系统基础

​	本书前4章总结了适用于所有数据系统的基本思想，既包括单机运行环境，也包括分布式集群环境：

1. 第1章介绍相关术语与方法，这些术语等将贯穿于全书。例如重点关注的可靠性、可扩展性与可维护性设计目标，以及达到这些目标的基本方法。
2. 第2章对比多种不同的数据模型与査询语言，从开发者角度来看，这些是不同数据库系统最显著的区别，我们也会讨论不同模型的具体适用场景。
3. 第3章深入数据库系统内部的核心存储引擎，详细解析数据库如何设计磁盘布局。针对不同的工作负载如何优化其引擎，而正确的设计选型对系统将产生巨大的影响。
4. 第4章比较不同的数据编码格式和序列化技术，特别是当上层应用需求多变而模型也需要灵活调整时，该如何最佳使用这些技术。

​	之后，在第二部分，我们将转向分布式场景下的一些典型问题和解决方案。

+ 可靠性：容忍硬件、软件失效，人为错误

+ 可扩展性：评测负载与性能，延迟百分位数，吞吐量
+ 可维护性：可运维、简单与可演化性

# 第1章 可靠、可扩展与可维护的系统

​	<u>当今许多新型应用都属于数据密集型(data-intensive)，而不是计算密集型(compute-intensive)</u>。对于这些类型应用，CPU的处理能力往往不是第一限制性因素，关键在于数据量、数据的复杂度及数据的快速多变性。

​	数据密集型应用通常也是基于标准模块构建而成，毎个模块负责单一的常用功能。例如，许多应用系统都包含以下模块：

+ 数据库：用以存储数据，这样之后应用可以再次访问。
+ 高速缓存：缓存那些复杂或操作代价昂贵的结果，以加快下一次访问。
+ 索引：用户可以按关键字搜索数据并支持各种过滤。
+ 流式处理：持续发送消息至另一个进程，处理采用异步方式。
+ 批处理：定期处理大量的累积数据。

## 1.1 认识数据系统

​	越来越多的应用系统需求广泛，单个组件往往无法满足所有数据处理与存储需求。因而需要将任务分解，每个组件负责高效完成其中一部分，多个组件依靠应用层代码驱动有机衔接起来。

​	影响数据系统设计的因素有很多，其中包括相关人员技能和经验水平、遗留系统依赖性、交付周期、对不同风险因素的容忍度、监管合规等。这些因素往往因时因地而异。本书将专注于对大多数软件系统都极为重要的三个问题：

+ 可靠性(Reliability)

  当出现意外情况如硬件、软件故障、人为失误等，系统应可以继续正常运转：虽然性能可能有所降低，但确保功能正确。具体请参阅本章后面的“可靠性”一节。

+ 可扩展性(Scalability)

  随着规模的增长，例如数据量、流量或复杂性，系统应以合理的方式来匹配这种增长，具体请参阅本章后面的“可扩展性”一节。

+ 可维护性(Maintainability)

  随着时间的推移，许多新的人员参与到系统开发和运维，以维护现有功能或适配新场景等，系统都应高效运转。具体请参阅本章后面的“可维护性”一节。

​	很多人对上述目标还欠缺深入的理解。追本溯源，本章后续部分将深入思考可靠性、可扩展性和可维护性，并将介绍各种技术、架构以及算法来实现这些目标。

## 1.2 可靠性

​	每个人脑子里都有一个直观的认识，即什么意味着可靠或者不可靠。对于软件，典型的期望包括：

+ 应用程序执行用户所期望的功能。
+ 可以容忍用户出现错误或者不正确的软件使用方法。
+ 性能可以应对典型场景、合理负载压力和数据量。
+ 系统可防止任何未经授权的访问和滥用。

​	如果所有上述目标都要支持才算“正常工作”，那么我们可以认为可靠性大致意味着：即使发生了某些错误，系统仍可以继续正常工作。

​	可能出错的事情称为错误(faults)或故障，系统可应对错误则称为容错(fault-tolerant)或者弹性(resilient)。前一个词略显误导：似乎暗示着系统可以容忍各种可能的故障类型，显然实际中这是不可能的。举一个夸张一些的例子，如果整个地球(及其上的所有服务器)都被黑洞吞噬，那么要在这个级别容错就意味着必须在宇宙范围内进行系统冗余。试想，这将是天价的预算。<u>因此，容错总是指特定类型的故障，这样的系统才更有实际意义</u>。

​	注意，故障与失效(failure)不完全一致。<u>故障通常被定义为组件偏离其正常规格，而失效意味系统作为一个整体停止，无法向用户提供所需的服务</u>。我们不太可能将故障概率降低到零，因此通常设计容错机制来避免从故障引发系统失效。本书将介绍在不可靠组件基础上构建可靠性系统的相关技术。

​	<u>在这种容错系统中，用于测试目的，可以故意提高故障发生概率，例如通过随机杀死某个进程，来确保系统仍保持健壮</u>。很多关键的bug实际上正是由于错误处理不当而造成的旳。通过这种故意引发故障的方式，来持续检验、测试系统的容错机制，增加对真实发生故障时应对的信心。 Netflix的 Chaos Monkey系统就是这种测试的典型例子。

​	<u>虽然我们通常倾向于容忍故障而不是预防故障，但是也存在“预防胜于治疗”的情况，安全问题就是一例，例如：如果攻击者破坏了系统并窃取了敏感数据，则该事件造成的影响显然无法被撤销</u>。然而，本书主要针对那些影响可以被消除的故障类型，接下来详细介绍。

### 1.2.1 硬件故障

​	当我们考虑系统故障时，<u>对于硬件故障总是很容易想到：硬盘崩溃，内存故障，电网停电，甚至有人误拔掉了网线</u>。任何与大型数据中心合作过的人都可以告诉你，当有很多机器时，这类事情迟早会发生。

​	有研究证明硬盘的平均无故障时间(MTTF)约为10~50年。因此，在一个包括10000个磁盘的存储集群中，我们应该预期平均每天有一个磁盘发生故障。

​	<u>我们的第一个反应通常是为硬件添加冗余来减少系统故障率。例如对磁盘配置RAID，服务器配备双电源，甚至热插拔CPU，数据中心添加备用电源、发电机等。当一个组件发生故障，冗余组件可以快速接管，之后再更换失效的组件</u>。这种方法可能并不能完全防止硬件故障所引发的失效，但还是被普遍采用，且在实际中也确实可以让系统不间断运行长达数年。

​	直到最近，采用硬件冗余方案对于大多数应用场景还是足够的，它使得单台机器完全失效的概率降为非常低的水平。只要可以将备份迅速恢复到新机器上，故障的停机时间在大多数应用中并不是灾难性的。而多机冗余则只对少量的关键应用更有意义，对于这些应用，高可用性是绝对必要的。

​	但是，随着数据量和应用计算需求的增加，更多的应用可以运行在大规模机器之上，随之而来的硬件故障率呈线性增长。例如，对于某些云平台(如 Amazon webServices，AwS)，由于系统强调的是总体灵活性与弹性而非单台机器的可靠性，虚拟机实例经常会在事先无告警的情况下出现无法访问问题。

​	因此，通过软件容错的方式来容忍多机失效成为新的手段，或者至少成为硬件容错的有力补充。这样的系统更具有操作便利性，<u>例如当需要重启计算机时为操作系统打安全补丁，可以每次给一个节点打补丁然后重启，而不需要同时下线整个系统(即滚动升级，详见第4章)</u>。

### 1.2.2 软件错误

​	<u>我们通常认为硬件故障之间多是相互独立的：一台机器的磁盘出现故障并不意味着另一台机器的磁盘也要失效</u>。除非存在某种弱相关(例如一些共性原因，如服务器机架中的温度过高)，否则通常不太可能出现大量硬件组件同时失效的情况。

​	<u>另一类故障则是系统内的软件问题。这些故障事先更加难以预料，而且因为节点之间是由软件关联的，因而往往会导致更多的系统故障</u>。例如：

+ 由于软件错误，导致当输入特定值时应用服务器总是崩溃。例如，2012年6月30日发生闰秒，由于Linux内核中的一个bug，导致了很多应用程序在该时刻发生挂起。
+ 一个应用进程使用了某些共享资源如CPU、内存、磁盘或网络带宽，但却不幸失控跑飞了。
+ 系统依赖于某些服务，但该服务突然变慢，甚至无响应或者开始返回异常的响应。
+ 级联故障，其中某个组件的小故障触发另一个组件故障，进而引发更多的系统问题。

​	导致软件故障的bug通常会长时间处于引而不发的状态，直到碰到特定的触发条件。这也意味着系统软件其实对使用环境存在某种假设，而这种假设多数情况都可以满足，但是在特定情况下，假设条件变得不再成立。

​	软件系统问题有时没有快速解决办法，而只能仔细考虑很多细节，包括认真检査依赖的假设条件与系统之间交互，进行全面的测试，进程隔离，允许进程崩溃并自动重启，反复评估，监控并分析生产环节的行为表现等。<u>如果系统提供某些保证，例如在消息队列中，输岀消息的数量应等于输入消息的数量，则可以不断地检査确认，如发现差异则立即告警</u>。

### 1.2.3 人为失误

​	设计和构建软件系统总是由人类完成，也是由人来运维这些系统。即使有时意图是好的，但人却无法做到万无一失。例如，一项针对大型互联网服务的调查发现，<u>运维者的配置错误居然是系统下线的首要原因，而硬件问题(服务器或网络)仅在10%~25%的故障中有所影响</u>。

​	如果我们假定人是不可靠的，那么该如何保证系统的可靠性呢?可以尝试结合以下多种方法：

+ 以最小出错的方式来设计系统。例如，精心设计的抽象层、API以及管理界面，使“做正确的事情”很轻松，但搞坏很复杂。但是，如果限制过多，人们就会想法来绕过它，这会抵消其正面作用。因此解决之道在于很好的平衡。
+ 想办法分离最容易出错的地方、容易引发故障的接口。特别是，提供一个功能齐全但非生产用的沙箱环境，使人们可以放心的尝试、体验，包括导入真实的数据，万一出现问题，不会影响真实用户。
+ <u>充分的测试：从各单元测试到全系统集成测试以及手动测试。自动化测试已被广泛使用，对于覆盖正常操作中很少出现的边界条件等尤为重要。</u>
+ <u>当出现人为失误时，提倛快速的恢复机制以尽量减少故障影响</u>。例如，快速回滚配置改动，滚动发布新代码(这样任何意外的错误仅会影响一小部分用户)，并提供校验数据的工具(防止旧的计算方式不正确)。
+ <u>设置详细而清晰的监控子系统，包括性能指标和错误率</u>。在其他行业称为遥测(Telemetry)，一旦火箭离开地面，遥测对于跟踪运行和了解故障至关重要监控可以向我们发送告警信号，并检查是否存在假设不成立或违反约束条件等。这些检测指标对于诊断问题也非常有用。
+ 推行管理流程并加以培训。这非常重要而且比较复杂，具体内容已超出本书范围。

### 1.2.4 可靠性的重要性

​	可靠性绝不仅仅针对的是核电站和空中交管软件之类的系统，很多应用都需要可靠工作。商业软件中的错误会导致效率下降(如数据报告错误，甚至带来法律风险)，电子商务网站的暂停会对营收和声誉带来巨大损失。

​	即使在所谓“非关键”应用中，我们也应秉持对用户负责的态度。例如一对父母，将其所有的照片以及他们孩子的视频存放在你的照片应用中。如果不幸发生了数据库损坏，他们的感受可想而知，他们是否知道该如何从备份数据来执行恢复?

​	当然，也会存在其他一些情况，例如面对不太确定的市场开发原型系统，或者服务的利润微薄，有时也会牺牲一些可靠性来降低开发成本或者运营开销，对此，我们总是建议务必三思后行。

## 1.3 可扩展性

​	即使系统现在工作可靠，并不意味着它将来一定能够可靠运转。发生退化的一个常见原因是负载增加：例如也许并发用户从最初的10000个增长到100000个，或从100万到1000万；又或者系统目前要处理的数据量超出之前很多倍。

​	可扩展性是用来描述系统应对负载增加能力的术语。但是请注意，它并不是衡量一个系统的一维指标，谈论“X是可扩展”或“Y不扩展”没有太大意义。相反，<u>讨论可扩展性通常要考虑这类问题：“如果系统以某种方式增长，我们应对增长的措施有哪些”，“我们该如何添加计算资源来处理额外的负载”</u>。

### 1.3.1 描述负载

​	首先，我们需要简洁地描述系统当前的负载，只有这样才能更好地讨论后续增长问题(例如负载加倍会意味着什么)。负载可以用称为负载参数的若干数字来描述。参数的最佳选择取决于系统的体系结构，它可能是Web服务器的每秒请求处理次数，数据库中写入的比例，聊天室的同时活动用户数量，缓存命中率等。<u>有时平均值很重要，有时系统瓶颈来自于少数峰值</u>。

​	我们以Twitter为例，使用其2012年11月发布的数据。 Twitter两个典型业务操作是：

+ 发布tweet消息：用户可以快速推送新消息到所有的关注者，平均大约4.6k request/sec，峰值约12k requests/sec
+ 主页时间线(Home timeline)浏览：平均300k request/sec查看关注对象的最新消息。

​	仅仅处理峰值约12k的消息发送听起来并不难，但是， Twitter扩展性的挑战重点不在于消息大小，而在于巨大的扇出(fan-out)串结构：每个用户会关注很多人，也会被很多人圈粉。此时大概有两种处理方案：

1. 将发送的新tweet插入到全局的tweet集合中。当用户查看时间线时，首先查找所有的关注对象，列出这些人的所有tweet，最后以时间为序来排序合并。如果以下图的关系型数据模型，可以执行下述的 SQL 查询语句：

   ```sql
   SELECT tweets.*,users.* FROM tweets
   JOIN users ON tweets.sender_id = users.id
   JOIN follows ON follows.followee_id = users.id
   WHERE follows.follower_id = current_user
   ```

   ![image.png](https://image-static.segmentfault.com/132/745/1327458763-60167c5753ce0)

2. 对每个用户的时间线维护一个缓存，如图所示，类似每个用户一个 tweet邮箱。当用户推送新 tweet 时，查询其关注者，将tweet插入到每个关注者的时间线缓存中。因为已经预先将结果取出，之后访问时间线性能非常快。

   ![image.png](https://image-static.segmentfault.com/872/753/87275316-60167ced9cac3)

​	Twitter 在其第一个版本使用了方法1，但发现主页时间线的读负载压力与日俱增，系统优化颇费周折，因此转而采用第二种方法。实践发现这样更好，<u>因为时间线浏览 tweet 的压力几乎比发布tweet 要高出两个数量级</u>，基于此，在发布时多完成一些事情可以加速读性能。

​	然而，方法2的缺点也很明显，在发布 tweet 时增加了大量额外的工作。考虑平均 75 个关注者和每秒 4.6k 的 tweet，则需要每秒 4.6k × 75 = 345k 速率写入缓存。但是，75 这个平均关注者背后还隐藏其他事实，即关注者其实偏差巨大，例如某些用户拥有超过 3000 万的追随者。这就意味着峰值情况下一个 tweet 会导致 3000 万笔写入！而且要求尽量快，Twitter 的设计目标是 5s 内完成，这成为一个巨大的挑战。

​	在Twitter的例子中，<u>每个用户关注者的分布情况（还可以结合用户使用 Twitter 频率情况进行加权）是该案例可扩展的关键负载参数，因为它决定了扇出数。其他应用可能具有不同的特性，但可以采用类似的原则来研究具体负载</u>。

​	Twitter 故事最后的结局是：方法 2 已经得到了稳定实现，Twitter 正在转向结合两种方法。<u>大多数用户的 tweet 在发布时继续以一对多写入时间线，但是少数具有超多关注者的用户除外，对这些用户采用类似方案 1，其推文被单独提取，在读取时才和用户的时间线主表合并。这种混合方法能够提供始终如一的良好表现</u>。在我们介绍诸多技术基础之后，我们将在第12章重新审视该例子。

### 1.3.2 描述性能

​	描述系统负载之后，接下来设想如果负载增加将会发生什么。有两种考虑方式：

+ 负载增加，但系统资源(如CPU、内存、网络带宽等)保持不变，系统性能会发生什么变化?
+ 负载增加，如果要保持性能不变，需要增加多少资源?

​	这两个问题都会关注性能指标，所以我们先简要介绍一下如何描述系统性能。在批处理系统如Hadoop中，我们通常关心<u>**吞吐量(throughput)**，即每秒可处理的记录条数，或者在某指定数据集上运行作业所需的总时间</u>；而在线系统通常更看重服务的**响应时间(response time)**，即客户端从发送请求到接收响应之间的间隔。

> **延迟与响应时间**
>
> 延迟(latency)和响应时间(response time)容易混淆使用，但它们并不完全一样。
>
> + <u>通常响应时间是客户端看到的：除了处理请求时间(服务时间， service time)外，还包括来回网络延迟和各种排队延迟</u>。
> + <u>延迟则是请求花费在处理上的时间</u>。

​	即使是反复发送、处理相同的请求，每次可能都会产生略微不同的响应时间。实际情况往往更复杂，由于系统要处理各种不同的请求，响应时间可能变化很大。因此，最好不要将响应时间视为一个固定的数字，而是可度量的一种数值分布。

​	一个例子如图所示，每个灰色条表示一个服务请求，高度表示该请求的响应时间。可以看到，大多数请求是相当快的，但偶尔会有异常表示需要更长的时间。也许这些异常请求确实代价很高，例如它们的数据大很多。但有时，即使所有请求都相同，也会由于其他变量因素而引入一些随机延迟抖动，<u>这些因素包括上下文切换和进程调度、网络数据包丢失和TCP重传、垃圾回收暂停、缺页中断和磁盘IO，甚至服务器机架的机械振动</u>。

​	我们经常考察的是服务请求的平均响应时间(严格来说，术语“平均值”并没有明确釆用何种具体公式，但通常被理解为算术平均值：给定n个值，将所有值相加，并除以n)。然而，如果想知道更典型的响应时间，平均值并不是合适的指标，因为它掩盖了一些信息，无法告诉有多少用户实际经历了多少延迟。

​	<u>因此最好使用百分位数(percentiles)。如果已经搜集到了响应时间信息，将其从最快到最慢排序，中位数(median)就是列表中间的响应时间</u>。例如，如果中位数响应时间为200ms，那意味着有一半的请求响应不到200ms，而另一半请求则需要更长的时间。

​	<u>中位数指标非常适合描述多少用户需要等待多长时间：一半的用户请求的服务时间少于中位数响应时间，另一半则多于中位数的时间。**因此中位数也称为50百分位数，有时缩写为p50**</u>。请注意，中位数对应单个请求；这也意味着如果某用户发了多个请求(例如包含在一个完整会话过程中，或者因为某页面包含了多个资源)，那么它们中至少一个比中位数慢的概率远远大于50%。

​	为了弄清楚异常值有多糟糕，<u>需要关注更大的百分位数如常见的第95、99和99.9(缩写为p95、p99和p999)值。作为典型的响应时间阈值，它们分别表示有95%、99%或99.9%的请求响应时间快于阈值</u>。例如，如果95百分位数响应时间为1.5，这意味着100个请求中的95个请求快于1.5s，而5个请求则需要1.5s或更长时间，如图1-4所示。

​	**采用较高的响应时间百分位数(tail latencies，尾部延迟或长尾效应)很重要，因为它们直接影响用户的总体服务体验**。<u>例如，亚马逊采用99.9百分位数来定义其内部服务的响应时间标准，或许它仅影响1000个请求中的1个。但是考虑到请求最慢的客户往往是购买了更多的商品，因此数据量更大换言之，他们是最有价值的客户</u>。让这些客户始终保持愉悦的购物体验显然非常重要：亚马逊还注意到，响应时间毎增加100ms，销售额就会下降了约1%，其他研究则表明，1s的延迟增加等价于客户满意度下降16%。

​	另一方面，也有人说，优化这个99.99百分位数(10000个请求中最慢的1个)代价昂贵，并没有为亚马逊的商业目标带来足够的收益。进一步提高响应时间技术上代价更大，很容易受到非可控因素如随机事件的影响，累积优势会减弱。

​	例如，**百分位数通常用于措述、定义服务质量目标(Service Level Objectives，SLO)和服务质量协议(Servie Level Agreements，SLA)，这些是规定服务预期质量和可用性的合同**。例如一份SLA合约通常会声明，响应时间中位数小于200ms，99%请求的响应时间小于1s，且要求至少99.9%的时间都要达到上述服务指标。这些指标明确了服务质量预期，并允许客户在不符合SLA的情况下进行赔偿。

​	排队延迟往往在高百分数响应时间中影响很大。<u>由于服务器并行处理的请求有限(例如，CPU内核数的限制)，正在处理的少数请求可能会阻挡后续请求，这种情况有时被称为**队头阻塞**</u>。即使后续请求可能处理很简单，但它阻塞在等待先前请求的完成，客户端将会观察到极慢的响应时间。

​	因此，很重要的一点是要在客户端来测量响应时间。因此，当测试系统可扩展性而人为产生负载时，负载生成端要独立于响应时间来持续发送请求。<u>如果客户端在发送请求之前总是等待先前请求的完成，就会在测试中人为地缩短了服务器端的累计队列深度，这就带来了测试偏差</u>。

### 1.3.3 应对负载增加的方法

​	我们已经讨论了描述负载的参数以及衡量性能的相关指标，接下来讨论可扩展性：即当负载参数增加时，应如何保持良好性能?

> 实践中的百分位数
>
> 对于后台服务，如果一次完整的服务里包含了多次请求调用，此时高百分位数指标尤为重要。即使这些子请求是并行发送、处理，但最终用户仍然需要等待最慢的那个调用完成才行。<u>哪怕一个缓慢的请求处理，即可拖累整个服务</u>。即使只有很小百分比的请求缓慢，如果某用户总是频繁产生这种调用，最终总体变慢的概率就会增加(即长尾效应)。
>
> 最好将响应时间百分位数添加到服务系统监控中，持续跟踪该指标。例如，设置个10min的滑动窗口，监控其中响应时间，滚动计算窗口中的中位数和各种百分位数，然后绘制性能图表。
>
> 一种简单的实现方案是在时间窗口内保留所有请求的响应时间列表，每分钟做次排序。如果这种方式效率太低，可以采用一些近似算法(如正向衰减，t-digest 或 Hdrhistogram)来计算百分位数，其CPU和内存开销很低。同时请注意，降低采样时间精度或直接组合来自多台机器的数据，在数学上没有太大意义，聚合响应时间的正确方法是采用直方图。

​	首先，针对特定级别负载而设计的架构不太可能应付超出预设目标10倍的实际负载。**如果目标服务处于快速增长阶段，那么需要认真考虑每增加一个数量级的负载，架构应如何设计**。

​	现在谈论更多的是**如何在垂直扩展(即升级到更强大的机器)和水平扩展(即将负载分布到多个更小的机器)之间做取舍**。在多台机器上分配负载也被称为**无共享体系结构**。在单台机器上运行的系统通常更简单，然而高端机器可能非常昂贵，且扩展水平有限，最终往往还是无法避免需要水平扩展。实际上，好的架构通常要做些实际取舍，例如，使用几个强悍的服务器仍可以比大量的小型虛拟机来得更简单、便宜。

​	某些系统具有弹性特征，它可以自动检测负载增加，然后自动添加更多计算资源，而其他系统则是手动扩展(人工分析性能表现，之后决定添加更多计算)。<u>如果负载高度不可预测，则自动弹性系统会更加高效，但或许手动方式可以减少执行期间的意外情况</u>(参阅第6章的“分区再平衡”)。

​	**把无状态服务分布然后扩展至多台机器相对比较容易，而有状态服务从单个节点扩展到分布式多机环境的复杂性会大大增加**。<u>出于这个原因，直到最近通常的做法一直是，将数据库运行在一个节点上(采用垂直扩展策略)，直到高扩展性或高可用性的要求迫使不得不做水平扩展</u>。

​	然而，随着相关分布式系统专门组件和编程接口越来越好，至少对于某些应用类型来讲，上述通常做法或许会发生改变。可以乐观设想，即使应用可能并不会处理大量数据或流量，但未来分布式数据系统将成为标配。在本书后续部分，我们将介绍多种分布式数据系统，不仅可以帮助提高可扩展性，也会提高易用性与可维护性。

​	超大规模的系统往往针对特定应用而高度定制，很难有一种通用的架构。背后取舍因素包括数据读取量、写入量、待存储的数据量、数据的复杂程度、响应时间要求、访问模式等，或者更多的是上述所有因素的叠加，再加上其他更复杂的问题。

​	例如，即使两个系统的数据吞吐量折算下来是一样的，但是为每秒处理1000次请求(每个大小为1KB)而设计的系统，与为每分钟3个请求(每个大小为2GB)设计的系统会大不相同。

​	对于特定应用来说，扩展能力好的架构通常会做出某些假设，然后有针对性地优化设计，如哪些操作是最频繁的，哪些负载是少数情况。如果这些假设最终发现是错误的，那么可扩展性的努力就白费了，甚至会出现与设计预期完全相反的情况。<u>对于早期的初创公司或者尚未定型的产品，快速迭代推出产品功能往往比投入精力来应对不可知的扩展性更为重要</u>。

​	可扩展架构通常都是从通用模块逐步构建而来，背后往往有规律可循，所以本书将会讨论这些通用模块和常见模式，希望对读者有所借鉴。

## 1.4 可维护性

​	众所周知，<u>软件的大部分成本并不在最初的开发阶段，而是在于整个生命周期内持续的投入，这包括维护与觖陷修复，监控系统来保持正常运行、故障排査、适配新平台、搭配新场景、技术缺陷的完善以及增加新功能等</u>。

​	不幸的是，许多从业人根本不喜欢维护这些所谓的遗留系统，例如修复他人埋下的错误，或者使用过时的开发平台，或者被迫做不喜欢的工作。坦白说，每一个遗留系统总有其过期的理由，所以很难给出一个通用的建议该如何处理它们。

​	但是，换个角度，我们可以从软件设计时开始考虑，尽可能较少维护期间的麻烦，甚至避免造出容易过期的系统。为此，我们将特别关注软件系统的三个设计原则：

+ 可运维性

  方便运营团队来保持系统平稳运行。

+ 简单性

  简化系统复杂性，使新工程师能够轻松理解系统。注意这与用户界面的简单性并不一样。

+ 可演化性

  后续工程师能够轻松地对系统进行改进，并根据需求变化将其适配到非典型场景，也称为可延伸性、易修改性或可塑性。

​	与可靠性和可扩展性类似，实现上述这些目标也没有简单的解决方案。接下来，我们首先建立对这三个特性的理解。

### * 1.4.1 可运维性：运维更轻松

​	有人认为，“良好的操作性经常可以化解软件的局限性，而不规范的操作则可以轻松击垮软件”。虽然某些操作可以而且应该是自动化的，但最终还是需要人来执行配置并确保正常工作。

​	运营团队对于保持软件系统顺利运行至关重要。一个优秀的运营团队通常至少负责以下内容：

+ 监视系统的健康状况，并在服务出现异常状态时快速恢复服务。
+ 追踪问题的原因，例如系统故障或性能下降。

+ 保持软件和平台至最新状态，例如安全补丁方面。
+ 了解不同系统如何相互影响，避免执行带有破坏性的操作，预测未来可能的问题，并在问题发生之前即使解决(例如容量规划)。
+ 建立用于部署、配置管理等良好的实践规范和工具包。
+ 执行复杂的维护任务，例如将应用程序从一个平台迁移到另一个平台。
+ 当配置更改时，维护系统的安全稳健。
+ 制定流程来规范操作行为，并保持生产环境稳定。
+ 保持相关知识的传承(如对系统理解)，例如发生团队人员离职或者新员工加入等。

​	良好的可操作性意味着使日常工作变得简单，使运营团队能够专注于高附加值的任务。数据系统设计可以在这方面贡献很多，包括：

+ 提供对系统运行时行为和内部的可观测性，方便监控。
+ 支持自动化，与标准工具集成。
+ 避免绑定特定的机器，这样在整个系统不间断运行的同时，允许机器停机维护。
+ 提供良好的文档和易于理解的操作模式，诸如“如果我做了X，会发生Y”。
+ 提供良好的默认配置，且允许管理员在需要时方便地修改默认值。
+ 尝试自我修复，在需要时让管理员手动控制系统状态。
+ 行为可预测，减少意外发生。

### 1.4.2 简单性：简化复杂度

​	小型软件项目通常可以写出简单而漂亮的代码，但随着项目越来越大，就会越来越复杂和难以理解。这种复杂性拖慢了开发效率，增加了维护成本。一个过于复杂的软件项目有时被称为一个“大泥潭“。

​	<u>复杂性有各种各样的表现方式：状态空间的膨胀，模块紧耦合，令人纠结的相互依赖关系，不一致的命名和术语，为了性能而采取的特殊处理，为解决某特定问题而引入的特殊框架等</u>。

​	复杂性使得维护变得越来越困难，最终会导致预算超支和开发进度滞后。对于复杂的软件系统，变更而引入潜在错误的风险会显著加大，最终开发人员更加难以准确理解、评估或者更加容易忽略相关系统行为，包括背后的假设，潜在的后果，设计之外的模块交互等。相反，降低复杂性可以大大提高软件的可维护性，因此简单性应该是我们构建系统的关键目标之一。

​	简化系统设计并不意味着减少系统功能，而主要意味着消除意外方面的复杂性，正如Moseley和Marks把复杂性定义为一种“意外”，即它并非软件固有、被用户所见或感知，而是实现本身所衍生出来的问题。

​	**消除意外复杂性最好手段之一是抽象。一个好的设计抽象可以隐藏大量的实现细节并对外提供干净、易懂的接口**。一个好的设计抽象可用于各种不同的应用程序。这样，复用远比多次重复实现更有效率；另一方面，也带来更高质量的软件，而质量过硬的抽象组件所带来的好处，可以使运行其上的所有应用轻松获益。

​	例如，高级编程语言作为一种抽象，可以隐藏机器汇编代码、CPU寄存器和系统调用等细节和复杂性。SQL作为一种抽象，隐藏了内部复杂的磁盘和内存数据结构，以及来自多客户端的并发请求，系统崩溃之后的不一致等问题。<u>当然，使用高级编程语言最终并没有脱离机器汇编代码，只是并非直接使用，与汇编代码打交道的事情已经由编程语言抽象为高效接口代我们完成。</u>

​	然而，设计好的抽象还是很有挑战性。在分布式系统领域中，虽然已有许多好的算法可供参考，但很多时候我们并不太清楚究竟该如何利用他们，封装到抽象接口之中最终帮助将系统的复杂性降低到可掌控的级别。

​	本书我们将广泛考察如何设计好的抽象，这样至少能够将大型系统的一部分抽象为定义明确、可重用的组件。

### 1.4.3 可演化性：易于改变

​	一成不变的系统需求几乎没有，想法和目标经常在不断变化：适配新的外部环境，新的用例，业务优先级的变化，用户要求的新功能，新平台取代旧平台，法律或监管要求的变化，业务增长促使架构的演变等。

​	在组织流程方面，敏捷开发模式为适应变化提供了很好的参考。敏捷社区还发布了很多技术工具和模式，以帮助在频繁变化的环境中开发软件，例如测试驱动开发(TDD)和重构。

​	这些敏捷开发技术目前多数还只是针对小规模、本地模式(例如同一应用程序中的几个源代码文件)环境。本书将探索在更大的数据系统层面上提高敏捷性，系统由多个不同特性的应用或者服务协作而成。例如，对于 Twitter的案例(参见本章前面的“描述负载”)，如何从方法1过渡到方法2，重构 Twitter架构来实现主页时间线。

​	我们的目标是可以轻松地修改数据系统，使其适应不断变化的需求，这和简单性与抽象性密切相关:简单易懂的系统往往比复杂的系统更容易修改。这是一个非常重要的理念，我们将采用另一个不同的词来指代数据系统级的敏捷性，即可演化性。

## 1.5 小结

​	这一章我们探讨了一些关于数据密集型应用的基本原则，这些原则将指导如何阅读本书的其余部分。

​	一个应用必须完成顸期的多种需求，主要包括功能性需求(即应该做什么，比如各种存储、检索、搜索和处理数据)和一些非功能性需求(即常规特性、例如安全性、可靠性、合规性、可伸缩性、兼容性和可维护性)。本章我们着重梳理讨论了可靠性、可扩展性和可维护性。

​	可靠性意味着即使发生故障，系统也可以正常工作。故障包括硬件(通常是随机的，不相关的)、软件(缺陷通常是系统的，更加难以处理)以及人为(总是很难避免时不时会岀错)方面。容错技术可以很好地隐藏某种类型故障，避免影响最终用户。

​	可扩展性是指负载增加时，有效保持系统性能的相关技术策略。为了讨论可扩展性，我们首先探讨了如何定量描述负载和性能。简单地以Twitter浏览时间线为例描述负载，并将响应时间百分位数作为衡量性能的有效方式。对于可扩展的系统，增加处理能力的同时，还可以在高负载情况下持续保持系统的高可靠性。	

​	可维护性则意味着许多方面，但究其本质是为了让工程和运营团队更为轻松。良好的抽象可以帮助降低复杂性，并使系统更易于修改和遹配新场景。良好的可操作性意味着对系统健康状况有良好的可观测性和有效的管理方法。

​	然而知易行难，使应用程序可靠、可扩展或可维护并不容易。考虑到一些重要的模式和技术在很多不同应用中普遍适用，在接下来的几章中，我们就一些数据密集系统例子，分析它们如何实现上述这些目标。

# 第2章 数据模型与查询语句

## 2.1 关系模型与文档模型

​	现在最著名的数据模型可能是SQL，它基于 Edgar codd于1970年提出的关系模型数据被组织成关系(relations)，在SQL中称为表( table)，其中每个关系都是元组( tuples)的无序集合(在SQL中称为行)。

​	关系模型曾经只是一个理论建议，当时很多人怀疑它是否能够被高效地实现。然而，到了20世纪80年代中期，关系数据库管理系统( RDBMS)和SQL已经成为大多数需要存储、査询具有某种规则结构数据的首选工具。关系数据库的主导地位已经持续了25~30年，这在计算机历史称得上一段不朽传奇。

​	关系数据库的核心在于商业数据处理，20世纪60年代和70年代主要运行在大型计算机之上。从今天的角度来看，用例看起来很常见，主要是事务处理(包括输入销售和银行交易、航空公司订票、仓库库存)和批处理(例如客户发票、工资单、报告)。

​	当时的其他数据库迫使应用开发人员考虑数据的内部表示。关系模型的目标就是将实现细节隐藏在更简洁的接口后面。

​	多年来，在数据存储和查询方面存在着其他许多竞争技术。在20世纪70年代和80年代初期，网络模型和层次模型是两个主要的选择，但最终关系模型主宰了这个领域。对象数据库曾在20世纪80年代后期和90年代初期起起伏伏。ⅩML数据库则出现在2世纪初，但也仅限于利基市场。关系模型的每个竞争者都曾聒噪一时，可惜无一持久。

​	随着计算机变得越来越强大和网络化，服务目的日益多样化。值得注意的是，关系数据库超出了它们最初的商业数据处理范围，顺利推广到了各种各样的用例。当前在网上看到的大部分内容很多仍然是由关系数据库所支撑的，无论是在线发布、论坛、社交网络、电子商务、游戏、SaaS等。

 ### 2.1.1 NoSQL的诞生

​	进入21世纪， NoSQL成为推翻关系模式主导地位的又一个竞争者。“ NoSQL”这个名字是不恰当的，因为它其实并不代表具体的某些技术，它最初只是作为一个吸引人眼球的 Twitter标签频频出现在2009年的开源、分布式以及非关系数据库的见面会上。尽管如此，这个称呼还是让人有所触动，并迅速传遍了网络创业社区。现在很多新兴的数据库系统总是会打上 NoSQL的标签，而其含义也已经被逆向重新解释为“不仅仅是SQL”。

​	采用NoSQL数据库有这样几个驱动因素，包括：

+ 比关系数据库更好的扩展性需求，包括**支持超大数据集**或**超高写入吞吐量**。
+ 普遍偏爱免费和开源软件而不是商业数据库产品。
+ 关系模型不能很好地支持一些特定的查询操作。
+ 对关系模式一些限制性感到沮丧，渴望更具动态和表达力的数据模型。

​	不同的应用程序有不同的需求，某个用例的最佳的技术选择未必适合另一个用例。因此，在可预见的将来，关系数据库可能仍将继续与各种非关系数据存储一起使用，这种思路有时也被称为混合持久化的。

### 2.1.2 对象-关系不匹配

​	**现在大多数应用开发都采用面向对象的编程语言，由于兼容性问题，普遍对SQL数据模型存在抱怨：如果数据存储在关系表中，那么应用层代码中的对象与表、行和列的数据库模型之间需要一个笨拙的转换层**。模型之间的脱离有时被称为**阻抗失谐**。

​	ActiveRecord 和 Hibernate 这样的对象-关系映射(ORM)框架则减少了此转换层所需的样板代码量，但是他们并不能完全隐藏两个模型之间的差异。

![28b8074d8e72d62db47420b144496bb8.png](https://img-blog.csdnimg.cn/img_convert/28b8074d8e72d62db47420b144496bb8.png)

​	一些开发人员认为JSON模型减少了应用程序代码和存储层之间的阻抗失配。然而正如我们将在第4章中看到的那样，JSON作为数据编码格式也存在问题。缺乏模式常常被认为是一个优势；我们将在本章后面“文档模型的模式灵活性”中讨论这个问题。

​	JSON表示的多表模式具有更好的局部性。如果要在关系模式中读取一份简历，那么要么执行多个查询(通过 user id查询每个表)，要么在 users表及其从属表之间执行混乱的多路联结。而对于JSON表示方法，所有的相关信息都在一个地方次查询就够了。

​	用户简历到用户的职位、教育历史和联系信息的一对多关系，意味着数据存在树状结构，JSON表示将该树结构显式化。

![7d0c6211074b0eb8fe9f796b4b89a3ba.png](https://img-blog.csdnimg.cn/img_convert/7d0c6211074b0eb8fe9f796b4b89a3ba.png)

### 2.1.3 多对一与多对多的关系

​	在示例中， region_id 和 industry_id定义为ID，而不是纯文本字符串形式，例如"Greater Seattle Area"和" Philanthropy"。为什么这样做呢?

​	如果用户界面是可以输入地区或行业的自由文本字段，则将其存储为纯文本字符串更有意义。但是，拥有地理区域和行业的标准化列表，并让用户从下拉列表或自动填充器中进行选择会更有优势，这样：

+ 所有的简历保持样式和输入值一致。
+ 避免歧义(例如，如果存在一些同名的城市)。
+ 易于更新：名字只保存一次，因此，如果需要改变(例如，由于政治事件而更改城市名称)，可以很容易全面更新。
+ 本地化支持：当网站被翻译成其他语言时，标准化的列表可以方便本地化，因此地区和行业可以用查看者的母语来显示。
+ 更好的搜索支持:例如，搜索华盛顿州的慈善家可以匹配到这个简历，这是因为地区列表可以将西雅图属于华盛顿的信息编码进来(而从“大西雅图地区”字符串中并不能看出来西雅图属于华盛顿)。

​	<u>无论是存储ID还是文本字符串，都涉及内容重复的问题。当使用ID时，对人类有意义的信息(例如慈善这个词)只存储在一个地方，引用它的所有内容都使用ID(I只在数据库中有意义)。当直接存储文本时，则使用它的毎条记录中都保存了一份这样可读信息</u>。

​	<u>使用ID的好处是，因为它对人类没有任何直接意义，所以永远不需要直接改变：即使ID标识的信息发生了变化，它也可以保持不变。任何对人类有意义的东西都可能在将来某个时刻发生变更。如果这些信息被复制，那么所有的冗余副本也都需要更新。这会导致更多写入开销，并且存在数据不一致的风险(信息的一些副本被更新，而其他副本未更新)</u>。消除这种重复正是数据库规范化的核心思想。

>数据库管理员和开发人员有时喜欢争论规范化与反规范化，此处我们暂不做评论。在本书的第三部分，我们将重回这个话题，并探索处理缓存、反规范化和派生数据更为系统化的方法。

​	然而这种数据规范化需要表达多对一的关系(许多人生活在同一地区，许多人在同行业工作)，这并不是很适合文档模型。对于关系数据库，由于支持联结操作，可以很方便地通过ID来引用其他表中的行。而在文档数据库中，一对多的树状结构不需要联结，支持联结通常也很弱。

​	如果数据库本身不支持联结，则必须在应用程序代码中，通过对数据库进行多次查询来模拟联结(对于上述例子，地区和行业的列表很小且一段时间内不太可能发生变化，应用程序可以简单地将它们缓存在内存中。但无论如何，联结的工作其实从数据库转移到了应用层)。

​	即使应用程序的初始版本非常适合釆用无联结的文档模型，但随着应用支持越来越多的功能，数据也变得更加互联一体化。

### 2.1.4 文档数据库是否在重演历史？

​	虽然关系数据库中经常使用多对多的关系和联结，但文档数据库和NoSQL再次引发了如何最佳表示数据关系的争论。而类似争论并不是第一次，事实上，它可以追溯到最早的计算机数据库系统。

​	20世纪70年代最受欢迎的商业数据处理数据库是IBM信息管理系统( InformationManagement System，IMS)，最初是为了阿波罗太空计划中的库存管理而开发的，并于1968年首次商业发布。至今它仍在维护和使用，通常运行在IBM大型机OS/390。

​	IMS采用了相当简单的数据模型，称为层次模型，它与文档数据库使用的JSON模型有些显著的相似之处。它将所有数据表示为嵌套在记录中的记录(树)，与JSON结构非常相似。

​	和文档数据库类似，IMS可以很好地支持一对多关系中，但是它支持多对多关系则有些困难，而且不支持联结。开发人员必须决定是复制(反规范化)多份数据，还是手动解析记录之间的引用。20世纪六七十年代的这些问题与开发人员今天遇到的文档数据库的问题非常相似。

​	为了解决层次模型的局限性，之后又提出了多种解决方案。其中最著名的是关系模型( relational model，后来演变成为SQL，并被广泛接受)和网络模型(network model，最初有很多拥趸，可惜最终被人们淡忘)。在20世纪70年代，这两个阵营之间的“大辩论”持续了很长时间。

####  网络模型

​	网络模型由一个称为数据系统语言会议(Conference on Data System Languages，CODASYL)的委员会进行标准化，并由多个不同的数据库厂商实施，它也被称为CODASYL模型。

​	CODASYL模型是层次模型的推广。在层次模型的树结构中，每个记录只有一个父结点；而在网络模型中，一个记录可能有多个父结点。例如，“大西雅图地区”可能有个记录，居住在该地区的每个用户都链接指向它。从而支持对多对一和多对多的关系进行建模。

​	在网络模型中，记录之间的链接不是外键，而更像是编程语言中的指针(会存储在磁盘上)。访问记录的唯一方法是选择一条始于根记录的路径，并沿着相关链接依次访问。这条链接链条也因此被称为访问路径。

​	在最简单的情况下，访问路径像是遍历链表：从链表的头部开始，一次査看一个记录，直到找到所需的记录。但是在一个多对多关系的世界里，存在多条不同的路径通向相同的记录，使用网络模型的程序员必须在脑海中设法跟踪这些不同的访问路径。

​	CODASYL中的査询通过遍历记录列表，并沿着访问路径在数据库中移动游标来执行。如果记录有多个父结点(即来自其他记录的多个传入指针)，则应用程序代码必须跟踪所有关系。甚至 CODASYL委员会的成员也承认，这就像在一个n维数据空间中进行遍历。

​	在20世纪70年代，尽管手动路径选择能够最有效地利用当时非常有限的硬件资源(例如磁带驱动器，搜索速度非常慢)，**但最大的问题在于它们使査询和更新数据库变得异常复杂而没有灵活性**。<u>无论是层次模型还是网络模型，如果脱离数据的访问路径那么将寸步难行</u>。它也支持改变访问路径，但随之需要大量的手写数据库查询代码重新实现处理新的访问路径。总之，对应用程序的数据模型进行更改是一件非常困难的事情。

#### 关系模型

​	相比之下，关系模型所做的则是定义了所有数据的格式：关系(表)只是元组(行)的集合，仅此而已。没有复杂的嵌套结构，也没有复杂的访问路径。可以读取表中的任何一行或者所有行，支持任意条件查询。可以指定某些列作为键并匹配这些列来读取特定行。可以在任何表中插入新行，而不必担心与其他表之间的外键关系。

​	<u>在关系数据库中，査询优化器自动决定以何种顺序执行査询，以及使用哪些索引。这些选择实际上等价于“访问路径”，但最大的区别在于它们是由查询优化器自动生成的，而不是由应用开发人员所维护，因此不用过多地考虑它们</u>。

​	如果想用新的方式查询数据，只需声明一个新的索引，査询会自动使用最合适的索引。不需要更改查询即可利用新的索引(另请参阅本章后面的“数据查询语言”部分)。因此，关系模型使得应用程序添加新功能变得非常容易。

​	关系数据库的査询优化器称得上是一个复杂的怪兽，研究开发人员多年来持续投入，花费巨大。不管怎样，**关系模型的一个核心要点是：只需构建一次查询优化器，然后使用该数据库的所有应用程序都可以从中受益**。<u>如果没有查询优化器，那么为特定査询手动编写访问路径比编写通用优化器更容易，但从长远来看，通用解决方案更胜一筹</u>。

####  文档数据库的比较

​	从以下角度来看，文档数据库是某种方式的层次模型：即在其父记录中保存了嵌套记录(一对多关系)，而不是存储在单独的表中。

​	**但是，在表示多对一和多对多的关系时，关系数据库和文档数据库并没有根本的不同：在这两种情况下，相关项都由唯一的标识符引用，该标识符在关系模型中被称为外键，在文档模型中被称为文档引用**。标识符可以査询时通过联结操作或相关后续查询来解析。迄今为止，文档数据库并未遵循 CODASYL 标准。

### 2.1.5 关系数据库与文档数据库现状

​	在比较关系数据库与文档数据库时，需要考虑很多方面的差异，包括它们的容错性参阅第5章)和并发处理(参阅第7章)。本章将只关注数据模型中的差异。<u>**支持文档数据模型的主要论点是模式灵活性**，由于**局部性**而带来较好的性能，对于某些应用来说，它更接近于应用程序所使用的数据结构</u>。**关系模型则强在联结操作、多对一和多对多关系更简洁的表达上，与文档模型抗衡**。

#### 哪种数据模型的应用代码更简单？

​	**如果应用数据具有类似文档的结构(即一对多关系树，通常一次加载整个树)，那么使用文档模型更为合适**。而关系型模型则倾向于某种数据分解，它把文档结构分解为多个表，有可能使得模式更为笨重，以及不必要的应用代码复杂化。

​	文档模型也有一定的局限性：例如，不能直接引用文档中的嵌套项，而需要说“用户251的职位列表中的第二项”(非常类似于层次模型中的访问路径)。然而，只要文档嵌套不太深，这通常不是问题。<u>在文档数据库中，对联结的支持不足是否是问题取决于应用程序</u>。例如，在使用文档数据库记录事件发生时间的应用分析程序中，可能永远不需要多对多关系。

​	但是，如果应用程序确实使用了多对多关系，那么文档模型就变得不太吸引人。<u>可以通过反规范化来减少对联结的需求，但是应用程序代码需要做额外的工作来保持非规范化数据的一致性</u>。**通过向数据库发出多个请求，可以在应用程序代码中模拟联结，但是这也将应用程序变得复杂，并且通常比数据库内的专用代码执行的联结慢**。在这些情况下，使用文档模型会导致应用程序代码更复杂、性能更差。

​	通常无法一概而论哪种数据模型的应用代码更简单。这主要取决于数据项之间的关系类型。**对于高度关联的数据，文档模型不太适合，关系模型可以胜任，而图模型(参阅本章后面的“图状数据模型”)则是最为自然的**。

#### 文档模型中的模式灵活性

​	大多数文档数据库，以及关系数据库中的JSON支持，都不会对文档中的数据强制执行任何模式。关系数据库中的XML通常支持带有可选的模式验证功能。<u>没有模式意味着可以将任意的键-值添加到文档中，并且在读取时，客户端无法保证文档可能包含哪些字段</u>。

​	文档数据库有时被称为无模式，但这具有误导性，因为读数据的代码通常采用某种结构因而存在某种隐形模式，而不是由数据库强制执行。<u>更准确的术语应该是读时模式(数据的结构是隐式的，只有在读取时才解释)，与写时模式(关系数据库的一种传统方法，模式是显式的，并且数据库确保数据写入时都必须遵循)相对应</u>。

​	**读时模式类似编程语言中的动态(运行时)类型检査，而写时模式类似于静态(编译时)类型检查**。正如静态与动态类型检查的支持者对于它们的优缺点存在很大的争议，数据库的模式执行也是一个有争议的话题，通常没有明确正确或错误的答案。

​	当应用程序需要改变数据格式时，这些方法之间的差异就变得尤其明显。例如，当前用户的全名存储在一个字段中，而现在想分别存储名字和姓氏。在文档数据库中，只需使用新字段来编写新文档，并在应用层来处理读取旧文档的情况。例如：

```java
if(user && user.name && !user.first_name) {
  // 2013年12月8日之前写的文档，不存在first_name
  user.first_name = user.name.split("")[0];
}
```

​	而对于"静态类型"数据库模式中，通常会按照以下方式执行升级（migration）：

```sql
ALTER TABLE users ADD COLUMN first_name text;
UPDATE users SET first_name = split_part(name, ' ', 1);  -- PostgreSQL
UPDATE users SET first_name = substring_index(name, ' ', 1); -- MySQL
```

​	模式更改由于速度慢并且需要停机，因而评价不高。但这种坏名声其实并不太公平：大多数关系数据库系统可以在几亳秒内执行ALTER TABLE语句。 **MySQL则需要注意，它执行ALTER TABLE时会把现在的整张表复制，因而当表很大时可能会需要几分钟甚至几小时的停机时间，尽管现在有各种辅助工具可以解决这个限制**。

​	<u>在大表上运行UPDATE语句，对于任何数据库都可能会很慢，因为每一行都需要重写。如果这是不可接受的，应用程序可以将 first_name设置为默认值NULL，并在读取时填充它，就像使用文档数据库一样</u>。

​	如果集合中的项由于某种原因(例如数据异构)，并不都具有相同的结构，例如：

+ 有许多不同类型的对象，将每种类型的对象都保存在各自的表中不太现实。
+ 数据的结构由无法控制的外部系统所决定，而且可能随时改变。

​	在这些情况下，模式带来的损害大于它所能提供的帮助，无模式文档可能是更自然的数据模型。但是，**当所有记录都有相同结构时，模式则是记录和确保这种结构的有效机制**。我们将在第4章更详细地讨论模式和模式演变。

#### 查询的数据局部性

​	文档通常存储为编码为JSON、XML或其二进制变体(如 MongoDB的BSON)的连续字符串。<u>如果应用程序需要频繁访问整个文档(例如，在网页上呈现它)，则存储局部性具有性能优势</u>。如果数据被划分在多个表中，则需要进行多次索引査找来检索所有数据，中间可能需要更多的磁盘I/O并花费更多的时间。

​	**局部性优势仅适用需要同时访问文档大部分内容的场景**。<u>由于数据库通常会加载整个文档，如果应用只是访向其中的一小部分，则对于大型文档数据来讲就有些浪费</u>。<u>对文档进行更新时，通常会重写整个文档，而只有修改量不改变源文档大小时，原地覆盖更新才更有效。因此，通常建议文档应该尽量小且避免写入时增加文档大小。这些性能方面的不利因素大大限制了文档数据库的适用场景</u>。

​	值得指出的是，将相关数据归为一组的局部性想法并不仅见于文档模型。例如，Google的Spanner数据库在关系数据模型中提供了相同的局部性，支持模式声明某些表的行应该在父表内交错(嵌套)。 Oracle支持类似的操作，称为“多表索引集群表”特性， Bigtable数据模型(用于Cassandra和Hbase)中的列族概念类似。

​	我们将在第3章介绍更多局部性相关内容。

#### 文档数据库与关系数据库的融合

​	自2000年中期以来，大多数关系数据库系统(MySQL除外)都支持XML。其中包括对XML文档进行本地修改，在XML文档中进行索引和查询等，这样应用程序可以获得与文档数据库非常相似的数据模型。

​	PostgreSQL版本9.3、MyQL版本5.7以及 IBM DB2 10.5，都对JSON文档提供了相应支持。考虑到JSON在 Web Api中非常流行，其他关系数据库很可能将很快增加JSON支持。

​	文档数据库方面， RethinkDB的査询接口支持和关系型类似的联结，而一些MongoDB驱动程序可以自动解析数据库的引用关系(在客户端执行高效联结，注意，因为需要额外的网络往返，且优化程度较低，因此绝对性能可能慢于数据库端执行)。

​	随着时间的推移，似乎关系数据库与文档数据库变得越来越相近，或许这是一件好事：数据模型可以相互补充。如果数据库能够很好处理文档类数据，还能对其执行关系査询，那么应用程序可以使用最符合其需求的功能的组合。

​	融合关系模型与文档模型是未来数据库发展的一条很好的途径。

## 2.2 数据查询语言

​	当关系模型是初被引入时，就包含了査询数据的新方法:SQL是一种声明式查询语言，而IMS和 CODASYL则是命令式。

​	声明式查询语言很有吸引力，它比命令式API更加简洁和容易使用。但更重要的是，它对外隐藏了数据库引擎的很多实现细节，这样数据库系统能够在不改变査询语句的情况下提高性能。

​	**声明式语言通常适合于并行执行**。现在CPU主要通过增加核，而不是通过比之前更高的时钟频率来提升速度。而命令式代码由于指定了特定的执行顺序，很难在多核和多台机器上并行化。<u>声明式语言则对于并行执行更为友好，它们仅指定了结果所满足的模式，而不指定如何得到结果的具体算法。所以如果可以的话，数据库都倾向于采用并行方式实现查询语言</u>。

#### Web上的声明式查询

​	对于Web浏览器的例子，使用声明式CSS样式表比用 JavaScript命令式地操作样式好得多。类似地，在数据库中，像SQL这样的声明式查询语言比命令式查询APIs要好得多。

#### MapReduce查询

​	MapReduce既不是声明式查询语言，也不是一个完全命令式的查询API，而是介于两者之间：査询的逻辑用代码片段来表示，这些代码片段可以被处理框架重复地调用。它主要基于许多函数式编程语言中的map(也称为 collect)和reduce(也称为fold或inject)函数。

​	MapReduce是一个相当底层的编程模型，用于在计算集群上分布执行。而SQL这样的更高层次的查询语言可以通过一些MapReduce操作pipeline来实现(参阅第10章)，当然也有很多SQL的分布式实现并不借助 MapReduce。请注意，SQL并没有任何限制规定它只能在单个机器上运行，而MapReduce也并非垄断了分布式查询。

## 2.3 图状数据模型

​	我们之前看到，多对多关系是不同数据模型之间的重要区别特征。如果数据大多是一对多关系(树结构数据)或者记录之间没有关系，那么文档模型是最合适的。

​	但是，如果多对多的关系在数据中很常见呢？**关系模型能够处理简单的多对多关系，但是随着数据之间的关联越来越复杂，将数据建模转化为图模型会更加自然**。

​	图由两种对象组成：顶点(也称为结点或实体)和边(也称为关系或弧)。很多数据可以建模为图。典型的例子包括：

+ 社交网络

  顶点是人，边指示哪些人彼此认识。

+ Web图

  顶点是网页，边表示与其他页面的HTML链接。

+ 公路或铁路网

  顶点是交叉路口，边表示他们之间的公路或铁路线。

​	有很多著名的算法可以在这些图上运行。例如，汽车导航系统搜索道路网中任意两点之间的最短路径， PageRank可以计算Web图上网页的流行度，从而确定搜索排名。

​	在刚才给出的示例中，图的顶点表示相同类型的事物(分别是人、网页或交叉路口)。然而，图并不局限于这样的同构数据，图更为强大的用途在于，提供了单个数据存储区中保存完全不同类型对象的一致性方式。例如， Facebook维护了一个包含许多不同类型的顶点与边的大图：顶点包括人、地点、事件、签到和用户的评论；边表示哪些人是彼此的朋友，签到发生在哪些位置，谁评论了哪个帖子，谁参与了哪个事件等。

### 属性图

在属性图模型中，每个顶点包括：

+ 唯一的标识符。
+ 出边的集合。
+ 入边的集合。
+ 属性的集合(键-值对)。

每个边包括：

+ 唯一的标识符。
+ 边开始的顶点(尾部顶点)。
+ 边结束的顶点(头部顶点)。
+ 描述两个顶点间关系类型的标签。
+ 属性的集合(键-值对)。

​	可以将图存储看作由两个关系表组成，一个用于顶点，另一个用于边。为每个边存储头部和尾部顶点，如果想要顶点的入边或出边的集合，可以分别通过head_vertex或tail_vertex来查询edges表。

​	示例：使用关系模式来表示属性图

```sql
CREATE TABLE vertices (
	vertex_id	integer PRIMARY KEY,
	properties	json
);

CREATE TABLE edges (
	edge_id integer PRIMARY KEY,
  tail_vertex integer REFERENCES vertices (vertex_id),
  head_vertex integer REFERENCES vertices (vertex_id),
  label	text,
  properties	json
);

CREATE INDEX edges_tails ON edges (tail_vertex);
CREATE INDEX edges_heads ON edges (head_vertex);
```

​	关于图模型一些值得注意的地方：

1. 任何顶点都可以连接到其他任何顶点。没有模式限制哪种事物可以或不可以关联。
2. 给定某个顶点，可以高效地得到它的所有入边和出边，从而遍历图，即沿着这些顶点链条一直向前或向后。
3. 通过对不同类型的关系使用不同的标签，可以在单个图中存储多种不同类型的信息，同时仍然保持整洁的数据模型。

![img](https://upload-images.jianshu.io/upload_images/10879214-aed5376d57a74a8b.png?imageMogr2/auto-orient/strip|imageView2/2/w/597/format/webp)

​	这些特性为数据建模提供了很大的灵活性，如图所示。图中显示了一些传统关系模式难以表达的东西，例如不同国家的不同类型的地区结构(法国有省和区，而美国有县和州)，特殊历史原因，以及不同粒度的数据(Lucy当前住所被指定为一个城市，而她的出生地则是州一级)。

​	可以把这个图扩展到包括许多关于Lucy和 Alain的其他信息，或者其他人。例如，可以用它来表示他们的任何食物过敏(通过为每个过敏源引入顶点，以及人与过敏原之间的边来表示过敏)，并将过敏源与顶点的集合联结，这些顶点显示哪些食物含有哪些物质。然后，可以编写一个查询找出每个人吃什么是安全的。图有利于演化：向应用程序添加功能时，图可以容易地扩展以适应数据结构的不断变化。

### Cypher查询语言

​	Cypher是属性图的声明性查询语言，为Neo4j图形数据库创建（它以电影The Matrix中的角色命名，与密码学中的密码无关）。

​	例2-3显示了将图2-5的左边部分插入图形数据库中的Cypher查询。 图的其余部分可以类似地添加，为了便于阅读而省略。 每个顶点都有一个符号名称，例如USA或Idaho，查询的其他部分可以使用这些名称在顶点之间创建边，使用箭头符号：`(Idaho) -[:WITHIN]-> (USA)`创建边 标记为WITHIN，Idaho为尾节点，USA为头节点。

   例2-3。 图2-5中的数据子集，表示为Cypher查询：

```cypher
CREATE 
(NAmerica:Location {name:'North America', type:'continent'}), 
(USA:Location {name:'United States', type:'country' }), 
(Idaho:Location {name:'Idaho', type:'state' }), 
(Lucy:Person {name:'Lucy' }), 
(Idaho) -[:WITHIN]-> (USA) -[:WITHIN]-> (NAmerica), 
(Lucy) -[:BORN_IN]-> (Idaho)
```

​    当图2-5的所有顶点和边被添加到数据库时，我们可以开始提出有趣的问题：例如，查找从美国移民到欧洲的所有人的姓名。 更确切地说，在这里我们想要找到所有在美国有一个BORN_IN边缘的顶点，还有一个LIVING_IN边缘到欧洲的一个位置，并返回每个顶点的name属性。

​    例2-4展示了如何在Cypher中表达该查询。 在MATCH子句中使用相同的箭头符号来查找图中的模式：`(person) -[:BORN_IN]-> ()` 通过标记为BORN_IN的边匹配任何两个相关的顶点。 该边的尾部顶点被绑定到变量person，并且顶部顶点未被命名。

​    例2-4：Cypher查询寻找从美国移民到欧洲的人员名单

```cypher
MATCH 
(person) -[:BORN_IN]-> () -[:WITHIN*0..]-> (us:Location {name:'United States'}), 
(person) -[:LIVES_IN]-> () -[:WITHIN*0..]-> (eu:Location {name:'Europe'})
RETURN person.name
```

​    该查询可以被读取如下：   

​    找到满足以下两个条件的任何顶点（称之为person）：

1. person有一个到其他顶点的出边 BORN_IN。从该顶点开始，可以沿着一系列出边WITHIN，直到最终到达类型为Location的顶点，name属性为"United States"。
2. 同一个person顶点也有一个出边LIVES_IN。沿着这条边，然后是一系列出边WITHIN，最终到达类型为 Location的顶点，name属性为"Europe"。

​	对于每个这样的顶点，返回name属性。

​    其实有多种可行的方法执行上述查询。这里给出的方案是，首先扫描数据库中的所有person，检查每个person的出生地和居住地，然后只返回符合条件的person。

​	当然也可以采用其他等价方式，例如可以从两个Location顶点开始。如果name属性上有索引，则可以高效地找到代表美国和欧洲的两个顶点。然后，通过沿着所有的WITHIN入边，可以继续查找美国和欧洲的所有地点(州、地区、城市等)。最后，根据某个位置顶点的入边 BORN IN或 LIVES IN来找到符合条件的人员。

​	对于声明式査询语言，通常在编写査询语句时，不需要指定执行细节：查询优化器会自动选择效率最高的执行策略，因此开发者可以专注于应用的其他部分。

### SQL中的图查询

​	示例2-2表明可以采用关系数据库表示图数据。如果把图数据放在关系结构中，是否意味着也可以支持SQL查询呢?

​	答案是肯定的，但存在一些困难。**在关系数据库中，通常会预先知道查询中需要哪些join操作。而对于图查询，在找到要查找的顶点之前，可能需要遍历数量未知的边，也就是说，join操作数量并不是预先确定的**。

​	对于示例2-4，这主要集中在 Cypher查询的`()-[: WITHIN * 0 ..]->()`规则中个人的 LIVES_IN边可以指向任何类型的位置，例如街道、城市、地区、区域、国家等。城市可以位于(WIHIN)某地区内，地区可以位于(WIHIN)某州内，州位于(WIHIN)国家内等。 LIVES_IN边可以直接指向正在查找的位置顶点，也可以是位置层次结构中删除的某些层。

​	Cypher可以用: `WITHIN*0..`非常简洁地表达这个情况：它表示“沿着一个WITHIN边，遍历零次或多次”，就像正则表达式中的\*运算符(表示匹配零次或多次)那样。

​	SQL:1999标准以后，査询过程中这种可变的遍历路径可以使用称为递归公用表表达式(即 WITH RECURSIVE语法)来表示。示例2-5采用该技术的SQL表达来执行相同的查询(查找从美国移民到欧洲的人员名单)，目前 PostgreSQL、 IBM DB2、 Oracle和SQL Server等都支持该技术，但与 Cypher相比，语法仍显得非常笨拙。

 例2-5。 与例2-4相同的查询，使用递归公用表达式在SQL中表达：

![img](https://upload-images.jianshu.io/upload_images/10879214-d0204aecb72fd4e4.png?imageMogr2/auto-orient/strip|imageView2/2/w/712/format/webp)

1. 首先找到name属性值为" United States"的顶点，并将其作为顶点集in_usa中的第一个元素。
2. 沿着集合in_usa中顶点的所有入边within，并将它们添加到同一集合，直到遍历所有的入边。
3. 从name属性值为"Europe"的顶点开始执行同样的操作，并建立顶点集in_europee。
4. 对于in_usa集合中的每个顶点，按照入边born_in来查找出生在美国境内某个地方的人。
5. 类似地，对于in_europe集合中的每个顶点，按照入边lives_in来查找居住在欧洲的人。
6. 最后，通过join把在美国出生的人的集合与在欧洲居住的人的集合相交。

​	如果相同的查询可以用一种查询语言写4行代码完成，而另一种查询语言则需要29行代码，这足以说明不同的数据模型适用于不同的场景。因此，选择适合应用程序的数据模型非常重要。

### 三元存储与SPARQL

> [数据模型和查询语言 -- 图形数据模型及本章概要 - 简书 (jianshu.com)](https://www.jianshu.com/p/9461022cbb22)

​	三元存储模式几乎等同于属性图模型，只是使用不同的名词描述了相同的思想。尽管如此，考虑到有多种针对三元存储的工具和语言，它们可能是构建应用程序宝贵的补充，因此还是值得在此讨论。

​	在三元存储中，所有信息都以非常简单的三部分形式存储(主体，谓语，客体)。例如，在三元组(吉姆，喜欢，香蕉)中，吉姆是主体，喜欢是谓语(动词)，香蕉是客体。

​	三元组的主体相当于图中的顶点。而客体则是以下两种之一:

1. 原始数据类型中的值，如字符串或数字。在这种情况下，三元组的谓语和客体分别相当于主体(顶点)属性中的键和值。例如，(lucy，age，33)就好比是顶点lucy，具有属性{"age":33}。
2. 图中的另一个顶点。此时，谓语是图中的边，主体是尾部顶点，而客体是头部顶点。例如，在(luey， marriedTo， alain)中，主体lucy和客体 alain都是顶点，并且谓语marriedTo是连接二者的边的标签。

#### 语义网

#### RDF数据模型

#### SPARQL查询语言

> 图数据库与网络模型的比较
>
> 在前面的“文档数据库是否在重演历史”中，我们介绍了 CODASYL 与关系模型如何竞争解决IMS中的多对多关系问题。乍一看， CODASYL 的网络模型和图模型很相似，那么图形数据库是乔装打扮的另一个 CODASYL吗?
>
> 答案是否定的，它们在以下几个重要方面有着明显区别：
>
> + 在 CODASY L中，数据库有一个模式来指定哪种记录类型可以嵌套在其他记录类型中。在图数据库中，则没有这样的限制：任何顶点都可以有边连接其他任何顶点。这就为应用程序适应不断变化的需求提供了更大的灵活性。
> + **在 CODASYL中，获取特定记录的唯一方法是遍历其中的一条访问路径。在图数据库中，则可以通过顶点的唯一ID直接引用该顶点，也可以使用索引查找满足特定值的那些顶点**。
> + 在 CODASYL中，记录的子记录是有序集合，所以数据库必须保持这种排序(这会对存储布局产生影响)，当应用插入新记录时不得不考虑新记录在这些集合中的位置。**在图数据库中，顶点和边不是有序的(只能在查询时对结果进行排序)。**
> + 在 CODASYL中，所有的查询都是命令式的，难以编写，并且很容易被模式的变化所破坏。在图数据库中，可以采用命令式代码来实现自己的遍历，但**大多数图形数据库还支持高级声明式查询语言**，例如 Cypher或SPARQL。

### Datalog基础

​	Datalog是比SPARQL或 Cypher更为古老的语言，在20世纪80年代被学者广泛研究。虽然在软件工程师中知名度较低，但它为以后的查询语言奠定了基础，因此它非常重要。

​	实践中有几个数据库系统采用了 Datalog。例如它是Datomic系统的查询语言，而Cascalog是用于查询Hadoop数据集的Datalog实现。

​	Datalog的数据模型类似于三元存储模式，但更为通用一些。它采用“谓语(主体客体)”的表达方式而不是三元组(主体，谓语，客体)。

​	Datalog方法需要釆取与其他査询语言略有不同的思维方式，但它非常强大，特别是规则可以在不同的查询中组合和重用。对于简单的一次性查询来说，这或许不太方便，但是如果数据非常复杂，处理起来会更加游刃有余。

## 2.4 小结

​	历史上，数据最初被表示为一棵大树(层次模型)，但是这不利于表示多对多关系，所以发明了关系模型来解决这个问题。最近，开发人员发现一些应用程序也不太适合关系模型。新的非关系“ NOSQL”数据存储在两个主要方向上存在分歧：

1. 文档数据库的目标用例是数据来自于自包含文档，且一个文档与其他文档之间的关联很少。
2. 图数据库则针对相反的场景，目标用例是所有数据都可能会互相关联。

​	**所有这三种模型(文档模型、关系模型和图模型)，如今都有广泛使用，并且在各自的目标领域都足够优秀。我们观察到，一个模型可以用另一个模型来模拟**。例如，图数据可以在关系数据库中表示，虽然处理起来比较笨拙。这就是为什么不同的系统用于不同的目的，而不是一个万能的解决方案。

​	**文档数据库和图数据库有一个共同点，那就是它们通常不会对存储的数据强加某个模式，这可以使应用程序更容易适应不断变化的需求**。<u>但是，应用程序很可能仍然假定数据具有一定的结构，只不过是模式是显式(写时强制)还是隐式(读时处理)的问题</u>。

​	毎个数据模型都有自己的查询语言或框架，我们讨论了几个例子：SQL、MapReduce、 MongoDB的聚合管道、 Cypher、SPARQLA和 Datalog。我们还讨论了CSS和XSL/ XPath，它们并不属于数据库查询语言，但存在有趣的相似之处。

​	虽然已经覆盖了很广的范围，但仍然有一些数据模型尚未提及。举几个简单的例子：

+ 使用基因组数据的硏究人员经常需要执行序列相似性搜索，这意味着需要用一个非常长的字符串(代表一个DNA分子)，与存在相似但却不完全相同的大型字符串数据库进行匹配。以上介绍的所有数据库都不适用于这种场景，这就是为什么研究人员开发了专门的基因组数据库软件，如 GenBank。
+ 数十年来，粒子物理学家一直在进行海量数据的超大规模数据分析，像大型强子对撞机(LHC)这样的项目，现在可以处理数百PB级别的数据在这种规模下，需要一些定制解决方案来避免硬件成本失控。
+ 全文搜索可以说是一种经常与数据库一起使用的数据模型。信息检索是一个很大的专业课题，本书不会详细介绍，但是将在第3章和第三部分中介绍搜索索引相关内容。

本章暂时告一段路。在下一章中，我们将讨论在实现本章所描述的数据模型过程中有哪些重要的权衡设计

# 第3章 数据存储与检索

P73