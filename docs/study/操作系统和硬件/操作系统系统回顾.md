> 经过之前寒假的Netty开发。打算对操作系统的知识重新回顾一遍。俗话说，温故而知新，可以为师矣。
>
> 最近把操作系统回顾了一遍，同样是OneNote笔记再整理一份Markdown的版本。没有图床，所以就文字将就了。
>
> <small>笔记整了将近一半之后，发现CSDN有个老哥跟我学的课内容差不多，他2018年的笔记里图还挺多的，正好我这缺图片。还省得去网上百度找图了，哈哈。附上这位博主的操作系统的CSDN笔记链接[操作系统--作者Alatebloomer](https://blog.csdn.net/alatebloomer/category_7565411.html)</small>

# 1. 基本概念

## 1.1 操作系统-概述

> [操作系统 （计算机管理控制程序）]([https://baike.baidu.com/item/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/192?fr=aladdin](https://baike.baidu.com/item/操作系统/192?fr=aladdin))
>
> 操作系统(Operating System，简称OS)是管理[计算机](https://baike.baidu.com/item/计算机)[硬件](https://baike.baidu.com/item/硬件)与[软件](https://baike.baidu.com/item/软件)资源的[计算机程序](https://baike.baidu.com/item/计算机程序)。操作系统需要处理如管理与配置[内存](https://baike.baidu.com/item/内存)、决定[系统资源](https://baike.baidu.com/item/系统资源/974435)供需的优先次序、控制[输入设备](https://baike.baidu.com/item/输入设备/10823368)与[输出设备](https://baike.baidu.com/item/输出设备/10823333)、操作网络与管理文件系统等基本事务。操作系统也提供一个让用户与系统交互的操作界面。

### 1.1.1 操作系统的层次结构

操作系统位于硬件之上，应用程序之下。

操作系统的最重要部分即Kernel，俗称内核。

内核Kernel向外提供底层硬件的抽象接口实现，即系统调用System Call。

再外层的Shell、共用函数库lib则是对系统调用的简单封装。

最外层应用程序通过Shell编程or调用共用函数库来申请使用系统调用，进而与硬件进行交互。（实际应用层编程，无需关心硬件的差异性，仅需要调用操作系统提供的系统调用即可。）

![img](https://pic3.zhimg.com/80/416d6b469bda642f1edf7ff56c1aea4d_720w.jpg?source=1940ef5c)

> [shell、操作系统、内核是一个东西吗？](https://www.zhihu.com/question/37695460)
>
> 上图就是来自这个链接，没有图床就这样了。

## 1.2 OS内核-Kernel

> [内核和操作系统的区别](https://zhuanlan.zhihu.com/p/54665833)
>
> [Kernel (operating system)--wiki](https://en.wikipedia.org/wiki/Kernel_(operating_system))

操作系统OS内核Kernel的特征：

+ 并发

  计算机系统中同时存在多个运行的程序，需要OS管理和调度

+ 共享

  + "同时"访问
  + 互斥共享

+ 虚拟

  利用多道程序设计技术，让每个用户都觉得有一个计算机专门为他服务

+ 异步

  + 程序的执行不是一贯到底，而是走走停停，向前推进的速度不可预知
  + 只要运行环境相同，OS需要保证同一个程序的运行结果相同

操作系统的三大关注点：

+ CPU--OS--进程
+ Memory--OS--地址空间
+ 文件--OS--磁盘

![img](https://img-blog.csdn.net/20180426131125758?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FsYXRlYmxvb21lcg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

> [一、绪论](https://blog.csdn.net/Alatebloomer/article/details/79819975)
>
> <small>估计看的网课都是同一个，正好缺图床。</small>

## 1.3 VMM虚拟机监视器

> [虚拟机监视程序--百度百科]([https://baike.baidu.com/item/%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9B%91%E8%A7%86%E7%A8%8B%E5%BA%8F/20839241?fromtitle=VMM&fromid=7047240&fr=aladdin](https://baike.baidu.com/item/虚拟机监视程序/20839241?fromtitle=VMM&fromid=7047240&fr=aladdin))
>
> 监控系统行为是[虚拟机](https://baike.baidu.com/item/虚拟机/104440)系统的核心任务监控系统可用于调度任务、[负载均衡](https://baike.baidu.com/item/负载均衡/932451)、向管理员报告软硬件故障，并广泛控制系统的使用情况。
>
> 虚拟化是从逻辑角度出发的资源配置方案，是对物理资源的一种抽象。抽象的结果是，在只有一台计算机硬件的情况下、通过虚拟化技术、可以让多个操作系统同时运行在此计算机硬件上，并且让这些操作系统都认为自己独享整个硬件，资源划分对操作系统是透明的。

![img](https://bkimg.cdn.bcebos.com/pic/b3119313b07eca801ea8eee99b2397dda144830b?x-bce-process=image/watermark,image_d2F0ZXIvYmFpa2U4MA==,g_7,xp_5,yp_5)

VMM将单独的机器接口转换成很多的幻象。每个这些接口（虚拟机）是一个原始计算机系统的有效副本，并完成所有的处理器指令。

```none
|VMs0、VMs1、VMs2...(多台虚拟机VMs)   |
|虚拟机监视器(VMM),也称为管理程序       |
|平台硬件(内存、CPU处理器、I/O设备)     |
```

常见的使用场景，就是VMware，大家常用的虚拟机程序啦。(物理硬件用同一套，VMM层抽象出接口，然后上层再搭载多个虚拟机操作系统)

![img](https://img-blog.csdn.net/20180426135244759?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FsYXRlYmxvb21lcg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

> [一、绪论](https://blog.csdn.net/Alatebloomer/article/details/79819975)

# 2. 启动；中断、异常、系统调用

## 2.1 启动

### 2.1.1 计算机体系结构概述

> [bios--百度百科](https://baike.baidu.com/item/bios/91424?fr=aladdin)
>
> BIOS是英文"**Basic Input Output System**"的[缩略词](https://baike.baidu.com/item/缩略词)，直译过来后中文名称就是"**基本输入输出系统**"。在[IBM](https://baike.baidu.com/item/IBM/9190) PC兼容系统上，是一种业界标准的[固件](https://baike.baidu.com/item/固件/627829)[接口](https://baike.baidu.com/item/接口/2886384)。 [1] BIOS这个字眼是在1975年第一次由[CP/M](https://baike.baidu.com/item/CP%2FM)操作系统中出现。  **BIOS是[个人电脑](https://baike.baidu.com/item/个人电脑/3688503)启动时加载的第一个软件。**
>
> 其实，它是一组固化到[计算机](https://baike.baidu.com/item/计算机)内[主板](https://baike.baidu.com/item/主板)上一个[ROM](https://baike.baidu.com/item/ROM)[芯片](https://baike.baidu.com/item/芯片)上的[程序](https://baike.baidu.com/item/程序)，它**保存着计算机最重要的基本输入输出的程序、开机后自检程序和系统自启动程序**，它可从CMOS中读写[系统设置](https://baike.baidu.com/item/系统设置)的具体信息。其**主要功能是为计算机提供最底层的、最直接的硬件设置和控制**。此外，BIOS还向作业系统提供一些系统参数。系统硬件的变化是由BIOS隐藏，程序使用BIOS功能而不是直接控制硬件。**现代作业系统会忽略BIOS提供的抽象层并直接控制硬件组件**。
>
> 当今，此系统已成为一些病毒[木马](https://baike.baidu.com/item/木马/530)的目标。一旦此系统被破坏，其后果[不堪设想](https://baike.baidu.com/item/不堪设想/1768458)。

处理器CPU、内存Memory、其他I/O设备等，通过总线连接和通信。

DSIK（硬盘/磁盘）：存放OS。

BIOS：基本I/O处理系统

Bootloader：加载OS

POST(加电自检)：寻找显卡和执行BIOS

> [开机自检--百度百科]([https://baike.baidu.com/item/%E5%BC%80%E6%9C%BA%E8%87%AA%E6%A3%80/5199677?fr=aladdin](https://baike.baidu.com/item/开机自检/5199677?fr=aladdin))
>
> 也称[上电自检](https://baike.baidu.com/item/上电自检/10976730)(POST，Power On Self Test)。 指计算机系统，接通电源，（BIOS程序）的行为，包括对CPU、系统主板、基本内存、[扩展内存](https://baike.baidu.com/item/扩展内存/7353990)、系统ROM BIOS等器件的测试。如发现错误，给操作者提示或警告。简化或加快该过程，可使系统能够[快速启动](https://baike.baidu.com/item/快速启动/5173174)。

### 2.1.2 启动大致流程

> [BIOS在POST时 最先检测的硬件是内存还是CPU?](https://zhidao.baidu.com/question/2137750054738218748.html)
>
> [BootLoader--百度百科](https://baike.baidu.com/item/BootLoader/8733520?fr=aladdin)
>
> 在嵌入式操作系统中，BootLoader是在[操作系统](https://baike.baidu.com/item/操作系统)内核运行之前运行。可以初始化硬件设备、建立内存空间映射图，从而将系统的软硬件环境带到一个合适状态，以便为最终调用[操作系统内核](https://baike.baidu.com/item/操作系统内核/297824)准备好正确的环境。

大致加载步骤：

1. 计算机启动时，首先执行BIOS程序中的自检程序，俗称POST（Power On Self Test），对计算机硬件设备进行检查，确定无故障后再将CPU执行权交还给BIOS主体。
2. BIOS加载Bootloader程序，把CPU控制权交给Bootloader。
3. BootLoader从硬盘Disk加载OS，使操作系统在内存中运行，把CPU控制权交给OS。（为了方便BootLoader记载OS，一般把OS放在硬盘的第一个扇区，比如Windows的C盘）

+ BIOS
  + 将Bootloader从磁盘的引导扇区（512字节）加载到0x7c000。
  + 跳转到CS:IP = 0000:7c00
+ Bootloader
  + 将操作系统的代码和数据从硬盘加载到内存中
  + 跳转到操作系统的起始地址

![img](https://img-blog.csdn.net/20180406172135760?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FsYXRlYmxvb21lcg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

> [二、操作系统启动、中断、异常和系统调用](https://blog.csdn.net/Alatebloomer/article/details/79834924)

## 2.2 系统调用、异常、中断

### 2.2.1 定义

+ 系统调用（来源于应用程序）

  应用程序主动向操作系统发出服务请求

+ 异常（来源于不良的应用程序）

  非法指令或者其他坏的处理状态（如：内存出错）

+ 中断（来源于外设）

  来自不同的硬件设备的计时器和网络的中断

从"产生源头"、"处理时间"、"响应处理"三个角度分析三者的异同点：

1. 产生源头
   + 系统调用：应用程序请求操作系统提供服务<small>（比如操作文件）</small>
   + 异常：应用程序意想不到的行为<small>（比如程序出现除零操作，系统执行指令出错等）</small>
   + 中断：外设<small>（比如网卡获取数据，网卡驱动程序将数据加载到内存后，要求CPU处理。更常见的就是键盘、鼠标操作）</small>
2. 处理时间
   + 系统调用：异步或同步<small>（同步：打开文件，等待返回文件描述符，得到结果前阻塞；异步：查看socket是否有接受到数据，没有则直接返回，不阻塞）</small>
   + 异常：同步<small>(除零操作，直接抛出异常。如果没有设置异常处理函数，程序进程崩溃并异常退出。)</small>
   + 中断：异步<small>（用户进程无感知，毕竟什么时候别的外设要占用CPU是完全随机的）</small>
3. 响应处理
   + 系统调用：等待和持续<small>（同步的系统调用则等待OS返回结果；异步则执行向下执行，OS返回结果时执行回调函数）</small>
   + 异常：杀死或者重新执行意想不到的应用程序指令<small>（一般没有预设异常处理函数，就是进程崩溃。）</small>
   + 中断：持续，对用户程序是透明的<small>（很好理解，你完全无需关心网卡等外设什么时候有数据被CPU处理了。）</small>

![img](https://img-blog.csdn.net/20180406175715834?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FsYXRlYmxvb21lcg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

> [二、操作系统启动、中断、异常和系统调用](https://blog.csdn.net/Alatebloomer/article/details/79834924)

### 2.2.2 系统调用

> [系统调用--百度百科]([https://baike.baidu.com/item/%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8](https://baike.baidu.com/item/系统调用))
>
> 由[操作系统](https://baike.baidu.com/item/操作系统/192)实现提供的所有系统调用所构成的集合即[程序接口](https://baike.baidu.com/item/程序接口/150383)或应用编程接口(Application Programming Interface，API)。是[应用程序](https://baike.baidu.com/item/应用程序)同系统之间的接口。

​	在计算机运行中，内核Kernel是被信任的第三方，所以只有内核可以执行特权指令（内核态）。为了方便应用程序（用户态）与硬件交互，操作系统提供了一套系统调用System Call接口API。应用程序不能直接操作硬件，因为权限不足（用户态），需要通过系统调用请求，让具有权限的内核Kernel代替用户程序执行特权指令与硬件设备交互（内核态），并把结果返回给用户程序。

​	实际开发中，程序访问的主要是高层次的API接口而不是直接进行系统调用。

+ WIN32 API用于Windows
+ POSIX API用于POSIX-based systems（包括UNIX、Linux、Mac OS X的所有版本）
+ Java API用于Java虚拟机（JVM）

*（POSIX提供一些可移植的系统调用标准。UNIX等遵循这种标准开发，使得操作系统具有可以执行。)*

*（Java虚拟机JVM提供的API不是系统调用，但是最后也是调用的POSIX API，所以说JVM跨平台，移植性好。）*

*（POSIX之所以说以执行好，就是因为UNIX、LINUX等都按照它这个标准去实现，那么高层应用调用POSIX API就根本不用管底层操作系统OS是UNIX内核还是Linux内核等。也就是说POSIX的可移植性强，源自大家都按它标准实现，使得上层应用无需关系底层差异性，反正用的都是同一套标准的POSIX API。）*

![img](https://img-blog.csdn.net/2018040619195766?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FsYXRlYmxvb21lcg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

> [POSIX-可移植操作系统接口--百度百科]([https://baike.baidu.com/item/%E5%8F%AF%E7%A7%BB%E6%A4%8D%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E6%8E%A5%E5%8F%A3/12718298?fromtitle=POSIX&fromid=3792413&fr=aladdin](https://baike.baidu.com/item/可移植操作系统接口/12718298?fromtitle=POSIX&fromid=3792413&fr=aladdin))
>
> <small>**可移植操作系统接口**（英语：Portable Operating System Interface，缩写为**POSIX**）是[IEEE](https://baike.baidu.com/item/IEEE)为要在各种[UNIX](https://baike.baidu.com/item/UNIX)[操作系统](https://baike.baidu.com/item/操作系统)上运行软件，而定义[API](https://baike.baidu.com/item/API)的一系列互相关联的标准的总称，其正式称呼为IEEE Std 1003，而国际标准名称为[ISO](https://baike.baidu.com/item/ISO)/[IEC](https://baike.baidu.com/item/IEC) 9945。此标准源于一个大约开始于1985年的项目。POSIX这个名称是由[理查德·斯托曼](https://baike.baidu.com/item/理查德·斯托曼)（RMS）应IEEE的要求而提议的一个易于记忆的名称。它基本上是Portable Operating System Interface（可移植操作系统接口）的缩写，而**X**则表明其对Unix API的传承。</small>
>
> [二、操作系统启动、中断、异常和系统调用](https://blog.csdn.net/Alatebloomer/article/details/79834924)

### 2.2.3 异常

> [异常(计算机术语)--百度百科]([https://baike.baidu.com/item/%E5%BC%82%E5%B8%B8/5952477#viewPageContent](https://baike.baidu.com/item/异常/5952477#viewPageContent))
>
> 异常指的是在程序运行过程中发生的异常事件，通常是由外部问题（如硬件错误、输入错误）所导致的。在Java等面向对象的编程语言中异常属于对象。

​	一般进程出现异常时，会产生对应的异常编号。操作系统尝试保存现场、异常处理（杀死产生异常的程序or重新执行异常指令）、恢复现场。

*（开发中，如果没有异常处理函数，那一般遇到的就是程序崩溃。如果在一些容器、服务下运行，好一点就是会保留一些错误提示。常见的WEB开发就是会保留错误提示。）*

### 2.2.4 中断

> [中断--百度百科]([https://baike.baidu.com/item/%E4%B8%AD%E6%96%AD/3933007?fr=aladdin](https://baike.baidu.com/item/中断/3933007?fr=aladdin))
>
> 中断是指计算机运行过程中，出现某些意外情况需主机干预时，机器能自动停止正在运行的程序并转入处理新情况的程序，处理完毕后又返回原被暂停的程序继续运行。

中断还可以细分为**硬中断**和**软中断**。

硬件中断（Hardware Interrupt）：

- 可屏蔽中断（maskable interrupt）。[硬件中断](https://baike.baidu.com/item/硬件中断)的一类，可通过在中断屏蔽寄存器中设定位掩码来关闭。
- 非可屏蔽中断（non-maskable interrupt，NMI）。硬件中断的一类，无法通过在中断屏蔽寄存器中设定位掩码来关闭。典型例子是时钟中断（一个硬件时钟以恒定频率—如50Hz—发出的中断）。
- 处理器间中断（interprocessor interrupt）。一种特殊的硬件中断。由处理器发出，被其它处理器接收。仅见于多处理器系统，以便于[处理器](https://baike.baidu.com/item/处理器)间通信或同步。
- 伪中断（spurious interrupt）。一类不希望被产生的硬件中断。发生的原因有很多种，如中断线路上电气信号异常，或是中断请求设备本身有问题。

软件中断（Software Interrupt）：

- 软件中断。是一条CPU指令，用以自陷一个中断。由于软中断指令通常要运行一个切换CPU至内核态（Kernel Mode/Ring 0）的子例程，它常被用作实现[系统调用](https://baike.baidu.com/item/系统调用)（System call）。

中断处理时，硬件、软件的相关要点：

1. 硬件：
   + 设置中断标记[CPU初始化]
     1. 将内部、外部事件设置中断标记
     2. 中断事件的ID
2. 软件：
   + 保存当前处理状态
   + 中断服务程序处理
   + 清理中断标记
   + 恢复之前保存的处理状态

### 2.2.5 跨越操作系统边界的开销

在执行时间上的开销超过程序调用。

开销：

+ 建立中断/异常/系统调用号与对应服务例程映射关系的初始化开销（一般是维护一张表来表示关系）
+ 建立内核堆栈（暂存当时的CPU运行状态）
+ 验证参数
+ 内核态映射到用户态的地址空间，更新页面映射权限（内核态操作，如果数据是用户态需要的，还需要把内核态内存区域的数据拷贝一份到用户态）
+ 内核态独立地址空间TLB刷新（缺页中断等，刷新TLB快表，TLB用于缓存常访问的内存区域地址映射关系）

# 3. 内存、地址空间、内存分配

## 3.1 内存和地址空间

### 3.1.1 计算机基本硬件结构

![img](https://img-blog.csdn.net/20180406210026897?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FsYXRlYmxvb21lcg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

```none
CPU        内存          设备(I/O)
|           |             |
<-----------总线------------->

CPU:进程在这里执行操作(CPU有运算器、寄存器、控制器、缓存Cache、存储处理单元MMU)
内存:执行的程序(进程)和数据驻留于此
设备(I/O):磁盘设备、鼠标、键盘、网卡等
```

虽然不同类型的硬件没有可比性，但是一般来说CPU工作速率>内存>设备(I/O)，这里只是模糊又不专业的说法。

CPU取指or取数据时，一般按照如下顺序查找，如果找不到就一直往下，找到了就不再往下了，实在找不到那就抛除异常了。

+ 寄存器（最快）
+ L1缓存
+ L2缓存
+ L3缓存<small>（多核CPU，3级缓存是多核共享的。一般1级和2级缓存都是KB大小，这个3级缓存MB大小）</small>
+ L4及等多的缓存，一般都是MB大小，如果有的话...<small>(据说L4缓存带来的速度提升不明显，我的电脑就有4级缓存)</small>

+ 主存<small>（也就是内存Memory）</small>
+ 虚拟内存<small>（也就是硬盘，需要操作系统支持虚拟化内存的技术。最慢）</small>

*<small>（对自己的电脑硬件配置不清楚的，推荐可以下载个[HWiNFO](https://www.hwinfo.com/)，算是各种参数比较齐全的硬件检测软件了吧。）</small>*

> [MMU--百度百科](https://baike.baidu.com/item/MMU/4542218?fr=aladdin)
>
> MMU是Memory Management Unit的缩写，中文名是[内存管理](https://baike.baidu.com/item/内存管理)单元，有时称作**分页内存管理单元**（英语：**paged memory management unit**，缩写为**PMMU**）。它是一种负责处理[中央处理器](https://baike.baidu.com/item/中央处理器)（CPU）的[内存](https://baike.baidu.com/item/内存)访问请求的[计算机硬件](https://baike.baidu.com/item/计算机硬件)。它的功能包括[虚拟地址](https://baike.baidu.com/item/虚拟地址)到[物理地址](https://baike.baidu.com/item/物理地址)的转换（即[虚拟内存](https://baike.baidu.com/item/虚拟内存)管理）、内存保护、中央处理器[高速缓存](https://baike.baidu.com/item/高速缓存)的控制，在较为简单的计算机体系结构中，负责[总线](https://baike.baidu.com/item/总线)的[仲裁](https://baike.baidu.com/item/仲裁)以及存储体切换（bank switching，尤其是在8位的系统上）。
>
> [三、计算机体系结构与内存体系、内存分配](https://blog.csdn.net/Alatebloomer/article/details/79836751)

### 3.1.2 物理地址和虚拟(逻辑)地址-简述

> [物理地址 （CPU中相关术语）--百度百科]([https://baike.baidu.com/item/%E7%89%A9%E7%90%86%E5%9C%B0%E5%9D%80/2901583?fr=aladdin](https://baike.baidu.com/item/物理地址/2901583?fr=aladdin))
>
> 在[存储器](https://baike.baidu.com/item/存储器/1583185)里以[字节](https://baike.baidu.com/item/字节/1096318)为单位存储信息，为正确地存放或取得信息，每一个字节单元给以一个唯一的[存储器地址](https://baike.baidu.com/item/存储器地址/7874173)，称为物理地址（Physical Address），又叫[实际地址](https://baike.baidu.com/item/实际地址/1061693)或[绝对地址](https://baike.baidu.com/item/绝对地址/573580)。
>
> [虚拟地址--百度百科]([https://baike.baidu.com/item/%E8%99%9A%E6%8B%9F%E5%9C%B0%E5%9D%80/1329947?fr=aladdin](https://baike.baidu.com/item/虚拟地址/1329947?fr=aladdin))
>
> 虚拟地址是Windows程序时运行在386保护模式下，这样程序访问[存储器](https://baike.baidu.com/item/存储器/1583185)所使用的[逻辑地址](https://baike.baidu.com/item/逻辑地址/3283849)称为虚拟地址，与实地址模式下的分段地址类似，虚拟地址也可以写为“段：[偏移量](https://baike.baidu.com/item/偏移量/9180391)”的形式，这里的段是指段选择器。

​	其实不管用了什么技术，一般而言，CPU找数据顶多向下找到内存，不会再去找硬盘，就算真有从硬盘上取数据，那其实也是把硬盘数据先取到内存，然后CPU再从内存中取数据。简言之，**CPU除了从寄存器、CPU缓存中取数据，那么就只能从内存中取数据**。

1. 逻辑地址范围

   32位操作系统，理论上可以寻址2<sup>32</sup>Byte内存，也就是4GB内存，这种理论上的出的就是**逻辑地址**的寻址范围了。*<small>（64位理论上可以寻址2<sup>64</sup>Byte的内存，但是由于内存寻址一般需要页表等机制管理，这个数量级太大了，所以其实也没操作系统真的用到那么大范围的逻辑地址）</small>*

2. 物理地址范围

   物理地址，那就是看内存具体多大了。要是内存条就256MB，那就是256MB的**物理地址**的寻址范围了。*<small>（早期计算机的内存条贵，所以很小，现在一般至少都8GB内存，夸张的也有上百GB内存的计算机）</small>*

物理地址空间——硬件支持的地址空间

逻辑地址空间——一个运行的程序所拥有的内存范围

*这里不展开逻辑地址和物理地址的具体描述，知道物理地址对应内存上的地址即可，而逻辑地址不过是进程中使用的地址，实际还需要翻译成物理地址，才能真正从内存上读取数据。过去32位系统，逻辑地址范围>物理地址范围，所以才会衍生出这种技术。*

​	CPU从内存（主存）取数据时，如果寄存器和缓存中没有，那么需要知道数据在内存的哪个<u>物理地址</u>上，而CPU是不清楚什么<u>逻辑地址</u>、<u>物理地址</u>这些乱七八糟的。CPU根据执行的指令中的地址寻找数据时，CPU把这个地址交给MMU，MMU会帮CPU把代码中的**逻辑地址**翻译成**物理地址**，进而CPU能够访问到内存上实际物理地址的数据。（实际CPU访问MMU之前，会先看看TLB快表看看有没有对应的逻辑地址-物理地址的映射记录，有的话就不用劳烦MMU转换了。）

更具体一些的描述：

1. 操作系统，事先建立逻辑地址和物理地址的映射关系。（维护页表等）
2. CPU运算器需要某个逻辑地址的内存内容
3. 内存管理单元MMU寻找在逻辑地址和物理地址之间的映射（这个需要操作系统事先建立好）
4. CPU的控制器往**总线**发送在物理地址的内存内容的请求
5. 内存收到总线上来自CPU的请求，发送物理地址内存的内容给CPU
6. CPU获取数据后继续执行指令

**操作系统维护程序虚拟地址与物理地址之间的映射关系**。如果CPU请求的数据在内存中不存在并触发异常时（比如超出物理地址的范围之类的），需要操作系统去处理异常。

![img](https://img-blog.csdn.net/20180407142744589?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FsYXRlYmxvb21lcg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

![img](https://img-blog.csdn.net/20180407143919790?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FsYXRlYmxvb21lcg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

> [TLB-转译后备缓冲区--百度百科]([https://baike.baidu.com/item/%E8%BD%AC%E8%AF%91%E5%90%8E%E5%A4%87%E7%BC%93%E5%86%B2%E5%8C%BA/22685572?fromtitle=TLB&fromid=2339981&fr=aladdin](https://baike.baidu.com/item/转译后备缓冲区/22685572?fromtitle=TLB&fromid=2339981&fr=aladdin))
>
> **转译后备缓冲器**，也被翻译为**页表缓存**、**转址旁路缓存**，为[CPU](https://baike.baidu.com/item/CPU)的一种缓存，由存储器管理单元用于改进[虚拟地址](https://baike.baidu.com/item/虚拟地址)到物理地址的转译速度。当前所有的桌面型及服务器型处理器（如 [x86](https://baike.baidu.com/item/x86)）皆使用TLB。TLB具有固定数目的空间槽，用于存放将虚拟地址映射至[物理地址](https://baike.baidu.com/item/物理地址)的标签页表条目。为典型的结合存储（content-addressable memory，首字母缩略字：CAM）。其搜索关键字为虚拟内存地址，其搜索结果为物理地址。如果请求的虚拟地址在TLB中存在，CAM 将给出一个非常快速的匹配结果，之后就可以使用得到的物理地址访问存储器。如果请求的虚拟地址不在 TLB 中，就会使用标签页表进行虚实地址转换，而标签页表的访问速度比TLB慢很多。有些系统允许标签页表被交换到次级存储器，那么虚实地址转换可能要花非常长的时间。
>
> [四、地址空间与内存分配](https://blog.csdn.net/Alatebloomer/article/details/79841088)

### 3.1.3 操作系统的内存管理-简述

在操作系统中，管理内存有多种方式：

+ 程序重定向
+ 分段
+ 分页
+ 虚拟内存
+ 按需分页虚拟内存

内存的管理和使用，需要硬件也参与实现。可以说内存管理是高度依赖于硬件的。（比如MMU内存管理单元，作为硬件组件负责处理CPU的内存访问请求）

![img](https://img-blog.csdn.net/20180406210626311?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FsYXRlYmxvb21lcg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

![img](https://img-blog.csdn.net/20180406211817815?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FsYXRlYmxvb21lcg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

上图中的P2、P3和P4的相关数据被放在磁盘中。<u>程序看到的空间是逻辑地址空间，主存和磁盘是物理地址空间</u>。

操作系统的内存管理：

1. 抽象，逻辑地址空间；
2. 保护，独立地址空间；
3. 共享，访问相同内存；
4. 虚拟化，更多的地址空间，最需要的数据放在内存中，暂时不需要的放在磁盘。

操作系统管理内存的不同机制： 
程序重定位，分段，分页，虚拟内存（ 目前多数系统(如Linux)采用按需页式虚拟存储）

管理的实现高度依赖于硬件，要知道内存架构，MMU（内存管理单元）——硬件组件中负责处理CPU的内存访问请求

> 推荐几篇文章<small>(内容比较多，就不像之前的计网笔记那样给出概述了。)</small>
>
> [MMU和cache学习](https://blog.csdn.net/chinesedragon2010/article/details/5922324)
>
> [物理地址和虚拟地址1 （MMU）](https://www.cnblogs.com/leaven/archive/2011/04/18/2019696.html)
>
> [三、计算机体系结构与内存体系、内存分配](https://blog.csdn.net/Alatebloomer/article/details/79836751) <= 上面2大图和下半部分文字来自这个文章

## 3.2 连续内存分配

### 3.2.1 连续内存分配的内存碎片问题

内存碎片问题，简单来说就是内存中存在某些空闲却又没法被使用的内存。

内存碎片一般可以分为两种：

+ 外部碎片

  在分配单元间未使用的内存

+ 内部碎片

  在分配单元中未使用的内存

外部碎片举例：200MB剩余内存，有两个99MB程序运行后，只剩2MB内存。这2MB虽然是空闲内存，但是太小，别人也用不上，就是外碎片了。

内部碎片举例：200MB剩余内存，有个程序申请要占用这200MB内存。<small>（其实内存一般也不可能完全用上，这里就假设）</small>，这时候不存在外碎片了。但是这个进程其实一开始初始化时用了200MB，后来也就只保留100MB常用数据在内存中，导致还有100MB内存空间浪费，这100MB空间就是内碎片。

![img](https://img-blog.csdn.net/20180407145218898?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FsYXRlYmxvb21lcg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

> [四、地址空间与内存分配](https://blog.csdn.net/Alatebloomer/article/details/79841088)

### 3.2.2 分区的动态分配

简单的内存管理方法：

+ 当一个程序准许在内存中时，分配一个连续的内存区间。
+ 分配一个连续的内存区间给运行的程序以访问数据。

常见分配策略：

+ 首次适配（第一适配）
+ 最优适配
+ 最差适配

---

下面拿一个举例来看看首次适配、最优适配、最差适配，这三者的区别：

假设现在内存中，有3段连续且空闲的内存空间（100MB、50MB、200MB），这时候有一个40MB的程序想要到内存中运行。

+ 首次适配：使用100MB的内存空间，即使用内存寻址最先寻找到的空闲区域。占用后，内存空闲空间分布（60MB，50MB、200MB）。
+ 最优适配：使用50MB的内存空间，即寻找和程序所需要的内存空间按最接近的一个区域。占用后，内存空闲空间分布（100MB，10MB、200MB）。
+ 最差适配：使用200MB的内存空间，即使用当前最大的空闲内存区域。占用后，内存空闲空间分布（100MB，10MB、160MB）。

---

对比：

+ 第一适配：
  + 优势：
    1. 简单
    2. 使得地址空间的结尾部分易于产生更大的空闲块
  + 劣势：
    1. 外部碎片
    2. 不确定性
+ 最优适配：
  + 优势：
    1. 比较简单
    2. 当大部分分配是小尺寸时非常有效
  + 劣势：
    1. 外部碎片
    2. 重分配慢
    3. 易产生很多没用的微小外碎片（不怎么好）
+ 最差适配
  + 优势：
    1. 简单
    2. 假如内存分配主要是中等尺寸，效果最好
  + 劣势：
    1. 外部碎片
    2. 重分配慢
    3. 内存空间要求大的进程可能分配不到内存（因为每次都把大的连续空间拆了）

### 3.2.3 压缩式碎片整理

​	重置程序以合并孔洞（指合并内存外碎片）。要求所有程序是动态可重置的（也就是要求程序能保证在内存挪动位置后还能正常运行，不会出现寻址异常等问题）。

​	需要考虑重定向的时机，比如运行时挪动可能导致代码寻址错误。再者需要考虑开销，如果频繁重定向，挪动内存分配的空间，也会浪费很多CPU事件。

```none
|进程1|                              |进程1|
|20MB|                              |进程2| 
|进程2|   ===== 压缩式碎片整理 =====>  |进程3| 
|30MB|                              |20MB|
|进程3|                              |30MB|
|40MB|                              |40MB|

这样就把空闲的20MB、30MB、40MB合并成一个连续的90MB的内存空间了。
```

### 3.2.4 交换式碎片整理

​	优先给需要更多内存的程序加载到内存，其余的等待。比如多个程序申请且占用内存后，剩余的内存空间很小，不够接下去的程序运行，就把一些程序申请后多余没使用的内存回收，交给新的程序使用。要是还不够，先把程序挂载到硬盘（虚拟内存）。

​	简言之，把内存中的程序换下来（挂载），硬盘的程序加载到内存中。

# 4. 非连续内存分配

## 4.0 引言

​	出现非连续内存分配，那么肯定是因为单纯的连续内存分配不能满足复杂操作系统的内存分配需求。

连续内存分配的缺点：

+ 分配给一个程序的物理内存是连续的
+ **内存利用率较低**
+ 有外碎片、内碎片的问题

非连续分配的优点

+ 一个程序的物理地址空间是非连续的
+ 更好的内存利用和管理
+ **允许共享代码与数据**（共享库等......）
+ 支持动态加载和动态链接

非连续分配的缺点

+ 需要考虑如何建立虚拟地址和物理之间的转换<small>（其实现在实现都很成熟了，应该也不是啥大问题了）</small>
  + 软件方案
  + 硬件方案
    + 分段
    + 分页

连续内存分配，可以说进程就是完全互相隔离的，要实现进程间通信比较难。后来的分连续分配，对进程间通讯的支持就很好了。

非连续内存分配，如果纯软件方案实现，难度大开销大，不现实。一般采取软硬件相结合的方式，即硬件方面设计时就考虑分段、分页等问题，然后软件按照硬件规定的分段、分页标准具体设计规划内存的非连续分配。

## 4.1 分段(Segmentation)

### 4.1.1 程序的分段地址空间	

​	早期设计时，按照应用的特点来进行分离和管理内存空间。（比如进程的函数调用栈，都统一放到某一段空间内去分配）

​	虽然程序员在编程时获取的是连续的逻辑地址空间，但是实际在内存中运行时，根据进程不同的组成部分，把其拆分到不同的物理地址空间中。（进程由堆、运行栈、程序数据、程序text字段组成，那么把每个进程的堆都放到内存某一片区域，运行栈、程序数据同理。而程序text段还可以细分成库和用户代码，再放到不同物理地址空间。库是多个进程可以共享的，之后出现进程调用相同的库就不用重复加载了。）

​	这样分段，使得进程虚拟地址空间划分到物理地址空间的映射有一定可控性，也可以实现部分物理空间共用。再者，这样方便把控权限，保证安全，比如把库等需要系统调用的，放到"内核态"使用的内存空间。

*（一般而言，操作系统会把虚拟地址划分成内核态区域和用户态区域。）*

![img](https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1596452791980&di=241d98dc422946a96a4c667505d766fa&imgtype=0&src=http%3A%2F%2Finews.gtimg.com%2Fnewsapp_bt%2F0%2F12010650392%2F641.jpg)

![img](https://img-blog.csdn.net/20180407160437973?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FsYXRlYmxvb21lcg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

![img](https://img-blog.csdn.net/20180407160527174?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FsYXRlYmxvb21lcg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

> [四、地址空间与内存分配](https://blog.csdn.net/Alatebloomer/article/details/79841088)

### 4.1.2 分段寻址方案

​	在分段的内存空间中，一个段对应一个内存"块"，一个段本身是一个逻辑地址空间。

​	程序访问内存地址，需要一个二维的二元组`(s，addr)`，s段号，addr段内偏移

```none
# 下面就打个比方，具体取几位数没有严格按照分段方案来
[010101] [1100101010]
n2     0 n1         0 
   s          addr
段寄存器+地址寄存器实现方案(也就是用两个寄存器存分段寻址的地址，组合后对应真实物理地址)

[1000101010010]
n             0
 | s |  addr  |
单地址实现方案(也就是前半段是s段号，后半部分是段内偏移,组合后经过计算获得对应的真实物理地址)

# 一般都是 s 左移几位，然后加上 addr获取对应的物理地址(指分段方案下，逻辑地址到物理地址的转换方式)
```

![img](https://img-blog.csdn.net/20180407161207970?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FsYXRlYmxvb21lcg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

> [四、地址空间与内存分配](https://blog.csdn.net/Alatebloomer/article/details/79841088)

### 4.1.3 内存分段的硬件实现方案

*<small>(大致找了张图，文字描述不一定和图一样，毕竟没图床，就这样吧。哈哈)）</small>*

![img](https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1596451014660&di=5d5ddf351b24f93e40514786fd8d6a39&imgtype=0&src=http%3A%2F%2Fa4.att.hudong.com%2F72%2F22%2F01200000144761134439220160183_s.jpg)

​	首先，段表需要操作系统建立并维护，然后再与硬件建立联系（比如段寄存器、地址寄存器、MMU等）。当然，段表的建立，操作系统也不是随便整的，必须按照硬件支持的段表寻址方式去实现和维护段表。

​	程序P运行=>CPU执行=>遇到需要从内存寻址的数据(段号s+段内偏移addr)=>段表查询，MMU转换逻辑地址=>CPU获取物理地址后，往总线向内存发起物理地址空间对应的数据获取请求=>内存响应CPU请求，并返回数据到总线=>CPU从总线获取到来自内存的数据，继续执行。

*（分段这种机制，基本被淘汰了，基本采用后面的分页方式，分页本身也是建立在分段思想上的。）*

![img](https://img-blog.csdn.net/2018040716232263?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FsYXRlYmxvb21lcg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

> [四、地址空间与内存分配](https://blog.csdn.net/Alatebloomer/article/details/79841088)

## 4.2 分页

### 4.2.1 分页地址空间

​	前面的分段，需要考虑段号和段内偏移；而分页，同样需要考虑页号和业内偏移。

​	**分页和分段两种机制的最大区别是：段是变长大小的，而页是固定大小的**。

+ 划分物理内存至**固定大小**的帧
  + 大小是2的幂，例如512、4096、8192
+ 划分逻辑地址空间至**相同大小**的页
  + 大小是2的幂，例如512、4096、8192

+ 建立方案转换逻辑地址为物理地址（pages to frames）
  + 页表
  + MMU/TLB

注意，物理地址PA（Physical Address）划分成固定大小的帧frame，而虚拟地址VA（Virtual address）划分成固定大小的page。

**frame和page必须大小相同**，如果frame是512，那么page也必须是512，如果frame=4KB，那么page也必须=4KB。

操作系统维护页表，记录VA到PA的转换。<small>（有VA作键key，PA作值value的；也有逆向页表PA作key，VA作value的。后者相对省空间，但是实现和维护更复杂。）</small>

MMU同理还是做VA和PA之间的转换工作，而TLB是页表的快表。<small>(也就是页表缓存，MMU转换后缓存结果到TLB，这样CPU要是遇到相同的虚拟地址就不用MMU重复到主存查页表然后转换地址。即TLB省去一次访问主存查页表找页号对应的页帧的时间，直接从TLB获取页号对应的页帧，然后就直接向主存申请对应物理地址的数据。这样明显比访问主存查页表+后续访问主存取数据快一点。)</small>

---

帧Frame：

物理内存被分割为大小相同的帧。

一个内存物理地址是一个二元组`(f,o)`，f帧号（F位，共有2<sup>F</sup>个帧），o帧内偏移（S位，每帧有2<sup>S</sup>字节）。
$$
物理地址PA=2^S*f+o
$$

---

页Page：

一个程序的逻辑地址空间被划分为大小相等的页。

+ **页内偏移的大小=帧内偏移的大小**
+ **页号大小<>帧号大小**

一个逻辑地址是一个二元组`(p,o)`，p页号（P位，2<sup>P</sup>个页），o页内偏移（S位，每页有2<sup>S</sup>字节）
$$
虚拟地址VA=2^S*p+o
$$

---

地址计算示例：

16-bit的物理地址PA，9-bit（512byte）大小的页帧，已知物理地址二元组表示为（3，6），那么计算物理地址为`2^9*3+6`，即1542。

![img](https://img-blog.csdn.net/20180407170551483?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FsYXRlYmxvb21lcg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

![img](https://img-blog.csdn.net/20180407170838613?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FsYXRlYmxvb21lcg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

![img](https://img-blog.csdn.net/20180407170648103?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FsYXRlYmxvb21lcg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

> [四、地址空间与内存分配](https://blog.csdn.net/Alatebloomer/article/details/79841088)

### 4.2.2 页寻址方案

![img](https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1596454096480&di=924a1703a50aef6a166ec1379c818003&imgtype=0&src=http%3A%2F%2Finews.gtimg.com%2Fnewsapp_bt%2F0%2F12010650396%2F641.jpg)

![img](https://ss2.bdstatic.com/70cFvnSh_Q1YnxGkpoWK1HF6hhy/it/u=206931261,4704473&fm=15&gp=0.jpg)

​	和前面分段机制差不多。页表存储页号-帧号的对应关系。由于页大小和帧大小相同，所以只要页号p查找到最终对应的帧号f后，通过计算公式，就可以得出具体的物理地址了。（页大小和帧大小相同，所以页偏移o和帧偏移o是一样的数值）

​	同样，页表由操作系统建立，操作系统初始化的时候就得加载好页表管理系统。

在页寻址机制中，注意几个要点：

+ 页映射到帧
+ 页是**连续**的虚拟内存<small>(也就是程序开发视角来看，地址是连续的）</small>
+ 帧是**非连续**的物理内存<small>(也就是说实际连续的虚拟地址对应的物理地址不一定是连续的，这样才能充分利用内存外部碎片，也方便一些减少内部碎片的内存管理机制实现）</small>
+ 不是所有的页都有对应的帧<small>(二种情况，物理内存全用完了，虚拟地址还有剩；或者虚拟地址没用完，物理地址也没用完。一般而言虚拟地址范围>=物理地址范围）</small>

## 4.3 页表

### 4.3.1 页表概述

> [请问在操作系统中PTBR和PTLR分别指什么？](https://iask.sina.com.cn/b/1H4Spm1zSq5n.html)
>
> 页表基寄存器（PTBR）指向页表. 页表长度寄存器（PTLR）指示页表的大小
>
> [操作系统概念学习笔记 16 内存管理(二) 段页](https://blog.csdn.net/sunmc1204953974/article/details/46859785)
>
> [读懂操作系统之虚拟内存基本原理篇（一）](https://www.cnblogs.com/CreateMyself/p/12969171.html)
>
> <small>上面这篇很好，主要图多，哈哈。下面的图片也是来自上述文章。</small>

![img](https://img2020.cnblogs.com/blog/589642/202005/589642-20200528215647997-211397649.png)

![img](https://img2020.cnblogs.com/blog/589642/202005/589642-20200528221912276-1423676717.png)

​	每个运行中的程序都有一个页表，其也算是程序运行状态，会动态变化。PTBR页表基址寄存器起到页表指针的作用，存放页表的索引key。

​	页表项除了存储 页号-帧号对应关系，还会存储一些状态信息。（比如这个页号对应的帧号数据是否被执行过写操作，是否被访问过等）操作系统需要根据页表中各个页表项的状态参数信息来实时维护、修改页表信息。（这个与后续介绍的页置换算法有关，也就是每个进程能分配到的实际内存物理空间有限，需要考虑把一些暂时不用的页帧置换出来，减少缺页中断次数，提高CPU运行效率）

```none
#页表项的内容(伪代码，只描述部分)
+ Flags(标志位)
  + dirty bit
  + resident bit
  + clock/reference bit
+ 帧号f

#示例，下面假装页表某一项
[010 | f]

dirty bit = 0 说明数据没有被执行过写操作(因为计算机很笨，一般你执行写操作，不管数据变不变，它直接当你变过了。)
resident bit = 1 说明该页号对应的页帧存在(也就是内存有对应的物理帧与该页表项的页号对应,0则说明后面帧号f无效)
clock/reference bit = 0 说明该页没被访问过(这个与后面的页置换算法有关。没有访问过的页表项可能被置换出来)
f 页帧号，就是对应物理地址的帧号
```

![img](https://img-blog.csdn.net/20180407171021168?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FsYXRlYmxvb21lcg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

![img](https://img-blog.csdn.net/20180410001844981?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FsYXRlYmxvb21lcg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

> [四、地址空间与内存分配](https://blog.csdn.net/Alatebloomer/article/details/79841088)

### 4.3.2 转换后背缓存区(TLB)

> [TLB-转译后备缓冲区--百度百科]([https://baike.baidu.com/item/%E8%BD%AC%E8%AF%91%E5%90%8E%E5%A4%87%E7%BC%93%E5%86%B2%E5%8C%BA/22685572?fromtitle=TLB&fromid=2339981&fr=aladdin](https://baike.baidu.com/item/转译后备缓冲区/22685572?fromtitle=TLB&fromid=2339981&fr=aladdin))
>
> TLB 用于缓存一部分标签页表条目。TLB可介于 CPU 和[CPU缓存](https://baike.baidu.com/item/CPU缓存)之间，或在 CPU 缓存和[主存](https://baike.baidu.com/item/主存)之间，这取决于缓存使用的是物理寻址或是虚拟寻址。如果缓存是虚拟定址，定址请求将会直接从 CPU 发送给缓存，然后从缓存访问所需的 TLB 条目。如果缓存使用物理定址，CPU 会先对每一个存储器操作进行 TLB 查寻，并且将获取的物理地址发送给缓存。两种方法各有优缺点。

分页机制存在一个明显的性能问题。即**访问一个内存单元，需要2次内存访问**<small>（没有TLB之前）</small>。

+ 一次用于获取页表项<small>(因为页表本身就是存放在内存中的)</small>
+ 一次用于访问数据<small>(从页表获取到页号具体的页帧后，还需要根据实际物理地址从总线向内存发起数据请求)</small>

再者，页表可能非常大。64位机器理论可以有2<sup>64</sup>Byte的寻址能力，如果只用一级页表，那么光是访问这张表，时间开销就超级大。*<small>（实际上常见的64位操作系统，也没有真的用2<sup>64</sup>Byte大小的虚拟地址，因为没必要，物理内存本身都没有那么大的数量级。）</small>*

为了解决这些问题，就出现了缓存Caching、间接访问等解决方案。而**TLB就是采用了缓存方案，使得页表机制下的内存访问能更快**。

---

![img](https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1596462377005&di=89e4a520e3f96e4b0d9a181145bb40e0&imgtype=0&src=http%3A%2F%2Foenhan.com%2Fwp-content%2Fuploads%2F2013%2F09%2Fpage_table_plus_tlb-1.jpg)

Translation Look-aside Buffer（TLB)，缓存近期访问的页帧转换表项

+ TLB使用associative memoty（关联内存）实现，具备快速访问性能
+ 如果TLB命中，物理页号可以很快被获取
+ 如果TLB未命中，对应的表项被更新到TLB中

前面提到过页表项存在Flags多个状态标识符，其中`resident bit`，判断是否存在 虚拟地址VA 对应的 物理地址PA。

CPU寻址，先看看存储器内的快表TLB是否有页表缓存，没有再取更慢的内存memory中查找页表项。如果连内存的页表也不存在虚拟地址对应的物理地址，那么抛出内存地址访问异常，交由操作系统去处理异常。

根据不同的CPU设计，TLB未命中时，从内存获取页表项并缓存到TLB的这个动作可能由CPU硬件完成，也可能由操作系统OS完成。*<small>(32位x86的CPU能硬件完成该动作，也有别的CPU需要依靠软件，也就是需要操作系统来完成填充TLB表的工作)</small>*

---

![image](http://blog.chinaunix.net/attachment/201112/18/16361381_1324218546w802.jpg)

​	**由于CPU首先接到的是由程序传来的虚拟内存地址，所以CPU必须先到物理内存中取页表，然后对应程序传来的虚拟页面号，在表里找到对应的物理页面 号，最后才能访问实际的物理内存地址，也就是说整个过程中CPU必须访问两次物理内存(实际上访问的次数更多)。因此，为了减少CPU访问物理内存的次 数，引入TLB**。

​	TLB在X86体系的CPU里的实际应用最早是从Intel的486CPU开始的，在X86体系的CPU里边，一般都设有如下4组TLB:

+ 第一组：缓存一般页表（4K字节页面）的指令页表缓存（Instruction-TLB）；

+ 第二组：缓存一般页表（4K字节页面）的数据页表缓存（Data-TLB）；

+ 第三组：缓存大尺寸页表（2M/4M字节页面）的指令页表缓存（Instruction-TLB）；

+ 第四组：缓存大尺寸页表（2M/4M字节页面）的数据页表缓存（Instruction-TLB）；

​	图中可见，当CPU执行机构收到应用程序发来的虚拟地址后，首先到TLB中查找相应的页表数据，如果TLB中正好存放着所需的页表，则称为TLB命中（TLB Hit）,接下来CPU再依次看TLB中页表所对应的物理内存地址中的数据是不是已经在一级、二级缓存里了，若没有则到内存中取相应地址所存放的数据。如果TLB中没有所需的页表，则称为TLB失败（TLB Miss），接下来就必须访问物理内存中存放的页表，同时更新TLB的页表数据。

​	既然说TLB是内存里存放的页表的缓存，那么它里边存放的数据实际上和内存页表区的数据是一致的，在内存的页表区里，每一条记录虚拟页面和物理页框对应关系的记录称之为一个页表条目（Entry），同样地，在TLB里边也缓存了同样大小的页表条目（Entry）。由于页表条目的大小总是固定不变的，所以TLB的容量越大，则它所能存放的页表条目数越多（类似于增大CPU一级、二级缓存容量的作用），这就意味着缓存命中率的增加，这样，就能大大减少CPU直接访问内存的次数，实现了性能提升。

> [TLB是否在多个内核之间共享？(Is the TLB shared between multiple cores?)](https://www.it1352.com/1845896.html)
>
> [多核CPU是有几个TLB？一个核有一个独有的TLB还是多核共享一个TLB？](https://www.zhihu.com/question/313913862/answer/635433592)
>
> [什么是TLB?](https://www.cnblogs.com/linhaostudy/p/10347288.html)
>
> 简言之，每个CPU内核都是有独立的TLB和MMU的。CPU一般用到的缓存就1~3级，L1和L2有TLB，L3是多个内核共享的缓存。
> L1里面还具体分 L1i和L1d，也就是 指令 和 数据的缓存。
>
> **TLB分为指令页表缓存（Instruction-TLB）和数据页表缓存（Data-TLB）**
>
> 一般主流Cache都是物理Cache，即要求访问Cache之前要先访问TLB进行VA到PA的转换。

---

![img](https://img-blog.csdn.net/2018041000331384?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FsYXRlYmxvb21lcg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

> [四、地址空间与内存分配](https://blog.csdn.net/Alatebloomer/article/details/79841088)

### 4.3.3 二级/多级页表

![img](https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1596465825786&di=432cb3dfcda3fa3d0cda4a79be9aa42b&imgtype=0&src=http%3A%2F%2Finews.gtimg.com%2Fnewsapp_bt%2F0%2F12010650398%2F641.jpg)

拆分二级页表，那么一级页表存储的值value是二级页表的初始地址；然后二级页表才是具体的页号-页帧（虚拟地址-物理地址）。

这样虽然开销依然很大，但是有个好处，就是一级页表的页表项如果`resident bit`值为0，那么说明不存在该一级页表项-二级页表项的映射关系，那么就可以少创建一个二级页表。*（即理论上一级页表某项表明没有对应的二级页表项时，其二级页表就可以不用创建了。这样就可以省下部分创建页表的空间)*

多级页表同理，就是把原本的页表拆分成更多层次/级别。

```none
#下面都是打比方，位数什么的随便取的
#一级页表
[8位p|8位o] 8位标识页号,8位标识页内偏移

#二级页表
[4位p1|4位p2|8位o] 4位标识一级页表(一级页号-二级页号),4位标识二级页表(二级页号-页帧号)

#三级页表
[2位p1|3位p3|3位p3|8位o]
...
```

---

![img](https://img-blog.csdn.net/20180410004657551?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FsYXRlYmxvb21lcg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

![img](https://img-blog.csdn.net/20180410004741295?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FsYXRlYmxvb21lcg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

> [四、地址空间与内存分配](https://blog.csdn.net/Alatebloomer/article/details/79841088)

### 4.3.4 反向页表

> [反向页表--百度百科]([https://baike.baidu.com/item/%E5%8F%8D%E5%90%91%E9%A1%B5%E8%A1%A8/3565803?fr=aladdin](https://baike.baidu.com/item/反向页表/3565803?fr=aladdin))
>
> 反向页表（ inverted page table ）一般被视为使用正常的系统内存的TLB的片外扩展。与真正的页表不同，它不需要容纳目前所有的映射。
>
> 反向页表对于每个真正的内存页或帧才有一个条目。每个条目包含保存在真正内存位置的页的虚拟地址以及拥有该页的进程的信息。因此，整个系统只有一个页表，对每个物理内存的页只有一条相应的条目。因为系统只有一个页表，而有多个地址空间映射物理内存，所以反向页表的条目中通常需要一个地址空间标识符，以确保一个特定进程的一个逻辑页可以映射到相应的物理帧。
>
> [Linux 匿名页的反向映射](https://www.cnblogs.com/linhaostudy/p/10350326.html)

​	由于虚拟地址范围通常比物理地址范围大，比如64位操作系统，理论虚拟地址范围总大小可以达到2<sup>64</sup>Byte，就算4KB作为页大小，也大概需要5~6级页表才能表示所有的虚拟地址。

​	我们反过来项，不让页表与逻辑地址空间大大小相对应，而是让页表与物理地址空间大小项对应，那么页表就可以缩小好几个数量级。

​	即页表原本(key-页号，value-帧号)变成（key-帧号，value-页号），这就是反向页表了。

*(操作系统要是有使用反向页表机制，那大多也是采用传统页表为主，反向页表为辅的方式。)*

---

基于页寄存器（Page Register）的方案

*<small>（找不到图，就大致说说吧。自己OneNote是有图，但是毕竟不是图床，额。）</small>*

​	进程运行时，CPU像往常一样，需要翻译逻辑地址，才能再去请求获取内存中对应物理地址的数据。这时在页寄存器（Page Register）维护一张特殊的页表（key帧号，value页号），先从页寄存器搜寻看看能不能通过value虚拟地址页号找到对应的key帧号。由于使用帧号做索引，页表的大小就与虚拟地址范围无关，而与物理地址范围有关（更小，同时也没必要硬性要求页寄存器存有所有帧号-页号对应关系，起到缓存作用就好了）

​	使用页寄存器时，每个帧和一个寄存器关联，寄存器内容包括：

+ Residence bit：此帧是否被占用
+ Occupier：对应的页号p
+ Protection bits：保护位

​	举例：

+ 物理内存大小4096\*4096=4K\*4KB=16MB

+ 页面大小：4096bytes=4KB

+ 页帧数：4096=4K

+ 页寄存器使用的空间（假设 8byte/register）：

  8*4096=32KB

+ 页寄存器带来的额外开销：

  32K/16M=0.2%（大约）

+ 虚拟内存的大小：任意

明显，如果采用 帧-页对应关系，需要的页寄存器大小比传统页表小很多，但是需要考虑怎么通过这种数据结构快速地由value页号查找到对应的key帧号。

优点：

+ 转换表的大小相对物理内存来说很小
+ 转换表的大小跟逻辑地址空间的大小无关

缺点：

+ 需要的信息对调了，即根据帧号可找到页号（需要考虑如何加快索引，如何转换结果等，实现更加复杂）

---

基于关联内存（associative memory）的方案

与基于页寄存器的方案类似，不过是把存放反向页表的容器从页寄存器变成了关联内存。这个特殊的存储器也是在CPU内部的，同样不能做得太大，太大成本高+查询速度下降。

在反向页表中搜索一个页对应的帧号

+ 如果帧数较少，页寄存器可以被放置在关联内存中

+ 在关联内存中查找逻辑页号

  + 成功：帧号被提取
  + 失败：页错误异常（page fault）

+ 限制因素：

  大量的关联内存非常昂贵、难以在单个时钟周期内完成、耗电......

---

基于哈希（Hash）查找的方案

根据进程号PID和CPU获取到的虚拟地址页号p，经过特殊的函数`h(PID,p)`计算，得到key，在反向页表中再根据key查找对应的帧号f。

在反向页表中通过哈希算法来搜索一个页对应的帧号

+ 对页号做哈希计算，为了在"帧表"（每帧拥有一个表项）中获取对应的帧号。
+ 页i被放置在表中f(i)位置，其中f是设定的哈希函数
+ 为了查找页i，执行下列操作：
  + 计算哈希函数f(i)，并且使用它作为页寄存器表的索引
  + 获取对应的页寄存器
  + 检查寄存器标签是否包含i，如果包含，则代表成功
  + 否则失败

*<small>（Hash计算的反向表，也是根据物理地址范围大小决定表大小，与虚拟地址无关，这样表占用空间更小。但是这个表同样需要放在内存中，所以还需要配合TLB使用。再者，哈希函数的设计需要硬件集成，和软件系操作系统配合，而且需要考虑Hash碰撞的处理。现在有些高端CPU就有采用基于Hash查找的反向表，能提高CPU寻址的效率。）</small>*

![img](https://img-blog.csdn.net/20180410014023104?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FsYXRlYmxvb21lcg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

问题：

- 会有碰撞，多个逻辑地址对应一个值，加入参数PID==ID of running program来缓解冲突；
- 哈希表在内存中，要访问内存，内存的时间开销还是很大

优点：**本身物理存址小省空间，不再是每个应用程序都要page table了，整个系统只用一个**。 

缺点：需求高，有高效哈希函数和解决冲突的机制，要硬件软件配合，仍然需要TLB机制。

> [反向页表（基于hash表）](https://blog.csdn.net/qq_41841130/article/details/102995118)
>
> [四、地址空间与内存分配](https://blog.csdn.net/Alatebloomer/article/details/79841088)

# 5. 覆盖技术、交换技术、虚拟技术

## 5.0 引言

### 5.0.1 存储器层次结构

> [存储层次--百度百科]([https://baike.baidu.com/item/%E5%AD%98%E5%82%A8%E5%B1%82%E6%AC%A1/3923789?fr=aladdin](https://baike.baidu.com/item/存储层次/3923789?fr=aladdin))
>
> 存储层次是在[计算机体系结构](https://baike.baidu.com/item/计算机体系结构/10547223)下[存储系统](https://baike.baidu.com/item/存储系统/944115)层次结构的排列顺序。每一层于下一层相比都拥有较高的速度和较低延迟性，以及较小的容量。大部分现今的中央处理器的速度都非常的快。大部分程序工作量需要存储器访问。由于高速缓存的效率和存储器传输位于层次结构中的不同档次，所以实际上会限制处理的速度，导致中央处理器花费大量的时间等待存储器I/O完成工作。

理想中的存储器：更大、更快、更便宜的非易失性存储器。

实际中的存储器：

![img](https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1596513928144&di=a357db7d614359b30487ed1a3a90a7eb&imgtype=0&src=http%3A%2F%2Fpic3.zhimg.com%2F50%2Fv2-f32dcdf4aab4499994157642a25fbd30_hd.jpg)

![img](https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=4207278865,2453922396&fm=15&gp=0.jpg)

![img](https://img-blog.csdn.net/20180410095034672?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FsYXRlYmxvb21lcg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

> [五、虚拟内存](https://blog.csdn.net/Alatebloomer/article/details/79876498)

### 5.0.2 多道程序运行引起内存不足

​	早期计算机硬件发展不如现在，硬件贵又容量小。在个人电脑内存只有256MB的年代，计算机往往跑不了几个程序就内存不足了。为了解决多道程序运行引起的内存不足，有以下几种解决方案。

+ 如果是**程序太大**，超过了内存的容量，可以采用**手动的覆盖（overlay）技术**，只把需要的指令和数据保存在内存当中。
+ 如果是**程序太多**，超过了内存的容量，可以采用**自动的交换（swapping）技术**，把暂时不能执行的程序送到外存中。
+ 如果想要在有限容量的内存中，以<u>更小的页粒度</u>为单位装入更多更大的程序，可以采用**自动的虚拟存储技术**。

## 5.1 覆盖技术

### 5.1.1 覆盖技术的目标

​	目标即在较小的可用内存中运行较大的程序。常用于多道程序系统，与分许存储管理配合使用。

*（上世纪80-90年代的常见技术手段。当时代表性的操作系统是DOS操作系统，硬件内存只有640KB左右）*

### 5.1.2 覆盖技术的原理

​	原理，把程序按照其自身逻辑结构，**划分为若干个功能上相对独立的程序模块**，那些不会同时执行的模块共享同一块内存区域，按时间先后来运行。

+ 必要部分（常用功能）的代码和数据常驻内存
+ 可选部分（不常用功能）在其他程序模块中实现，平时存放在外存中，在需要用到时才装入内存
+ <u>不存在调用关系的模块不必同时装入到内存，从而可以相互覆盖，即这些模块共用一个分区</u>

---

思想:不相互调用的程序段可以共享同一内存区

例子：

设某进程的程序正文段由A，B，C，D，E和F等6个程序段组成.
由于程序段B不调用C，程序段C也不调用B，因此程序段B和C无需同时驻留在内存，它们可以共享同一内存区。
同理，程序段D、E、F也可共享同一内存区。

内存可以分为两个部分:

- 常驻内存区:常驻内存部分，与所有被调用程序段有关，不能被覆盖。这一部分称为根程序。图 (b)中，根程序是程序段A
- 覆盖区（这里B和C共用覆盖区0，D、E、F共用覆盖区1，按照不同时间顺序进入覆盖区即可）
  ![img](https://img2018.cnblogs.com/blog/1734701/201911/1734701-20191122163549323-1363685626.png)

覆盖区0由程序段B、C共享，容量50K。
覆盖区1为程序段F、D、E共享，容量40K。
进程正文段要求内存空间：
A(20K)+B(50K)+F(30K)+C(30K)+D(20K)+E(40K)=190K
采用覆盖技术，只需（常驻部分）20K+（覆盖区0）50K+（覆盖区1）40K=110K的内存空间即可开始执行。

另一种覆盖方案（100K）：A占一个分区20K；B、D和E共用一个分区50K；C和F共用一个分区30K。

> [存储管理-覆盖技术和交换技术](https://www.cnblogs.com/mengxiaoleng/p/11912571.html)  <small>上述样例部分来自该文章，为啥？因为没图床，哈哈。</small>

### 5.1.3 覆盖技术的优缺点

优点：在程序能够拆分成多个模块代码的前提下，能够减少进程占用的内存空间。

缺点：

+ 由程序员来把一个大的程序划分成若干个小的功能模块，并确定各个模块之间的覆盖关系，费时费力，增加了编程的复杂度。
+ 覆盖模块从外存装入内存，实际上是以时间延长来换取空间节省。

*（Turbo Pascal的Overlay系统单元支持程序员控制的覆盖技术）*

## 5.2 交换技术

### 5.2.1 交换技术的目标

目标，多道程序在内存中时，让正在运行的程序或需要运行的程序获得更多的内存资源。

### 5.2.2 交换技术的方法

方法：

+ 将暂时不能运行的程序送到外存，从而获得空闲内存空间。
+ 操作系统把一个**进程的整个地址空间**的内存保存到外存中（换出swap out），而将外存中的某个进程的地址空间读入到内存中（换入swap in）。换入换出内容的大小为整个程序的地址空间。

*（把暂时不运行的程序导出到硬盘，需要运行的程序从硬盘导入到内存。一般涉及的空间对应页表至少成百上千页。早期页大小通常定为4KB。）*

交换技术实现中的几个问题：

+ 交换时机的确定：何时需要发生交换？一般只当内存空间不够或有不够的危险时才换出。<small>*(毕竟硬盘和内存存取速度相差好几个量级，要是频繁交换，很影响操作系统整体的运行效率。)*</small>
+ 交换区的大小：必须足够大以存放所有用户进程的所有内存映像的拷贝；必须能对这些内存映像进行直接存取。*<small>（一来内存要本身至少够存放整个进程本身，二来换入到硬盘时要保证硬盘足够大。）</small>*
+ 程序换入时的重定位：换出后再换入的内存位置一定要在原本的位置上吗？最好采用<u>地址动态映射</u>的方法。*<small>（因为程序换出再换入，如果对应进程的页表不修改，要是进程这次换入的位置不同，将导致进程出错。所以需要地址动态映射，保证即时下次换入位置不同，也能正常进行虚拟地址-物理地址的转换。）</small>*

![img](https://img-blog.csdn.net/20180410102326240?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FsYXRlYmxvb21lcg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

> [动态地址映射--百度百科]([https://baike.baidu.com/item/%E5%8A%A8%E6%80%81%E5%9C%B0%E5%9D%80%E6%98%A0%E5%B0%84/6239909?fr=aladdin](https://baike.baidu.com/item/动态地址映射/6239909?fr=aladdin))
>
> 动态地址映射：在程序运行期间，随着每条指令和数据的访问自动地，连续的进行映射。
>
> [五、虚拟内存](https://blog.csdn.net/Alatebloomer/article/details/79876498)

### 5.2.3 交换技术与覆盖技术比较

+ 覆盖只能发生在那些<u>互相之间没有调用关系</u>的程序模块之间，因此程序员必须给出程序内的各个模块之间的逻辑覆盖结构。
+ 交换技术是以在内存中的程序大小为单位来进行的，它不需要程序员给出各个模块之间的逻辑覆盖结构。换言之，**交换发生在内存中程序与管理程序或操作系统之间，而覆盖则发生在运行程序内部**。

*（在内存连完整的单个程序都没有办法一次性加载时，就只能考虑用覆盖技术了，毕竟交换技术是一次加载整个程序的。）*

*<small>（交换，对于程序员来说工作量更轻，因为不用考虑内存到底是怎么分配的，交由管理程序或者操作系统去安排。）</small>*

*<small>（覆盖，需要程序员事先设计好内存覆盖的顺序和位置，虽然效率上比起交换可能好一些，因为只对个别部分进行覆盖，而交换直接整个程序空间进行交换，但是实现更加复杂。）</small>*

## 5.3 虚拟技术

### 5.3.1 虚拟技术的目标

> [虚拟内存--百度百科]([https://baike.baidu.com/item/%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98/101812?fr=aladdin](https://baike.baidu.com/item/虚拟内存/101812?fr=aladdin))
>
> 虚拟[内存](https://baike.baidu.com/item/内存)是[计算机系统](https://baike.baidu.com/item/计算机系统/7210959)[内存管理](https://baike.baidu.com/item/内存管理/5633616)的一种技术。它使得[应用程序](https://baike.baidu.com/item/应用程序/5985445)认为它拥有连续的可用的[内存](https://baike.baidu.com/item/内存/103614)（一个连续完整的[地址空间](https://baike.baidu.com/item/地址空间/1423980)），而实际上，它通常是被分隔成多个[物理内存](https://baike.baidu.com/item/物理内存/2502263)碎片，还有部分暂时存储在外部[磁盘存储器](https://baike.baidu.com/item/磁盘存储器/2386684)上，在需要时进行[数据交换](https://baike.baidu.com/item/数据交换/1586256)。目前，大多数[操作系统](https://baike.baidu.com/item/操作系统/192)都使用了虚拟内存，如Windows家族的“虚拟内存”；Linux的“交换空间”等。
>
> [内存管理--虚拟内存管理技术](https://www.cnblogs.com/Leo_wl/p/12781450.html)

+ 在内存不够用的情形下，可以采用覆盖技术和交换技术，但是：
  + 覆盖技术：需要程序员自己把整个程序划分成若干个小的功能模块，并确定各个模块之间的覆盖关系，增加了程序员的负担；
  + 交换技术：以进程为交换的单位，需要把进程的整个地址空间都换进换出，增加了处理器的开销。
+ "四海之内的"解决之道：虚拟内存管理技术——虚拟技术。

目标：

+ 像覆盖技术那样，不是把程序的所有内容都放在内存中，因而能够运行比当前的空闲内存空间还要大的程序。但做得更好，由操作系统自动来完成，无须程序员的干涉。
+ 像交换技术那样，能够实现进程在内存与外存之间的交换，因而获得更多的空闲内存空间。但做得更好，只对进程的部分内容在内存和外存之间进行交换。

Physical Memory + Disk = Virtual Memory

![img](https://img-blog.csdn.net/2018041010551261?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FsYXRlYmxvb21lcg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

虚拟存储器是由硬件和操作系统自动实现存储信息调度和管理的。它的工作过程包括6个步骤： 

①[中央处理器](https://baike.baidu.com/item/中央处理器)访问主存的逻辑地址分解成组号a和组内地址b，并对组号a进行地址变换，即将逻辑组号a作为索引，查地址变换表，以确定该组信息是否存放在主存内。 

②如该组号已在[主存](https://baike.baidu.com/item/主存)内，则转而执行④；如果该组号不在主存内，则检查主存中是否有空闲区，如果没有，便将某个暂时不用的组调出送往辅存，以便将这组信息调入主存。 

③从辅存读出所要的组，并送到主存空闲区，然后将那个空闲的物理组号a和逻辑组号a登录在地址变换表中。 

④从地址变换表读出与逻辑组号a对应的物理组号a。 

⑤从物理组号a和组内字节地址b得到物理地址。 

⑥根据物理地址从主存中存取必要的信息。

> [五、虚拟内存](https://blog.csdn.net/Alatebloomer/article/details/79876498)

### 5.3.2 程序的局部性原理

> [程序的局部性原理--百度百科]([https://baike.baidu.com/item/%E7%A8%8B%E5%BA%8F%E7%9A%84%E5%B1%80%E9%83%A8%E6%80%A7%E5%8E%9F%E7%90%86/8412331?fr=aladdin](https://baike.baidu.com/item/程序的局部性原理/8412331?fr=aladdin))
>
> 程序的局部性原理是指程序在执行时呈现出局部性规律，即在一段时间内，整个程序的执行仅限于程序中的某一部分。相应地，执行所访问的存储空间也局限于某个内存区域。局部性原理又表现为：时间局部性和空间局部性。时间局部性是指如果程序中的某条指令一旦执行，则不久之后该指令可能再次被执行；如果某数据被访问，则不久之后该数据可能再次被访问。空间局部性是指一旦程序访问了某个存储单元，则不久之后，其附近的存储单元也将被访问。

​	程序的局部性原理（principle of locality）：指程序在执行过程中的一个较短时期，所执行的指令地址和指令的操作数地址，分别局限于一定区域。这可以表现为：

+ 时间局部性：一条指令的一次执行和下次执行，一个数据的一次访问和下次访问都集中在一个较短时期内。
+ 空间局部性：当前指令和邻近的几条指令，当前访问的数据和邻近的几个数据都集中在一个较小区域内。

程序的局部性原理表明，从理论上来看，虚拟存储技术是能够实现的，而且在实现了以后，应该是能够取得一个满意的效果的。

---

程序的编写方法对缺页率的影响：

例子：也面大小为4KB，分配给每个进程的物理页面数为1。在一个进程中，定义了如下的二维数组`int A[1024][1024]`，该数组按行存放在内存，每一行放在一个页面中。

```c
// 程序编写方法1
for(j=0;j<1024;j++)
    for(i=0;i<1024;i++)
        A[i][j]=0;

// 程序编写方法2
for(i=0;i<1024;i++)
    for(j=0;j<1024;j++)
        A[i][j]=0;
```

由于前提假设数组按行存放在内存中，每一行放在一个页面中。（32位操作系统，int占4字节，1024个int正好占4096B，即4KB）

编写方法1，每次跨行访问，也正好是跨页访问，总共触发1024\*1024次中断。

编写方法2，只有外循环跨行（跨页），总共触发1024次中断。

（每次换行正好换页，为一次中断，内循环跨行1024次，外循环1024次，总1024\*1024次缺页中断，因为这里假设程序只占用一个物理页，每次跨页等于触发一次缺页中断）

### 5.3.3 虚拟技术的基本概念

> [虚拟内存--百度百科]([https://baike.baidu.com/item/%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98/101812?fr=aladdin](https://baike.baidu.com/item/虚拟内存/101812?fr=aladdin))

​	调度方式有分页式、段式、段页式3种。页式调度是将逻辑和物理地址空间都分成固定大小的页。主存按页顺序编号，而每个独立编址的程序空间有自己的页号顺序，通过调度辅存中程序的各页可以离散装入主存中不同的页面位置，并可据表一一对应检索。**页式调度的优点是页内零头小，页表对程序员来说是透明的，地址变换快，调入操作简单；缺点是各页不是程序的独立模块，不便于实现程序和数据的保护。段式调度是按程序的逻辑结构划分地址空间，段的长度是随意的，并且允许伸长，它的优点是消除了内存零头，易于实现存储保护，便于程序动态装配；缺点是调入操作复杂。**将这两种方法结合起来便构成段页式调度。**在段页式调度中把物理空间分成页，程序按模块分段，每个段再分成与物理空间页同样小的页面。**段页式调度综合了段式和页式的优点。其缺点是增加了硬件成本，软件也较复杂。<u>大型通用计算机系统多数采用段页式调度。</u> 

**页式调度**

在页式虚拟存储系统中，虚拟空间被分成大小相等的页，称为逻辑页或虚页。主存空间也被分成同样大小的页，称为物理页或实页。相应地，虚拟地址分为两个字段:高位字段为虚页号，低位字段为页内地址。实存地址也分为两个字段：高位字段为实页号，低位字段为页内地址。同时，页的大小都取2的整数幂个字。  

通过页表可以把虚拟地址转换成物理地址。每个程序设置一张页表，在页表中，对应每一个虚页号都有一个条目，条目内容至少包含该虚页所在的主存页面地址(实页号)，用它作为实存地址的高位字段;实页号与虚拟地址的页内地址相拼接，就产生完整的实存地址，据此访问主存。  

**段式调度**

页面是主存[物理空间](https://baike.baidu.com/item/物理空间/4804325)中划分出来的等长的固定区域。分页方式的优点是页长固定，因而便于构造[页表](https://baike.baidu.com/item/页表/679625)、易于管理，且不存在外碎片。但分页方式的缺点是页长与程序的逻辑大小不相关。例如，某个时刻一个子程序可能有一部分在主存中，另一部分则在辅存中。这不利于编程时的独立性，并给换入/换出处理、存储保护和存储共享等操作造成麻烦。 

另一种划分可寻址的存储空间的方法称为分段。段是按照程序的自然分界划分的、长度可以动态改变的区域。通常，程序员把[子程序](https://baike.baidu.com/item/子程序/3941697)、操作数和常数等不同类型的数据划分到不同的段中，并且每个程序可以有多个相同类型的段。 

在段式虚拟存储系统中，虚拟地址由段号和段内地址组成，虚拟地址到实存地址的变换通过段表来实现。每个程序设置一个段表，段表的每一个表项对应一个段，每个表项至少包括三个字段：有效位(指明该段是否已经调入主存)、段起址(该段在实存中的首地址)和[段长](https://baike.baidu.com/item/段长/5742657)(记录该段的实际长度)。 

**段页式调度**

段页式虚拟存储器是段式虚拟存储器和页式虚拟存储器的结合。 

首先，实存被等分成页。在段页式虚拟存储器中，把程序按逻辑结构分段以后，再把每段按照实存的页的大小分页，程序按页进行调入和调出操作，但它又可按段实现共享和保护。因此，它可以兼有页式和段式系统的优点。它的缺点是在地址映像过程中需要多次查表，虚拟地址转换成物理地址是通过一个段表和一组页表来进行定位的。段表中的每个表目对应一个段，每个表目有一个指向该段的页表的起始地址(页号)及该段的控制保护信页表指明该段各页在主存中的位置以及是否已装入、已修改等标志。 

---

虚拟技术，可以在页式、段式或者段页式也存管理的基础上实现

+ 在装入程序时，不必将其全部装入到内存，而只需将当前需要执行的部分页面或段装入到内存，就可让程序开始执行；
+ 在程序执行过程中，如果需执行的指令或访问的数据尚未在内存（称为缺页或却段），则由处理器通知操作系统将相应的页面调入到内存，然后继续执行程序。（也就是缺页中断，用户态转内核态）
+ 另一方面，操作系统将内存中暂时不使用的页面或段调出保存在外存（硬盘）上，从而腾出更多空闲空间存放将要装入的程序以及将要调入的页面或段。

### 5.3.4 虚拟技术的基本特征

+ 大的用户空间：通过把物理内存与外存相结合，提供给用户的虚拟内存空间通常大于实际的物理内存，即实现了两者的分离。如32位的虚拟地址理论上可以访问4GB，而可能计算机上仅有256MB的物理内存，但硬盘容量大于4GB。
+ 部分交换：与交换技术相比较，<u>虚拟存储的调入和调出是对部分虚拟地址空间进行的</u>。
+ 不连续性：物理内存分配的不连续，虚拟地址空间使用的不连续。

*<small>（进程中某些虚拟地址连续的部分由于不需要被执行，被暂时移出内存。这可能导致异常-缺页中断，倒是操作系统会自动处理异常，当被移出的页面又需要被使用时，会再重新加载到内存中。）</small>*

### 5.3.5 虚拟页式内存管理

> [内存管理--虚拟内存管理技术](https://www.cnblogs.com/Leo_wl/p/12781450.html)
>
> [虚拟内存设置多少比较合适？](https://www.zhihu.com/question/295194595?sort=created)
>
> 在物理内存+虚拟内存总大小不足50GB的情况下，为什么一次性申请50G不行，分批就可以呢？因为一次性申请50G，系统直接就能判定没有这么多。但是如果你分开使用，虽然我们每次都申请5G，但系统并没有真的给我们5G，只有在真的需要写入的时候，才会真的让这5G对应物理地址。<small>（也就是只申请但是没有进行写操作，就不会实际分配物理地址，挺多就是虚拟地址标记50GB空间--我估计也不会真的对应50GB空间的页表每页都标记，操作系统应该能更智能地标记这种只申请却不用的空间分配。）</small>
>
> 在物理内存和虚拟内存都将超额的情况下，继续申请并写入数据，不同的系统会有不同的应对方式。常见的应对方式即操作系统OS触发OOM killer，杀死系统认为大量浪费占用内存的进程，以维持系统的正常运行。

![内核空间用户空间全图](https://user-gold-cdn.xitu.io/2020/4/20/17195b7a9b3cf2c2?w=1019&h=414&f=png&s=56870)

+ 大部分虚拟存储系统都采用虚拟页式存储管理技术，即在页式存储管理的基础上，增加**请求调页**和**页面置换**功能。
+ 基本思路：
  + 当一个用户程序要调入内存运行时，不是将程序的所有页面都装入内存，而是只装入部分的页面，就可以启动程序运行。
  + 在运行的过程中，如果发现要运行的程序或要访问数据不在内存，则向系统发出**缺页中断**请求，系统在处理这个中断时，将外存中相应的页面调入内存，使得该程序能够继续运行。

页表表项：

```none
[逻辑页号i][访问位][修改位][保护位][驻留位][物理页帧号]
```

+ 驻留位：表示该页是在内存还是在外存。如果该位等于1，表示该页位于内存当中，即该页表项是有效的，可以使用；如果该位等于0，表示该页当前还在外存当中，如果访问该页表项，将导致缺页中断；
+ 保护位：表示允许对该页做何种类型的访问，如只读、可读写、可执行等；
+ 修改位：表示此页在内存中是否被修改过。当系统回收该物理页面时，根据此位来决定是否把它的内存写回内存；
+ 访问位：如果该页面被访问过（包括读操作或写操作），则设置此位。用于页面置换算法。

<small>*（保护位，假如设置成不可执行，但是程序要求在该页进行执行操作，就会抛异常）*</small>

*<small>（修改位，如果这个页在内存中被修改过就是1，这样下次如果要置换该页的内存，就需要把这个页数据覆写到外存。如果0，那么直接释放，不需要把也数据覆写到外存。很明显如果修改位1的页被置换出来，费时又费力。）</small>*

*<small>（访问位，虚拟内存页式管理，在物理内存不够用时，尽量挑选没被访问过的页置换出去，猜测之前没用到的数据之后也不需要。）</small>*

![img](https://img-blog.csdn.net/20180410124345656?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FsYXRlYmxvb21lcg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

![img](https://img-blog.csdn.net/20180410123314860?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FsYXRlYmxvb21lcg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

> [五、虚拟内存](https://blog.csdn.net/Alatebloomer/article/details/79876498)

### 5.3.6 缺页中断

> [缺页中断]([https://baike.baidu.com/item/%E7%BC%BA%E9%A1%B5%E4%B8%AD%E6%96%AD/5029040?fr=aladdin](https://baike.baidu.com/item/缺页中断/5029040?fr=aladdin))
>
> 缺页中断就是要访问的页不在主存，需要操作系统将其调入主存后再进行访问。在这个时候，被内存[映射](https://baike.baidu.com/item/映射)的文件实际上成了一个分页交换文件。
>
> **页缺失**（英语：Page fault，又名**硬错误**、**硬中断**、**分页错误**、**寻页缺失**、**缺页中断**、**页故障**等）指的是当软件试图访问已映射在[虚拟](https://baike.baidu.com/item/虚拟)[地址空间](https://baike.baidu.com/item/地址空间)中，但是并未被加载在[物理内存](https://baike.baidu.com/item/物理内存)中的一个[分页](https://baike.baidu.com/item/分页)时，由[中央处理器](https://baike.baidu.com/item/中央处理器)的内存管理单元所发出的[中断](https://baike.baidu.com/item/中断)。
>
> 通常情况下，用于处理此中断的程序是[操作系统](https://baike.baidu.com/item/操作系统)的一部分。如果操作系统判断此次访问是有效的，那么操作系统会尝试将相关的分页从硬盘上的[虚拟内存](https://baike.baidu.com/item/虚拟内存)文件中调入内存。而如果访问是不被允许的，那么操作系统通常会结束相关的[进程](https://baike.baidu.com/item/进程)。

缺页中断分类：

1. 软性

   ​	**软性页缺失**指页缺失发生时，相关的页已经被加载进内存，但是没有向MMU注册的情况。操作系统只需要在MMU中注册相关页对应的物理地址即可。

   ​	发生这种情况的可能性之一，是一块物理内存被两个或多个程序[共享](https://baike.baidu.com/item/共享)，操作系统已经为其中的一个装载并注册了相应的页，但是没有为另一个程序注册。

   ​	可能性之二，是该页已被从CPU的[工作集](https://baike.baidu.com/item/工作集)中移除，但是尚未被交换到[磁盘](https://baike.baidu.com/item/磁盘)上。比如[OpenVMS](https://baike.baidu.com/item/OpenVMS)这样的使用次级页缓存的系统，就有可能会在工作集过大的情况下，将某页从工作集中去除，但是不写入硬盘也不擦除（比如说这一页被读出硬盘后没被修改过），只是放入空闲页表。除非有其他程序需要，导致这一页被分配出去了，不然这一页的内容不会被修改。当原程序再次需要该页内的数据时，如果这一页确实没有被分配出去，那么系统只需要重新为该页在MMU内注册映射即可。

2. 硬性

   ​	与软性页缺失相反，**硬性页缺失**是指相关的页在页缺失发生时未被加载进内存的情况。这时操作系统需要：

   1. 寻找到一个空闲的页。或者把另外一个使用中的页写到磁盘上（如果其在最后一次写入后发生了变化的话），并注销在MMU内的记录
   2. 将数据读入被选定的页
   3. 向MMU注册该页

   ​	硬性页缺失导致的性能损失是很大的。以一块7200[rpm](https://baike.baidu.com/item/rpm)的主流[机械硬盘](https://baike.baidu.com/item/机械硬盘)为例，其平均寻道时间为8.5毫秒，读入内存需要0.05毫秒。相对的，[DDR3内存](https://baike.baidu.com/item/DDR3内存)的访问延迟通常在数十到100纳秒之间，性能差距可能会达到8万到22万倍。

   ​	另外，有些操作系统会将程序的一部分延迟到需要使用的时候再加载入内存执行，以此来提升性能。这一特性也是通过捕获硬性页缺失达到的。

   当硬性页缺失过于频繁的发生时，称发生系统颠簸。

3. 无效

   ​	当程序访问的虚拟地址是不存在于虚拟地址空间内的时候，则发生**无效页缺失**。一般来说这是个软件问题，但是也不排除硬件可能，比如因为内存故障而损坏了一个正确的[指针](https://baike.baidu.com/item/指针)。

   ​	具体动作与所使用的操作系统有关，比如Windows会使用[异常](https://baike.baidu.com/item/异常)机制向程序报告，而[类Unix系统](https://baike.baidu.com/item/类Unix系统)则会使用[信号](https://baike.baidu.com/item/信号)机制。如果程序未处理相关问题，那么操作系统会执行默认处理方式，通常是转储内存、终止相关的程序，然后向用户报告。

---

缺页中断发生时的事件顺序如下：

1) 硬件陷入内核，在内核[堆栈](https://baike.baidu.com/item/堆栈)中保存[程序计数器](https://baike.baidu.com/item/程序计数器)。大多数机器将当前指令的各种状态信息保存在特殊的CPU[寄存器](https://baike.baidu.com/item/寄存器)中。

2) 启动一个汇编代码例程保存[通用寄存器](https://baike.baidu.com/item/通用寄存器)和其他易失的信息，以免被操作系统破坏。这个例程将操作系统作为一个函数来调用。

3) 当操作系统发现一个缺页中断时，尝试发现需要哪个虚拟页面。通常一个硬件寄存器包含了这一信息，如果没有的话，操作系统必须检索程序计数器，取出这条指令，用软件分析这条指令，看看它在缺页中断时正在做什么。

4) 一旦知道了发生缺页中断的[虚拟地址](https://baike.baidu.com/item/虚拟地址)，操作系统检查这个地址是否有效，并检查存取与保护是否一致。如果不一致，向进程发出一个信号或杀掉该进程。如果地址有效且没有保护错误发生，系统则检查是否有空闲[页框](https://baike.baidu.com/item/页框)。如果没有空闲页框，执行[页面置换算法](https://baike.baidu.com/item/页面置换算法)寻找一个页面来淘汰。

5) 如果选择的页框“脏”了，安排该页写回磁盘，并发生一次[上下文切换](https://baike.baidu.com/item/上下文切换)，挂起产生缺页中断的进程，让其他进程运行直至磁盘传输结束。无论如何，该页框被标记为忙，以免因为其他原因而被其他进程占用。

6) 一旦页框“干净”后（无论是立刻还是在写回磁盘后），操作系统查找所需页面在磁盘上的地址，通过磁盘操作将其装入。该页面被装入后，产生缺页中断的进程仍然被挂起，并且如果有其他可运行的用户进程，则选择另一个用户进程运行。

7) 当磁盘中断发生时，表明该页已经被装入，[页表](https://baike.baidu.com/item/页表)已经更新可以反映它的位置，[页框](https://baike.baidu.com/item/页框)也被标记为正常状态。

8) 恢复发生缺页[中断指令](https://baike.baidu.com/item/中断指令)以前的状态，[程序计数器](https://baike.baidu.com/item/程序计数器)重新指向这条指令。

9) 调度引发缺页中断的进程，操作系统返回调用它的汇编语言例程。

10) 该例程恢复寄存器和其他状态信息

![img](https://img-blog.csdn.net/20180410125645119?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FsYXRlYmxvb21lcg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

![img](https://img-blog.csdn.net/2018041013120418?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FsYXRlYmxvb21lcg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

> [五、虚拟内存](https://blog.csdn.net/Alatebloomer/article/details/79876498)

### 5.3.7 后备存储

在何处保存未被映射的页？

+ 能够简单地识别在二级存储器中的页
+ 交换空间（磁盘或者文件）：特殊格式，用于存储未被映射的页面

概念：后备存储backing store

+ 一个虚拟地址空间的页面可以被映射到一个文件(在二级存储）中的某个位置*（windows保存到文件[pagefile.sys](https://baike.baidu.com/item/PageFile.Sys) 中）*
+ 代码段：映射到可执行二进制文件
+ 动态加载的共享库程序段：映射到动态调用的库文件
+ 其他段：可能被映射到交换文件（swap file）

### 5.3.8 虚拟内存性能

为了方便理解分页的开销，使用有效存储器访问时间effective memory access time（EAT）。
$$
EAT=访问时间*页表命中几率+page fault处理时间*page fault几率
$$
举例：

访问时间：10ns；	磁盘访问时间：5ms；

参数p = page fault几率；	参数q = dirty page几率；

EAT = 10 \* （1-p) + 5000000p(1+q)

*(这里q，是置换页面的时候，被置换的页面可能修改位是1，那么置换出去还需要覆写外存，消耗额外的时间)*

*（明显，p越小，也就是页表命中率越高的话，缺页中断出现越少。而一般程序也经常是一个页4KB的数据访问几百次，然后才会触发一次缺页中断。减少缺页中断损耗的时间，程序执行的效率也就间接提高了。）*

![img](https://img-blog.csdn.net/20180410132934394?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FsYXRlYmxvb21lcg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

> [五、虚拟内存](https://blog.csdn.net/Alatebloomer/article/details/79876498)

# 6. 页面置换算法

## 6.0 概述

### 6.0.1 功能与目标

功能：当缺页中断发生，需要调入新的页面而内存已满时，根据特定算法选择内存当中某个物理页面置换。

目标：**尽可能地减少**页面地换进换出次数（即缺页中断的次数）。具体来说，把未来不再使用的或短期内较少使用的页面换出，通常只能在局部性原理指导下依据过去的统计数据来进行预测。

**页面锁定**（frame locking）：用于描述必须常驻内存的操作系统的关键部分或时间关键（time-critical）的应用进程。实现的方法是：在页表中添加锁定标志位（lock bit）。

*（有些特殊的代码段，比如操作系统的代码段，需要一直存在于内存中，才能正常运行操作系统。这时候，就可以给操作系统使用的代码段所在的页面添加标志位lock bit，这样页表含有lock bit的页就不会参与页面置换算法，直接被忽略。）*

*由于访问同一页必定不会产生缺页中断，所以考虑缺页中断和页面置换的情况时，无需关心页内偏移量。只考虑页号。*

> [操作系统课本里面说页表项占用一个字节是怎么来的？](https://www.v2ex.com/t/309437)
>
> 在 32 位 Linux 中，一个页是 4K（ 12 位地址空间），剩下的 20 位地址空间被二级页表索引，每一级负责 10 位。
>
> 但是页表项除了地址还要存其他很多信息，比如页的访问权限之类的。所以每一个页表项依旧需要 4 个字节。
>
> 那么问题就明朗了，一级页表 1024 项（ 10 位地址空间嘛），每个项目 4 字节正好 4K （一页）。二级页表项也是 1024 项，每个项目依旧 4 字节正好 4K 。最后形成的两级页表体系一共能表示 20 位地址空间，补上 12 位页内地址空间正好 32 位。
>
> 需要说明的是二级页表只对 32 位系统有效， 64 位就是其他的做法了。

### 6.0.2 常见算法

**局部页面置换算法**：

+ 最优页面置换算法（OPT，optimal）
+ 先进先出算法（FIFO）
+ 最近最久未使用算法（LRU，Least Recently Used）
+ 时钟页面置换算法（Clock）
+ 二次机会法（或者enhanced clock）
+ 最不常用算法（LFU，Least Frequently Used）

**全局页面置换算法**

+ 工作集页置换算法
+ 缺页率置换算法

局部页面置换算法，目的是减小**单进程**的缺页中断次数。

全局页面置换算法，目的是减少**操作系统系统整体**出现的缺页中断次数。

## 6.1 局部页面置换算法

### 6.1.1 最优页面置换算法(OPT，optimal)

基本思路：

​	当一个缺页中断发生时，对于保存在内存当中的每一个<u>逻辑页面</u>，计算在它下一次访问之前，还需等待多长时间，从中选择等待时间最长的那个，作为被置换的页面。

这只是一种理想情况，在实际系统中是无法实现的，因为操作系统无法知道每一个页面要等待多长时间以后才会再次被访问。

最优页面置换算法，可用作其他算法的性能评价的依据<small>（在一个模拟器上运行某个程序，并记录每一次的页面访问情况，在第二遍运行时即可使用最优算法）</small>。

![img](https://img-blog.csdn.net/20180417162011992?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FsYXRlYmxvb21lcg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

> [六、页面置换算法](https://blog.csdn.net/Alatebloomer/article/details/79976068)

### 6.1.2 先进先出算法（FIFO)

基本思路：

​	选择在内存中驻留时间最长的页面并淘汰。具体来说：操作系统维护着一个链表，其记录了所有内存当中的<u>逻辑页面</u>。从链表的排序顺序来看，链首页面的驻留时间最长，链尾页面的驻留时间最短。当发生一个页面中断时，把链首页面淘汰出局，把新的页面添加到链表的末尾。 

**性能较差**，调出的页面可能是经常要访问的页面，并且有**Belady现象**，FIFO算法很少单独使用。 

*（理论上，给的物理页总量越多，那么产生的缺页中断次数应该越少。而采用FIFO的页置换算法时，同种访问页表项的顺序下，加大物理页总量，有时反而出现缺页中断次数增多的现象。这就是Belady现象，只有FIFO算法会有该现象。）*

![img](https://img-blog.csdn.net/2018041716313855?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FsYXRlYmxvb21lcg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

> [六、页面置换算法](https://blog.csdn.net/Alatebloomer/article/details/79976068)

### 6.1.3 最近最久未使用算法（LRU，Least Recently Used）

基本思路：

​	当一个缺页中断发生时，选择最久未使用的那个页面，并淘汰。

它是最优置换算法的近似，其根据程序的局部性原理，即在最近一小段时间（最近几条指令）内，如果某些页面被频繁访问，那么在将来的一小段时间内，它们还可能会再被频繁访问。反过来说，过去某些页面长时间未被访问，那么它们将来还可能长时间地得不到访问。

*（最优置换算法OPT根据未来推测未来，所以肯定最优，但是不现实。而LRU算法，根据过去推测未来，假定过去不常被访问的页面将来也可能不会再被访问。在OS长期工作下，LRU效益可近似OPT。）*

![img](https://img-blog.csdn.net/20180417165641987?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FsYXRlYmxvb21lcg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

<u>LRU算法需要记录各个页面使用时间的先后顺序，开销比较大</u>。两种常见的实现方法是：

- 系统维护一个页面链表。

  ​	最近刚使用过的页面作为首结点，最久未使用的页面作为尾结点，每一次访问内存时，找到相应的页面，把它从链表中摘下来，再移动到链表之首。每次缺页中断发生时，淘汰链表末尾的页面。

- 设置一个活动页面堆栈。

  ​	当访问某页时，将此页号入栈顶，然后，考察栈内是否有与此页面相同的页号，若有则抽出。当需要淘汰一个页面时，总是选择栈底的页面，它就是最久未使用的。

![img](https://img-blog.csdn.net/20180417165714990?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FsYXRlYmxvb21lcg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

> [六、页面置换算法](https://blog.csdn.net/Alatebloomer/article/details/79976068)

### 6.1.4 时钟页面置换算法(Clock)

 Clock 页面置换算法，LRU的近似，对FIFO的一种改进： 

基本思路：

+ 需要用到页表项当中的访问位，当一个页面被装入内存时，把该位初始化为0。然后如果这个页被访问（读/写）时，则把它置为1。（硬件完成访问位置1的操作,无需软件实现）

- 把各个页面组织成环形链表（类似钟表面），把指针指向最老的页面（最先进来）。
- 当发生一个缺页中断，考察指针所指向的最老的页面，若它的访问为为0，则立即淘汰；若访问位为1，则把该位置为0，然后指针往下移动一格。如此下去，直到找到被淘汰的页面，然后把指针移动到它的下一格。

*（Clock算法比起LRU而言，判断最老页面不够精确，因为系统也会周期性把所有页的访问位置0，以避免死锁。而且CLock算法的环形队列判断访问位0再置换，并不一定置换的就是最老页面。相对LRU更粗糙，但是不需要维护LRU需求的复杂数据结构和计算，实现较简单。）*

![img](https://img-blog.csdn.net/20180417172110816?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FsYXRlYmxvb21lcg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

Clock算法，维持一个环形页面链表保存在内存中

+ 用一个时钟（或者使用/引用）位来标记一个页面是否经常被访问
+ 当一个页面被引用时，这个位被设置（为1）

时钟头扫描页面寻找一个带有`used bit=0`，将其替换出来。（替换在一个周期内没有被引用过的页面）

```pascal
func Clock_Replacement
begin
while (victim page not found) do
	if (used bit for current page = 0) do
		replace current page(& set used bit to 1)
	else
		reset used bit(to 0)
	end if 
	advance clock pointer
end while
end Clock_Replacement
```

![img](https://img-blog.csdn.net/2018041717255663?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FsYXRlYmxvb21lcg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

*<small>（虽然这个模拟场景比前面LRU算法多了一次缺页中断，但是实际应用中，Clock算法效益接近LRU。而且Clock算法只用一个`used bit`，相对LRU需要维护链表or栈要更简单且开销小。）</small>*

> [六、页面置换算法](https://blog.csdn.net/Alatebloomer/article/details/79976068)

### 6.1.5 二次机会法（或者enhanced clock）

​	由于Clock算法，只考虑页是否被访问，没考虑页是否被修改，这可能导致被换出的页经常是被"写"过的，这样内存置换该页时，还需要覆写一遍数据到外存（硬盘）中，需要额外消耗时间。

​	于是出现了在Clock算法基础上改进的，二次机会法。其同时用**脏位**`dirty bit`和**使用位**`used bit`来指导置换，允许脏页总是在一次时钟头扫描中保留下来。
*(尽量优先置换未被访问且未被执行写操作的页。脏页需要时钟头扫描两次才可能被置换，所以该算法被称作二次机会法)*

![img](https://img-blog.csdn.net/20180417201216650?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FsYXRlYmxvb21lcg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

+ `dirty bit`，标记1说明该页需进行写操作，0说明没有进行写操作。和`used bit`一样都是硬件修改数值，无需操作系统干预。
+ `used bit`只能看出来该页是否被访问过，不管页是用来读还是写，都是1。

这里指针每次转动时，会把`used bit`和`dirty bit`同时值为1以外的都置为双0，只有双1变成0 1。也就是访问过且被修改过的脏页，会在内存中多一次存活的机会。

*毕竟修改过的页，要置换出去之前，还需要先覆写内存数据到硬盘原本的物理位置，这需要消耗大量时间，所以二次机会法力求尽量置换没用过或者只读的内存页面。*

![img](https://img-blog.csdn.net/20180417203910279?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FsYXRlYmxvb21lcg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

*w表示访问内存页，且需要进行写操作，即`dirty bit = 1`*。

这个二次机会法的样例里，和前面LRU一样是3次缺页中断。和Clock算法一样，二次机会法在实际应用中效果近似LRU算法。并且二次机会法区分读/写情况，尽量置换只读页，减少内存覆写硬盘的开销。

> [六、页面置换算法](https://blog.csdn.net/Alatebloomer/article/details/79976068)

### 6.1.6 最不常用算法(LFU，Least Frequently Used)

- 基本思路：当一个缺页中断发生时，选择访问次数最少的那个页面，并淘汰。
- 实现方法：对每个页面设置一个访问计数器，每当一个页面被访问时，该页面的访问计数器加1。在发生缺页中断时，淘汰计数值最小的那个页面。
- LRU/LFU区别：LRU考察的是多久未访问，时间越短越好；而LFU考察的是访问次数或频度，访问次数越多越好。 

LFU算法可能存在的某类问题：一个页面在进程开始时使用的次数很多，但是以后就再也不用了，如果计数器保持数值不变，那么这个页可能直到进程结束前都不会被释放。（解决方法：定期把次数寄存器右移以一位。）

*（LRU是最近没被使用，LFU是最近使用最少次，两者实现的开销都相对较大。LRU需要借助链表or栈等数据结构；而LFU需要给每个页表另外配置访问计数器，那么硬件上可能需要额外的寄存器等，开销大。）*

*（所以如果要综合考虑成本和效率去使用LFU，不能简单考虑硬件层面添加寄存器等设备。最好能找到类似Clock这类折中且效率近似LRU的实现方式。）*

### 6.1.7 Belady现象

> [belady现象--百度百科]([https://baike.baidu.com/item/belady%E7%8E%B0%E8%B1%A1/7635569?fr=aladdin](https://baike.baidu.com/item/belady现象/7635569?fr=aladdin))
>
> 所谓Belady现象是指：在分页式虚拟存储器管理中，发生缺页时的置换算法采用FIFO（[先进先出](https://baike.baidu.com/item/先进先出/9629304)）算法时，如果对一个进程未分配它所要求的全部页面，有时就会出现分配的页面数增多但缺页率反而提高的异常现象。

- Belady现象：在采用FIFO算法时，有时会出现分配的物理页面数增加，缺页率反而提高的异常现象。
- 出现Belady现象的原因：FIFO算法的置换特征与进程访问内存的动态特征是矛盾的，与置换算法的目标是不一致的（即替换较少使用的页面），因此，被它置换出去的页面不一定是进程不会访问的。

### 6.1.8 LRU、FIFO和Clock的比较

- LRU算法和FIFO本质都是先进先出的思路，只不过LRU是针对**页面的最近访问时间**来进行排序，所以需要在每一次页面访问的时候动态地调整各个页面之间的先后顺序（每一个页面的最近访问时间变了）；而FIFO是针对**页面进入内存的时间**来进行排序，这个时间是固定不变的，所以各页面之间的先后顺序是固定的。如果一个页面在进入内存后没有被访问，那么它的最近访问时间就是它进入内存的时间。换句话说，如果内存当中的所有页面都未曾被访问过，那么LRU算法就会退化为FIFO算法。

  例如：给进程分配3个物理页面，逻辑页面的访问顺序为1、2、3、4、5、6、1、2、3......

- LRU算法性能较好，但系统开销较大；FIFO算法的系统的开销较小，但可能发生Belady现象。因此，折中的办法就是Clock算法，在每一次页面访问时，它不必去动态调整页面在链表中的顺序，而仅仅是做一个标记，然后等到发生缺页中断的时候，再把它移动到链表的末尾。对于内存当中那些未被访问的页面，Clock算法的表现与LRU算法一样好；而对于那些曾经访问过的页面，它不能像LRU那样，记住它们的准确位置（访问顺序）。

*（Clock和基于Clock改进的二次机会法，本身都是通过1~2bit标志位，来近似模拟LRU算法。如果我们的程序本身不符合局部性原则，那么LRU算法实际的效果会退化成FIFO。同理，近似Clock和二次机会法也有可能退化成FIFO。所以我们程序开发本身需要考虑局部性原则，这样才能充分发挥页面置换算法的作用。）*

## 6.2 全局页面置换算法

### 6.2.0 概述

全局页面置换算法置换页面的选择范围是所有可换出的物理页面

全局置换需要解决的问题：

- 进程在不同阶段的内存需求是变化的
- 分配给进程的内存也需要在不同阶段有所变化
- 全局置换算法需要确定分配给进程的物理页面数

> [六、页面置换算法](https://blog.csdn.net/Alatebloomer/article/details/79976068)

### 6.2.1 工作集和常驻集

1. **工作集**

   前面介绍的各种页面置换算法都是基于一个前提，即程序的局部性原理。但是此原理是否成立？

   + 如果局部性原理不成立，那么各种页面算法都没有什么区别，也就没什么意义。例如：假设进程对逻辑页面的访问顺序是1、2、3、4、5···，即单调递增，那么在**物理页面**数有限的前提下，不管采用何种页面置换算法，每次的页面访问都必然导致缺页中断。 

   + 如果局部性原理是成立的，那么如何证明它的存在，如何对它进行定量分析？这就是工作集模型！

   工作集：一个进程当前使用的**逻辑页面集合** ，可以用一个二元函数`W(t,Δ)`表示。

   + `t`是当前的执行时刻；

   + `Δ`称为工作集窗口 （working-set window），即一个定长的页面访问的时间窗口；

   + `W(t,Δ)`表示在当前时刻t之前的Δ时间窗口当中的所有访问页面组成的集合（随着t的变化，该集合也在不断地变化）；

   + `| W(t,Δ)|`指工作集的大小，即页面数目。

   ![img](https://img-blog.csdn.net/20180418094046133?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FsYXRlYmxvb21lcg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

   工作集大小的变化：进程开始执行后，随着访问新页面逐步建立较稳定的工作集。当内存访问的局部性区域的位置大致稳定时，工作集大小也大致稳定；局部性区域的位置改变时，工作集快速扩张和收缩过渡到下一个稳定值。

   ![img](https://img-blog.csdn.net/20180418094502895?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FsYXRlYmxvb21lcg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

2. **常驻集**

   常驻集是指在当前时刻，**进程实际驻留在内存当中的页面集合**。

   - 工作集是进程在运行过程中固有性质。而常驻集取决于系统分配给进程的物理页面数目，以及所采用的页面置换算法；
   - 如果一个进程的整个工作集在内存当中，即工作集⊆（=）常驻集,那么进程将很顺利地运行,而不会造成太多的缺页中断(直到工作集发生剧烈变动，从而过渡到另一状态)；
   - 当进程常驻集的大小达到某个数目之后，再分配更多的物理页面，缺页率也不会明显下降。

常驻集和工作集很好理解。比如某程序占用硬盘页A~Z，但是操作系统只先把程序A~G部分放入内存(因为还有其他程序要用内存,所以不能给这个程序一下子分配A~Z那么多页的物理内存空间)，这个A~G大小就是常驻集，常驻集就是{A~G}；而工作集，和程序执行有关，是实时变动的，比如A~Z内，某时间段内工作集{A~C}，也就是只有A~C的代码被执行了，D-G还没有被执行，但是也在内存中待命就是了。

这种常驻集没有和程序等大的，肯定会有缺页中断发生。比如A~G先加载到页表，A-G每个页面都要至少中断一次(从硬盘加载到内存）。之后A~G代码可能还要调用H~Z范围的代码，那就又需要把H~Z的从物理硬盘加载某几页到内存，内存需要置换出来一些（置换方式,看具体什么算法。）

> [六、页面置换算法](https://blog.csdn.net/Alatebloomer/article/details/79976068)

### 6.2.2 工作集页置换算法

- 思路：置换出不在工作集中的页面
- 当前时刻前`τ`个内存访问的页引用是工作集，`τ`被称为窗口大小
- 实现方法：维护窗口内的访存页面链表，访存时，换出不在工作集的页面；更新访存链表。缺页时，换入页面；更新访存链表。

![img](https://img-blog.csdn.net/20180418101003790?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FsYXRlYmxvb21lcg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

这个样例中，假设工作集窗口大小为4，然后程序分配到的物理帧共5页（内存中加载 常驻集a~e）

这里置换判断依据是"页面是否在工作集窗口范围内"，所以当`Time=2`时，虽然Page e没有引发缺页中断，我们也主动把它置换出去。（内存给我们这个进程5个物理页大小的空间，正好只加载程序的a~e这5页的内容，剩余的还没加载）

工作集算法，从整个系统层面思考缺页中断处理，对于每个进程，都采取尽早把无用内容（不在工作集窗口内的页面）置换出去的策略，使得别的程序更能有机会获取到足够大的物理空间。其避免产生某些程序占用很多无用页帧而引起其他程序被迫频繁缺页中断的现象。

*<small>（有点TCP中的流量控制和拥塞避免的感觉了，流量控制针对通信双方而言，而拥塞避免针对所有TCP通信用户。）</small>*

> [六、页面置换算法](https://blog.csdn.net/Alatebloomer/article/details/79976068)

### 6.2.3 缺页率置换算法

**可变分配策略**：常驻集大小可变 。例如：每个进程在刚开始运行的时候，根据程序的大小给它分配一定数目的物理页面，然后在进程运行过程中，再动态地调整常驻集的大小。

- 可采用**全局页面置换**的方式，当发生一个缺页中断时，被置换的页面可以是在其他进程当中，各个并发进程竞争地使用物理页面。
- 优缺点：性能较好，但增加了系统开销。
- 具体实现：可以使用**缺页率置换算法**（PFF, page fault frequency）来动态调整常驻集的大小。

**缺页率**

缺页率表示"缺页次数/ 内存访问次数"（比率）或"缺页的平均时间间隔的倒数"。

影响缺页率的因素：

- 页面置换算法<small>（每个页面置换算法在不同页面使用情况下缺页率不尽相同）</small>
- 分配给进程的物理页面数目<small>（除了FIFO可能产生Belady异常现象，其他页面置换算法，一般程序分配到的物理页面越多，缺页率越小。）</small>
- 页面本身的大小<small>（比如一个页大小从4KB改成4MB，那么一般缺页率也会更小。毕竟一页能够加载原本的1024倍大小的内容）</small>
- 编程方法<small>（一般而言，程序编写越符合时间和空间局部性，那么出现缺页的概率越低。）</small>

若运行的程序缺页率过高，则通过增加工作集来驻集来分配更多的物理页面；

若运行的程序缺页率过低，则通过减少工作集以减少它的物理页面数。

力图使每个运行中的程序的缺页率保持在一个合理的范围内。

![img](https://img-blog.csdn.net/20180418102536991?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FsYXRlYmxvb21lcg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

实现：

- 访存时，设置引用位标志
- 缺页时，计算从上次缺页时间tlast到现在tcurrent的时间间隔

1. 如果tcurrent– tlast>T,则置换所有在[tlast, tcurrent]时间内没有被引用的页
2. 如果tcurrent – tlast≤ T, 则增加缺失页到工作集中

![img](https://img-blog.csdn.net/20180418103854147?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FsYXRlYmxvb21lcg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

​	工作集置换算法每次Time变动都要检查窗口内的页是否需要置换，而缺页率置换算法只在发生缺页中断时才进行页置换操作。

​	相对局部页面置换算法（FIFO、LRU、LFU、Clock、二次机会法）等，工作集置换算法和缺页率置换算法，这两种全局置换算法针对的是整个操作系统的程序缺页中断的控制，而不是针对某一个进程的缺页中断处理。对于多道程序运行的操作系统来说，全局置换算法是必备品。<small>（操作系统的实际实现肯定没有像这几个描述的那么简单，但是大致的思想都有提到）</small>

> [六、页面置换算法](https://blog.csdn.net/Alatebloomer/article/details/79976068)

### 6.2.4 抖动问题

- 如果**分配给一个进程的物理页面太少**，不能包含整个工作集，即常驻集∈工作集，进程会造成很多的缺页中断，需要频繁地在内存和外存之间替换页面，从而使进程的运行速度变慢，我们把这种状态称为”抖动”。 
- 产生抖动的原因：随着驻留内存的进程数目增加，分配给每个进程的物理页面数不断减少，缺页率不断上升。所以OS要选择一个适当的进程数目和进程需要的帧数，以便在并发水平和缺页率之间达到一个平衡。 

抖动问题可能会被本地的页面置换改善。

更好的规则为加载控制：调整并发进程数（MPL）来进行系统负载控制

- ∑WSi=内存的大小
- 平均缺页间隔时间mean time between page faults(MTBF) = 缺页异常处理时间 page fault service time(PFST)

![img](https://img-blog.csdn.net/20180418110731341?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FsYXRlYmxvb21lcg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

MTBF/PFST的比值越大，说明CPU用于处理缺页中断的时间越少，当比值为1时，CPU达到能承载的程序的最大数量，如果超过这个进程并发数，CPU利用率会大大降低。<small>（因为缺页中断需要内存和硬盘频繁IO交互，CPU没啥事干，等待中断处理完毕后，获取到数据对应的物理地址后，才能继续工作。当然CPU也不是真没啥事干，X进程缺页中断，那就保存X进程PCB状态，先去执行别的进程比如Y进程。）</small>

> [六、页面置换算法](https://blog.csdn.net/Alatebloomer/article/details/79976068)

# 7. 进程和线程、上下文切换

