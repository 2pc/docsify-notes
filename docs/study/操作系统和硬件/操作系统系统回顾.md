> 经过之前寒假的Netty开发。打算对操作系统的知识重新回顾一遍。俗话说，温故而知新，可以为师矣。
>
> 最近把操作系统回顾了一遍，同样是OneNote笔记再整理一份Markdown的版本。没有图床，所以就文字将就了。

# 1. 基本概念

## 1.1 操作系统-概述

> [操作系统 （计算机管理控制程序）]([https://baike.baidu.com/item/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/192?fr=aladdin](https://baike.baidu.com/item/操作系统/192?fr=aladdin))
>
> 操作系统(Operating System，简称OS)是管理[计算机](https://baike.baidu.com/item/计算机)[硬件](https://baike.baidu.com/item/硬件)与[软件](https://baike.baidu.com/item/软件)资源的[计算机程序](https://baike.baidu.com/item/计算机程序)。操作系统需要处理如管理与配置[内存](https://baike.baidu.com/item/内存)、决定[系统资源](https://baike.baidu.com/item/系统资源/974435)供需的优先次序、控制[输入设备](https://baike.baidu.com/item/输入设备/10823368)与[输出设备](https://baike.baidu.com/item/输出设备/10823333)、操作网络与管理文件系统等基本事务。操作系统也提供一个让用户与系统交互的操作界面。

### 1.1.1 操作系统的层次结构

操作系统位于硬件之上，应用程序之下。

操作系统的最重要部分即Kernel，俗称内核。

内核Kernel向外提供底层硬件的抽象接口实现，即系统调用System Call。

再外层的Shell、共用函数库lib则是对系统调用的简单封装。

最外层应用程序通过Shell编程or调用共用函数库来申请使用系统调用，进而与硬件进行交互。（实际应用层编程，无需关心硬件的差异性，仅需要调用操作系统提供的系统调用即可。）

![img](https://pic3.zhimg.com/80/416d6b469bda642f1edf7ff56c1aea4d_720w.jpg?source=1940ef5c)

> [shell、操作系统、内核是一个东西吗？](https://www.zhihu.com/question/37695460)
>
> 上图就是来自这个链接，没有图床就这样了。

## 1.2 OS内核-Kernel

> [内核和操作系统的区别](https://zhuanlan.zhihu.com/p/54665833)
>
> [Kernel (operating system)--wiki](https://en.wikipedia.org/wiki/Kernel_(operating_system))

操作系统OS内核Kernel的特征：

+ 并发

  计算机系统中同时存在多个运行的程序，需要OS管理和调度

+ 共享

  + "同时"访问
  + 互斥共享

+ 虚拟

  利用多道程序设计技术，让每个用户都觉得有一个计算机专门为他服务

+ 异步

  + 程序的执行不是一贯到底，而是走走停停，向前推进的速度不可预知
  + 只要运行环境相同，OS需要保证同一个程序的运行结果相同

操作系统的三大关注点：

+ CPU--OS--进程
+ Memory--OS--地址空间
+ 文件--OS--磁盘

## 1.3 VMM虚拟机监视器

> [虚拟机监视程序--百度百科]([https://baike.baidu.com/item/%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9B%91%E8%A7%86%E7%A8%8B%E5%BA%8F/20839241?fromtitle=VMM&fromid=7047240&fr=aladdin](https://baike.baidu.com/item/虚拟机监视程序/20839241?fromtitle=VMM&fromid=7047240&fr=aladdin))
>
> 监控系统行为是[虚拟机](https://baike.baidu.com/item/虚拟机/104440)系统的核心任务监控系统可用于调度任务、[负载均衡](https://baike.baidu.com/item/负载均衡/932451)、向管理员报告软硬件故障，并广泛控制系统的使用情况。
>
> 虚拟化是从逻辑角度出发的资源配置方案，是对物理资源的一种抽象。抽象的结果是，在只有一台计算机硬件的情况下、通过虚拟化技术、可以让多个操作系统同时运行在此计算机硬件上，并且让这些操作系统都认为自己独享整个硬件，资源划分对操作系统是透明的。

![img](https://bkimg.cdn.bcebos.com/pic/b3119313b07eca801ea8eee99b2397dda144830b?x-bce-process=image/watermark,image_d2F0ZXIvYmFpa2U4MA==,g_7,xp_5,yp_5)

VMM将单独的机器接口转换成很多的幻象。每个这些接口（虚拟机）是一个原始计算机系统的有效副本，并完成所有的处理器指令。

```none
|VMs0、VMs1、VMs2...(多台虚拟机VMs)   |
|虚拟机监视器(VMM),也称为管理程序       |
|平台硬件(内存、CPU处理器、I/O设备)     |
```

常见的使用场景，就是VMware，大家常用的虚拟机程序啦。(物理硬件用同一套，VMM层抽象出接口，然后上层再搭载多个虚拟机操作系统)

# 2. 启动；中断、异常、系统调用

## 2.1 启动

### 2.1.1 计算机体系结构概述

> [bios--百度百科](https://baike.baidu.com/item/bios/91424?fr=aladdin)
>
> BIOS是英文"**Basic Input Output System**"的[缩略词](https://baike.baidu.com/item/缩略词)，直译过来后中文名称就是"**基本输入输出系统**"。在[IBM](https://baike.baidu.com/item/IBM/9190) PC兼容系统上，是一种业界标准的[固件](https://baike.baidu.com/item/固件/627829)[接口](https://baike.baidu.com/item/接口/2886384)。 [1] BIOS这个字眼是在1975年第一次由[CP/M](https://baike.baidu.com/item/CP%2FM)操作系统中出现。  **BIOS是[个人电脑](https://baike.baidu.com/item/个人电脑/3688503)启动时加载的第一个软件。**
>
> 其实，它是一组固化到[计算机](https://baike.baidu.com/item/计算机)内[主板](https://baike.baidu.com/item/主板)上一个[ROM](https://baike.baidu.com/item/ROM)[芯片](https://baike.baidu.com/item/芯片)上的[程序](https://baike.baidu.com/item/程序)，它**保存着计算机最重要的基本输入输出的程序、开机后自检程序和系统自启动程序**，它可从CMOS中读写[系统设置](https://baike.baidu.com/item/系统设置)的具体信息。其**主要功能是为计算机提供最底层的、最直接的硬件设置和控制**。此外，BIOS还向作业系统提供一些系统参数。系统硬件的变化是由BIOS隐藏，程序使用BIOS功能而不是直接控制硬件。**现代作业系统会忽略BIOS提供的抽象层并直接控制硬件组件**。
>
> 当今，此系统已成为一些病毒[木马](https://baike.baidu.com/item/木马/530)的目标。一旦此系统被破坏，其后果[不堪设想](https://baike.baidu.com/item/不堪设想/1768458)。

处理器CPU、内存Memory、其他I/O设备等，通过总线连接和通信。

DSIK（硬盘/磁盘）：存放OS。

BIOS：基本I/O处理系统

Bootloader：加载OS

POST(加电自检)：寻找显卡和执行BIOS

> [开机自检--百度百科]([https://baike.baidu.com/item/%E5%BC%80%E6%9C%BA%E8%87%AA%E6%A3%80/5199677?fr=aladdin](https://baike.baidu.com/item/开机自检/5199677?fr=aladdin))
>
> 也称[上电自检](https://baike.baidu.com/item/上电自检/10976730)(POST，Power On Self Test)。 指计算机系统，接通电源，（BIOS程序）的行为，包括对CPU、系统主板、基本内存、[扩展内存](https://baike.baidu.com/item/扩展内存/7353990)、系统ROM BIOS等器件的测试。如发现错误，给操作者提示或警告。简化或加快该过程，可使系统能够[快速启动](https://baike.baidu.com/item/快速启动/5173174)。

### 2.1.2 启动大致流程

> [BIOS在POST时 最先检测的硬件是内存还是CPU?](https://zhidao.baidu.com/question/2137750054738218748.html)
>
> [BootLoader--百度百科](https://baike.baidu.com/item/BootLoader/8733520?fr=aladdin)
>
> 在嵌入式操作系统中，BootLoader是在[操作系统](https://baike.baidu.com/item/操作系统)内核运行之前运行。可以初始化硬件设备、建立内存空间映射图，从而将系统的软硬件环境带到一个合适状态，以便为最终调用[操作系统内核](https://baike.baidu.com/item/操作系统内核/297824)准备好正确的环境。

大致加载步骤：

1. 计算机启动时，首先执行BIOS程序中的自检程序，俗称POST（Power On Self Test），对计算机硬件设备进行检查，确定无故障后再将CPU执行权交还给BIOS主体。
2. BIOS加载Bootloader程序，把CPU控制权交给Bootloader。
3. BootLoader从硬盘Disk加载OS，使操作系统在内存中运行，把CPU控制权交给OS。（为了方便BootLoader记载OS，一般把OS放在硬盘的第一个扇区，比如Windows的C盘）

+ BIOS
  + 将Bootloader从磁盘的引导扇区（512字节）加载到0x7c000。
  + 跳转到CS:IP = 0000:7c00
+ Bootloader
  + 将操作系统的代码和数据从硬盘加载到内存中
  + 跳转到操作系统的起始地址

## 2.2 系统调用、异常、中断

### 2.2.1 定义

+ 系统调用（来源于应用程序）

  应用程序主动向操作系统发出服务请求

+ 异常（来源于不良的应用程序）

  非法指令或者其他坏的处理状态（如：内存出错）

+ 中断（来源于外设）

  来自不同的硬件设备的计时器和网络的中断

从"产生源头"、"处理时间"、"响应处理"三个角度分析三者的异同点：

1. 产生源头
   + 系统调用：应用程序请求操作系统提供服务<small>（比如操作文件）</small>
   + 异常：应用程序意想不到的行为<small>（比如程序出现除零操作，系统执行指令出错等）</small>
   + 中断：外设<small>（比如网卡获取数据，网卡驱动程序将数据加载到内存后，要求CPU处理。更常见的就是键盘、鼠标操作）</small>
2. 处理时间
   + 系统调用：异步或同步<small>（同步：打开文件，等待返回文件描述符，得到结果前阻塞；异步：查看socket是否有接受到数据，没有则直接返回，不阻塞）</small>
   + 异常：同步<small>(除零操作，直接抛出异常。如果没有设置异常处理函数，程序进程崩溃并异常退出。)</small>
   + 中断：异步<small>（用户进程无感知，毕竟什么时候别的外设要占用CPU是完全随机的）</small>
3. 响应处理
   + 系统调用：等待和持续<small>（同步的系统调用则等待OS返回结果；异步则执行向下执行，OS返回结果时执行回调函数）</small>
   + 异常：杀死或者重新执行意想不到的应用程序指令<small>（一般没有预设异常处理函数，就是进程崩溃。）</small>
   + 中断：持续，对用户程序是透明的<small>（很好理解，你完全无需关心网卡等外设什么时候有数据被CPU处理了。）</small>

### 2.2.2 系统调用

> [系统调用--百度百科]([https://baike.baidu.com/item/%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8](https://baike.baidu.com/item/系统调用))
>
> 由[操作系统](https://baike.baidu.com/item/操作系统/192)实现提供的所有系统调用所构成的集合即[程序接口](https://baike.baidu.com/item/程序接口/150383)或应用编程接口(Application Programming Interface，API)。是[应用程序](https://baike.baidu.com/item/应用程序)同系统之间的接口。

​	在计算机运行中，内核Kernel是被信任的第三方，所以只有内核可以执行特权指令（内核态）。为了方便应用程序（用户态）与硬件交互，操作系统提供了一套系统调用System Call接口API。应用程序不能直接操作硬件，因为权限不足（用户态），需要通过系统调用请求，让具有权限的内核Kernel代替用户程序执行特权指令与硬件设备交互（内核态），并把结果返回给用户程序。

​	实际开发中，程序访问的主要是高层次的API接口而不是直接进行系统调用。

+ WIN32 API用于Windows
+ POSIX API用于POSIX-based systems（包括UNIX、Linux、Mac OS X的所有版本）
+ Java API用于Java虚拟机（JVM）

*（POSIX提供一些可移植的系统调用标准。UNIX等遵循这种标准开发，使得操作系统具有可以执行。)*

*（Java虚拟机JVM提供的API不是系统调用，但是最后也是调用的POSIX API，所以说JVM跨平台，移植性好。）*

*（POSIX之所以说以执行好，就是因为UNIX、LINUX等都按照它这个标准去实现，那么高层应用调用POSIX API就根本不用管底层操作系统OS是UNIX内核还是Linux内核等。也就是说POSIX的可移植性强，源自大家都按它标准实现，使得上层应用无需关系底层差异性，反正用的都是同一套标准的POSIX API。）*

> [POSIX-可移植操作系统接口--百度百科]([https://baike.baidu.com/item/%E5%8F%AF%E7%A7%BB%E6%A4%8D%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E6%8E%A5%E5%8F%A3/12718298?fromtitle=POSIX&fromid=3792413&fr=aladdin](https://baike.baidu.com/item/可移植操作系统接口/12718298?fromtitle=POSIX&fromid=3792413&fr=aladdin))
>
> <small>**可移植操作系统接口**（英语：Portable Operating System Interface，缩写为**POSIX**）是[IEEE](https://baike.baidu.com/item/IEEE)为要在各种[UNIX](https://baike.baidu.com/item/UNIX)[操作系统](https://baike.baidu.com/item/操作系统)上运行软件，而定义[API](https://baike.baidu.com/item/API)的一系列互相关联的标准的总称，其正式称呼为IEEE Std 1003，而国际标准名称为[ISO](https://baike.baidu.com/item/ISO)/[IEC](https://baike.baidu.com/item/IEC) 9945。此标准源于一个大约开始于1985年的项目。POSIX这个名称是由[理查德·斯托曼](https://baike.baidu.com/item/理查德·斯托曼)（RMS）应IEEE的要求而提议的一个易于记忆的名称。它基本上是Portable Operating System Interface（可移植操作系统接口）的缩写，而**X**则表明其对Unix API的传承。</small>

### 2.2.3 异常

> [异常(计算机术语)--百度百科]([https://baike.baidu.com/item/%E5%BC%82%E5%B8%B8/5952477#viewPageContent](https://baike.baidu.com/item/异常/5952477#viewPageContent))
>
> 异常指的是在程序运行过程中发生的异常事件，通常是由外部问题（如硬件错误、输入错误）所导致的。在Java等面向对象的编程语言中异常属于对象。

​	一般进程出现异常时，会产生对应的异常编号。操作系统尝试保存现场、异常处理（杀死产生异常的程序or重新执行异常指令）、恢复现场。

*（开发中，如果没有异常处理函数，那一般遇到的就是程序崩溃。如果在一些容器、服务下运行，好一点就是会保留一些错误提示。常见的WEB开发就是会保留错误提示。）*

### 2.2.4 中断

> [中断--百度百科]([https://baike.baidu.com/item/%E4%B8%AD%E6%96%AD/3933007?fr=aladdin](https://baike.baidu.com/item/中断/3933007?fr=aladdin))
>
> 中断是指计算机运行过程中，出现某些意外情况需主机干预时，机器能自动停止正在运行的程序并转入处理新情况的程序，处理完毕后又返回原被暂停的程序继续运行。

中断还可以细分为**硬中断**和**软中断**。

硬件中断（Hardware Interrupt）：

- 可屏蔽中断（maskable interrupt）。[硬件中断](https://baike.baidu.com/item/硬件中断)的一类，可通过在中断屏蔽寄存器中设定位掩码来关闭。
- 非可屏蔽中断（non-maskable interrupt，NMI）。硬件中断的一类，无法通过在中断屏蔽寄存器中设定位掩码来关闭。典型例子是时钟中断（一个硬件时钟以恒定频率—如50Hz—发出的中断）。
- 处理器间中断（interprocessor interrupt）。一种特殊的硬件中断。由处理器发出，被其它处理器接收。仅见于多处理器系统，以便于[处理器](https://baike.baidu.com/item/处理器)间通信或同步。
- 伪中断（spurious interrupt）。一类不希望被产生的硬件中断。发生的原因有很多种，如中断线路上电气信号异常，或是中断请求设备本身有问题。

软件中断（Software Interrupt）：

- 软件中断。是一条CPU指令，用以自陷一个中断。由于软中断指令通常要运行一个切换CPU至内核态（Kernel Mode/Ring 0）的子例程，它常被用作实现[系统调用](https://baike.baidu.com/item/系统调用)（System call）。

中断处理时，硬件、软件的相关要点：

1. 硬件：
   + 设置中断标记[CPU初始化]
     1. 将内部、外部事件设置中断标记
     2. 中断事件的ID
2. 软件：
   + 保存当前处理状态
   + 中断服务程序处理
   + 清理中断标记
   + 恢复之前保存的处理状态

### 2.2.5 跨越操作系统边界的开销

在执行时间上的开销超过程序调用。

开销：

+ 建立中断/异常/系统调用号与对应服务例程映射关系的初始化开销（一般是维护一张表来表示关系）
+ 建立内核堆栈（暂存当时的CPU运行状态）
+ 验证参数
+ 内核态映射到用户态的地址空间，更新页面映射权限（内核态操作，如果数据是用户态需要的，还需要把内核态内存区域的数据拷贝一份到用户态）
+ 内核态独立地址空间TLB刷新（缺页中断等，刷新TLB快表，TLB用于缓存常访问的内存区域地址映射关系）

# 3. 内存、地址空间、内存分配

## 3.1 内存和地址空间

### 3.1.1 计算机基本硬件结构

```none
CPU        内存          设备(I/O)
|           |             |
<-----------总线------------->

CPU:进程在这里执行操作(CPU有运算器、寄存器、控制器、缓存Cache、存储处理单元MMU)
内存:执行的程序(进程)和数据驻留于此
设备(I/O):磁盘设备、鼠标、键盘、网卡等
```

虽然不同类型的硬件没有可比性，但是一般来说CPU工作速率>内存>设备(I/O)，这里只是模糊又不专业的说法。

CPU取指or取数据时，一般按照如下顺序查找，如果找不到就一直往下，找到了就不再往下了，实在找不到那就抛除异常了。

+ 寄存器（最快）
+ L1缓存
+ L2缓存
+ L3缓存<small>（多核CPU，3级缓存是多核共享的。一般1级和2级缓存都是KB大小，这个3级缓存MB大小）</small>
+ L4及等多的缓存，一般都是MB大小，如果有的话...<small>(据说L4缓存带来的速度提升不明显，我的电脑就有4级缓存)</small>

+ 主存<small>（也就是内存Memory）</small>
+ 虚拟内存<small>（也就是硬盘，需要操作系统支持虚拟化内存的技术。最慢）</small>

*<small>（对自己的电脑硬件配置不清楚的，推荐可以下载个[HWiNFO](https://www.hwinfo.com/)，算是各种参数比较齐全的硬件检测软件了吧。）</small>*

> [MMU--百度百科](https://baike.baidu.com/item/MMU/4542218?fr=aladdin)
>
> MMU是Memory Management Unit的缩写，中文名是[内存管理](https://baike.baidu.com/item/内存管理)单元，有时称作**分页内存管理单元**（英语：**paged memory management unit**，缩写为**PMMU**）。它是一种负责处理[中央处理器](https://baike.baidu.com/item/中央处理器)（CPU）的[内存](https://baike.baidu.com/item/内存)访问请求的[计算机硬件](https://baike.baidu.com/item/计算机硬件)。它的功能包括[虚拟地址](https://baike.baidu.com/item/虚拟地址)到[物理地址](https://baike.baidu.com/item/物理地址)的转换（即[虚拟内存](https://baike.baidu.com/item/虚拟内存)管理）、内存保护、中央处理器[高速缓存](https://baike.baidu.com/item/高速缓存)的控制，在较为简单的计算机体系结构中，负责[总线](https://baike.baidu.com/item/总线)的[仲裁](https://baike.baidu.com/item/仲裁)以及存储体切换（bank switching，尤其是在8位的系统上）。

### 3.1.2 物理地址和虚拟(逻辑)地址-简述

> [物理地址 （CPU中相关术语）--百度百科]([https://baike.baidu.com/item/%E7%89%A9%E7%90%86%E5%9C%B0%E5%9D%80/2901583?fr=aladdin](https://baike.baidu.com/item/物理地址/2901583?fr=aladdin))
>
> 在[存储器](https://baike.baidu.com/item/存储器/1583185)里以[字节](https://baike.baidu.com/item/字节/1096318)为单位存储信息，为正确地存放或取得信息，每一个字节单元给以一个唯一的[存储器地址](https://baike.baidu.com/item/存储器地址/7874173)，称为物理地址（Physical Address），又叫[实际地址](https://baike.baidu.com/item/实际地址/1061693)或[绝对地址](https://baike.baidu.com/item/绝对地址/573580)。
>
> [虚拟地址--百度百科]([https://baike.baidu.com/item/%E8%99%9A%E6%8B%9F%E5%9C%B0%E5%9D%80/1329947?fr=aladdin](https://baike.baidu.com/item/虚拟地址/1329947?fr=aladdin))
>
> 虚拟地址是Windows程序时运行在386保护模式下，这样程序访问[存储器](https://baike.baidu.com/item/存储器/1583185)所使用的[逻辑地址](https://baike.baidu.com/item/逻辑地址/3283849)称为虚拟地址，与实地址模式下的分段地址类似，虚拟地址也可以写为“段：[偏移量](https://baike.baidu.com/item/偏移量/9180391)”的形式，这里的段是指段选择器。

​	其实不管用了什么技术，一般而言，CPU找数据顶多向下找到内存，不会再去找硬盘，就算真有从硬盘上取数据，那其实也是把硬盘数据先取到内存，然后CPU再从内存中取数据。简言之，**CPU除了从寄存器、CPU缓存中取数据，那么就只能从内存中取数据**。

1. 逻辑地址范围

   32位操作系统，理论上可以寻址2<sup>32</sup>Byte内存，也就是4GB内存，这种理论上的出的就是**逻辑地址**的寻址范围了。*<small>（64位理论上可以寻址2<sup>64</sup>Byte的内存，但是由于内存寻址一般需要页表等机制管理，这个数量级太大了，所以其实也没操作系统真的用到那么大范围的逻辑地址）</small>*

2. 物理地址范围

   物理地址，那就是看内存具体多大了。要是内存条就256MB，那就是256MB的**物理地址**的寻址范围了。*<small>（早期计算机的内存条贵，所以很小，现在一般至少都8GB内存，夸张的也有上百GB内存的计算机）</small>*

物理地址空间——硬件支持的地址空间

逻辑地址空间——一个运行的程序所拥有的内存范围

*这里不展开逻辑地址和物理地址的具体描述，知道物理地址对应内存上的地址即可，而逻辑地址不过是进程中使用的地址，实际还需要翻译成物理地址，才能真正从内存上读取数据。过去32位系统，逻辑地址范围>物理地址范围，所以才会衍生出这种技术。*

​	CPU从内存（主存）取数据时，如果寄存器和缓存中没有，那么需要知道数据在内存的哪个<u>物理地址</u>上，而CPU是不清楚什么<u>逻辑地址</u>、<u>物理地址</u>这些乱七八糟的。CPU根据执行的指令中的地址寻找数据时，CPU把这个地址交给MMU，MMU会帮CPU把代码中的**逻辑地址**翻译成**物理地址**，进而CPU能够访问到内存上实际物理地址的数据。（实际CPU访问MMU之前，会先看看TLB快表看看有没有对应的逻辑地址-物理地址的映射记录，有的话就不用劳烦MMU转换了。）

更具体一些的描述：

1. 操作系统，事先建立逻辑地址和物理地址的映射关系。（维护页表等）
2. CPU运算器需要某个逻辑地址的内存内容
3. 内存管理单元MMU寻找在逻辑地址和物理地址之间的映射（这个需要操作系统事先建立好）
4. CPU的控制器往**总线**发送在物理地址的内存内容的请求
5. 内存收到总线上来自CPU的请求，发送物理地址内存的内容给CPU
6. CPU获取数据后继续执行指令

**操作系统维护程序虚拟地址与物理地址之间的映射关系**。如果CPU请求的数据在内存中不存在并触发异常时（比如超出物理地址的范围之类的），需要操作系统去处理异常。

> [TLB-转译后备缓冲区--百度百科]([https://baike.baidu.com/item/%E8%BD%AC%E8%AF%91%E5%90%8E%E5%A4%87%E7%BC%93%E5%86%B2%E5%8C%BA/22685572?fromtitle=TLB&fromid=2339981&fr=aladdin](https://baike.baidu.com/item/转译后备缓冲区/22685572?fromtitle=TLB&fromid=2339981&fr=aladdin))
>
> **转译后备缓冲器**，也被翻译为**页表缓存**、**转址旁路缓存**，为[CPU](https://baike.baidu.com/item/CPU)的一种缓存，由存储器管理单元用于改进[虚拟地址](https://baike.baidu.com/item/虚拟地址)到物理地址的转译速度。当前所有的桌面型及服务器型处理器（如 [x86](https://baike.baidu.com/item/x86)）皆使用TLB。TLB具有固定数目的空间槽，用于存放将虚拟地址映射至[物理地址](https://baike.baidu.com/item/物理地址)的标签页表条目。为典型的结合存储（content-addressable memory，首字母缩略字：CAM）。其搜索关键字为虚拟内存地址，其搜索结果为物理地址。如果请求的虚拟地址在TLB中存在，CAM 将给出一个非常快速的匹配结果，之后就可以使用得到的物理地址访问存储器。如果请求的虚拟地址不在 TLB 中，就会使用标签页表进行虚实地址转换，而标签页表的访问速度比TLB慢很多。有些系统允许标签页表被交换到次级存储器，那么虚实地址转换可能要花非常长的时间。

### 3.1.3 操作系统的内存管理-简述

在操作系统中，管理内存有多种方式：

+ 程序重定向
+ 分段
+ 分页
+ 虚拟内存
+ 按需分页虚拟内存

内存的管理和使用，需要硬件也参与实现。可以说内存管理是高度依赖于硬件的。（比如MMU内存管理单元，作为硬件组件负责处理CPU的内存访问请求）

> 推荐几篇文章<small>(内容比较多，就不像之前的计网笔记那样给出概述了。)</small>
>
> [MMU和cache学习](https://blog.csdn.net/chinesedragon2010/article/details/5922324)
>
> [物理地址和虚拟地址1 （MMU）](https://www.cnblogs.com/leaven/archive/2011/04/18/2019696.html)

## 3.2 连续内存分配

### 3.2.1 连续内存分配的内存碎片问题

内存碎片问题，简单来说就是内存中存在某些空闲却又没法被使用的内存。

内存碎片一般可以分为两种：

+ 外部碎片

  在分配单元间未使用的内存

+ 内部碎片

  在分配单元中未使用的内存

外部碎片举例：200MB剩余内存，有两个99MB程序运行后，只剩2MB内存。这2MB虽然是空闲内存，但是太小，别人也用不上，就是外碎片了。

内部碎片举例：200MB剩余内存，有个程序申请要占用这200MB内存。<small>（其实内存一般也不可能完全用上，这里就假设）</small>，这时候不存在外碎片了。但是这个进程其实一开始初始化时用了200MB，后来也就只保留100MB常用数据在内存中，导致还有100MB内存空间浪费，这100MB空间就是内碎片。

### 3.2.2 分区的动态分配

简单的内存管理方法：

+ 当一个程序准许在内存中时，分配一个连续的内存区间。
+ 分配一个连续的内存区间给运行的程序以访问数据。

常见分配策略：

+ 首次适配（第一适配）
+ 最优适配
+ 最差适配

---

下面拿一个举例来看看首次适配、最优适配、最差适配，这三者的区别：

假设现在内存中，有3段连续且空闲的内存空间（100MB、50MB、200MB），这时候有一个40MB的程序想要到内存中运行。

+ 首次适配：使用100MB的内存空间，即使用内存寻址最先寻找到的空闲区域。占用后，内存空闲空间分布（60MB，50MB、200MB）。
+ 最优适配：使用50MB的内存空间，即寻找和程序所需要的内存空间按最接近的一个区域。占用后，内存空闲空间分布（100MB，10MB、200MB）。
+ 最差适配：使用200MB的内存空间，即使用当前最大的空闲内存区域。占用后，内存空闲空间分布（100MB，10MB、160MB）。

---

对比：

+ 第一适配：
  + 优势：
    1. 简单
    2. 使得地址空间的结尾部分易于产生更大的空闲块
  + 劣势：
    1. 外部碎片
    2. 不确定性
+ 最优适配：
  + 优势：
    1. 比较简单
    2. 当大部分分配是小尺寸时非常有效
  + 劣势：
    1. 外部碎片
    2. 重分配慢
    3. 易产生很多没用的微小外碎片（不怎么好）
+ 最差适配
  + 优势：
    1. 简单
    2. 假如内存分配主要是中等尺寸，效果最好
  + 劣势：
    1. 外部碎片
    2. 重分配慢
    3. 内存空间要求大的进程可能分配不到内存（因为每次都把大的连续空间拆了）

### 3.2.3 压缩式碎片整理

​	重置程序以合并孔洞（指合并内存外碎片）。要求所有程序是动态可重置的（也就是要求程序能保证在内存挪动位置后还能正常运行，不会出现寻址异常等问题）。

​	需要考虑重定向的时机，比如运行时挪动可能导致代码寻址错误。再者需要考虑开销，如果频繁重定向，挪动内存分配的空间，也会浪费很多CPU事件。

```none
|进程1|                              |进程1|
|20MB|                              |进程2| 
|进程2|   ===== 压缩式碎片整理 =====>  |进程3| 
|30MB|                              |20MB|
|进程3|                              |30MB|
|40MB|                              |40MB|

这样就把空闲的20MB、30MB、40MB合并成一个连续的90MB的内存空间了。
```

### 3.2.4 交换式碎片整理

​	优先给需要更多内存的程序加载到内存，其余的等待。比如多个程序申请且占用内存后，剩余的内存空间很小，不够接下去的程序运行，就把一些程序申请后多余没使用的内存回收，交给新的程序使用。要是还不够，先把程序挂载到硬盘（虚拟内存）。

​	简言之，把内存中的程序换下来（挂载），硬盘的程序加载到内存中。

# 4. 非连续内存分配

## 4.0 引言

​	出现非连续内存分配，那么肯定是因为单纯的连续内存分配不能满足复杂操作系统的内存分配需求。

连续内存分配的缺点：

+ 分配给一个程序的物理内存是连续的
+ **内存利用率较低**
+ 有外碎片、内碎片的问题

非连续分配的优点

+ 一个程序的物理地址空间是非连续的
+ 更好的内存利用和管理
+ **允许共享代码与数据**（共享库等......）
+ 支持动态加载和动态链接

非连续分配的缺点

+ 需要考虑如何建立虚拟地址和物理之间的转换<small>（其实现在实现都很成熟了，应该也不是啥大问题了）</small>
  + 软件方案
  + 硬件方案
    + 分段
    + 分页

连续内存分配，可以说进程就是完全互相隔离的，要实现进程间通信比较难。后来的分连续分配，对进程间通讯的支持就很好了。

非连续内存分配，如果纯软件方案实现，难度大开销大，不现实。一般采取软硬件相结合的方式，即硬件方面设计时就考虑分段、分页等问题，然后软件按照硬件规定的分段、分页标准具体设计规划内存的非连续分配。

## 4.1 分段(Segmentation)

### 4.1.1 程序的分段地址空间	

​	早期设计时，按照应用的特点来进行分离和管理内存空间。（比如进程的函数调用栈，都统一放到某一段空间内去分配）

​	虽然程序员在编程时获取的是连续的逻辑地址空间，但是实际在内存中运行时，根据进程不同的组成部分，把其拆分到不同的物理地址空间中。（进程由堆、运行栈、程序数据、程序text字段组成，那么把每个进程的堆都放到内存某一片区域，运行栈、程序数据同理。而程序text段还可以细分成库和用户代码，再放到不同物理地址空间。库是多个进程可以共享的，之后出现进程调用相同的库就不用重复加载了。）

​	这样分段，使得进程虚拟地址空间划分到物理地址空间的映射有一定可控性，也可以实现部分物理空间共用。再者，这样方便把控权限，保证安全，比如把库等需要系统调用的，放到"内核态"使用的内存空间。

*（一般而言，操作系统会把虚拟地址划分成内核态区域和用户态区域。）*

![img](https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1596452791980&di=241d98dc422946a96a4c667505d766fa&imgtype=0&src=http%3A%2F%2Finews.gtimg.com%2Fnewsapp_bt%2F0%2F12010650392%2F641.jpg)

### 4.1.2 分段寻址方案

​	在分段的内存空间中，一个段对应一个内存"块"，一个段本身是一个逻辑地址空间。

​	程序访问内存地址，需要一个二维的二元组`(s，addr)`，s段号，addr段内偏移

```none
# 下面就打个比方，具体取几位数没有严格按照分段方案来
[010101] [1100101010]
n2     0 n1         0 
   s          addr
段寄存器+地址寄存器实现方案(也就是用两个寄存器存分段寻址的地址，组合后对应真实物理地址)

[1000101010010]
n             0
 | s |  addr  |
单地址实现方案(也就是前半段是s段号，后半部分是段内偏移,组合后经过计算获得对应的真实物理地址)

# 一般都是 s 左移几位，然后加上 addr获取对应的物理地址(指分段方案下，逻辑地址到物理地址的转换方式)
```

### 4.1.3 内存分段的硬件实现方案

*<small>(大致找了张图，文字描述不一定和图一样，毕竟没图床，就这样吧。哈哈)）</small>*

![img](https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1596451014660&di=5d5ddf351b24f93e40514786fd8d6a39&imgtype=0&src=http%3A%2F%2Fa4.att.hudong.com%2F72%2F22%2F01200000144761134439220160183_s.jpg)

​	首先，段表需要操作系统建立并维护，然后再与硬件建立联系（比如段寄存器、地址寄存器、MMU等）。当然，段表的建立，操作系统也不是随便整的，必须按照硬件支持的段表寻址方式去实现和维护段表。

​	程序P运行=>CPU执行=>遇到需要从内存寻址的数据(段号s+段内偏移addr)=>段表查询，MMU转换逻辑地址=>CPU获取物理地址后，往总线向内存发起物理地址空间对应的数据获取请求=>内存响应CPU请求，并返回数据到总线=>CPU从总线获取到来自内存的数据，继续执行。

*（分段这种机制，基本被淘汰了，基本采用后面的分页方式，分页本身也是建立在分段思想上的。）*

## 4.2 分页

### 4.2.1 分页地址空间

​	前面的分段，需要考虑段号和段内偏移；而分页，同样需要考虑页号和业内偏移。

​	**分页和分段两种机制的最大区别是：段是变长大小的，而页是固定大小的**。

+ 划分物理内存至**固定大小**的帧
  + 大小是2的幂，例如512、4096、8192
+ 划分逻辑地址空间至**相同大小**的页
  + 大小是2的幂，例如512、4096、8192

+ 建立方案转换逻辑地址为物理地址（pages to frames）
  + 页表
  + MMU/TLB

注意，物理地址PA（Physical Address）划分成固定大小的帧frame，而虚拟地址VA（Virtual address）划分成固定大小的page。

**frame和page必须大小相同**，如果frame是512，那么page也必须是512，如果frame=4KB，那么page也必须=4KB。

操作系统维护页表，记录VA到PA的转换。<small>（有VA作键key，PA作值value的；也有逆向页表PA作key，VA作value的。后者相对省空间，但是实现和维护更复杂。）</small>

MMU同理还是做VA和PA之间的转换工作，而TLB是页表的快表。<small>(也就是页表缓存，MMU转换后缓存结果到TLB，这样CPU要是遇到相同的虚拟地址就不用MMU重复到主存查页表然后转换地址。即TLB省去一次访问主存查页表找页号对应的页帧的时间，直接从TLB获取页号对应的页帧，然后就直接向主存申请对应物理地址的数据。这样明显比访问主存查页表+后续访问主存取数据快一点。)</small>

---

帧Frame：

物理内存被分割为大小相同的帧。

一个内存物理地址是一个二元组`(f,o)`，f帧号（F位，共有2<sup>F</sup>个帧），o帧内偏移（S位，每帧有2<sup>S</sup>字节）。
$$
物理地址PA=2^S*f+o
$$

---

页Page：

一个程序的逻辑地址空间被划分为大小相等的页。

+ **页内偏移的大小=帧内偏移的大小**
+ **页号大小<>帧号大小**

一个逻辑地址是一个二元组`(p,o)`，p页号（P位，2<sup>P</sup>个页），o页内偏移（S位，每页有2<sup>S</sup>字节）
$$
虚拟地址VA=2^S*p+o
$$

---

地址计算示例：

16-bit的物理地址PA，9-bit（512byte）大小的页帧，已知物理地址二元组表示为（3，6），那么计算物理地址为`2^9*3+6`，即1542。

### 4.2.2 页寻址方案

![img](https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1596454096480&di=924a1703a50aef6a166ec1379c818003&imgtype=0&src=http%3A%2F%2Finews.gtimg.com%2Fnewsapp_bt%2F0%2F12010650396%2F641.jpg)

![img](https://ss2.bdstatic.com/70cFvnSh_Q1YnxGkpoWK1HF6hhy/it/u=206931261,4704473&fm=15&gp=0.jpg)

​	和前面分段机制差不多。页表存储页号-帧号的对应关系。由于页大小和帧大小相同，所以只要页号p查找到最终对应的帧号f后，通过计算公式，就可以得出具体的物理地址了。（页大小和帧大小相同，所以页偏移o和帧偏移o是一样的数值）

​	同样，页表由操作系统建立，操作系统初始化的时候就得加载好页表管理系统。

在页寻址机制中，注意几个要点：

+ 页映射到帧
+ 页是**连续**的虚拟内存<small>(也就是程序开发视角来看，地址是连续的）</small>
+ 帧是**非连续**的物理内存<small>(也就是说实际连续的虚拟地址对应的物理地址不一定是连续的，这样才能充分利用内存外部碎片，也方便一些减少内部碎片的内存管理机制实现）</small>
+ 不是所有的页都有对应的帧<small>(二种情况，物理内存全用完了，虚拟地址还有剩；或者虚拟地址没用完，物理地址也没用完。一般而言虚拟地址范围>=物理地址范围）</small>

## 4.3 页表

### 4.3.1 页表概述

> [请问在操作系统中PTBR和PTLR分别指什么？](https://iask.sina.com.cn/b/1H4Spm1zSq5n.html)
>
> 页表基寄存器（PTBR）指向页表. 页表长度寄存器（PTLR）指示页表的大小
>
> [操作系统概念学习笔记 16 内存管理(二) 段页](https://blog.csdn.net/sunmc1204953974/article/details/46859785)
>
> [读懂操作系统之虚拟内存基本原理篇（一）](https://www.cnblogs.com/CreateMyself/p/12969171.html)
>
> <small>上面这篇很好，主要图多，哈哈。下面的图片也是来自上述文章。</small>

![img](https://img2020.cnblogs.com/blog/589642/202005/589642-20200528215647997-211397649.png)

![img](https://img2020.cnblogs.com/blog/589642/202005/589642-20200528221912276-1423676717.png)

​	每个运行中的程序都有一个页表，其也算是程序运行状态，会动态变化。PTBR页表基址寄存器起到页表指针的作用，存放页表的索引key。

​	页表项除了存储 页号-帧号对应关系，还会存储一些状态信息。（比如这个页号对应的帧号数据是否被执行过写操作，是否被访问过等）操作系统需要根据页表中各个页表项的状态参数信息来实时维护、修改页表信息。（这个与后续介绍的页置换算法有关，也就是每个进程能分配到的实际内存物理空间有限，需要考虑把一些暂时不用的页帧置换出来，减少缺页中断次数，提高CPU运行效率）

```none
#页表项的内容(伪代码，只描述部分)
+ Flags(标志位)
  + dirty bit
  + resident bit
  + clock/reference bit
+ 帧号f

#示例，下面假装页表某一项
[010 | f]

dirty bit = 0 说明数据没有被执行过写操作(因为计算机很笨，一般你执行写操作，不管数据变不变，它直接当你变过了。)
resident bit = 1 说明该页号对应的页帧存在(也就是内存有对应的物理帧与该页表项的页号对应,0则说明后面帧号f无效)
clock/reference bit = 0 说明该页没被访问过(这个与后面的页置换算法有关。没有访问过的页表项可能被置换出来)
f 页帧号，就是对应物理地址的帧号
```

### 4.3.2 转换后背缓存区(TLB)

> [TLB-转译后备缓冲区--百度百科]([https://baike.baidu.com/item/%E8%BD%AC%E8%AF%91%E5%90%8E%E5%A4%87%E7%BC%93%E5%86%B2%E5%8C%BA/22685572?fromtitle=TLB&fromid=2339981&fr=aladdin](https://baike.baidu.com/item/转译后备缓冲区/22685572?fromtitle=TLB&fromid=2339981&fr=aladdin))
>
> TLB 用于缓存一部分标签页表条目。TLB可介于 CPU 和[CPU缓存](https://baike.baidu.com/item/CPU缓存)之间，或在 CPU 缓存和[主存](https://baike.baidu.com/item/主存)之间，这取决于缓存使用的是物理寻址或是虚拟寻址。如果缓存是虚拟定址，定址请求将会直接从 CPU 发送给缓存，然后从缓存访问所需的 TLB 条目。如果缓存使用物理定址，CPU 会先对每一个存储器操作进行 TLB 查寻，并且将获取的物理地址发送给缓存。两种方法各有优缺点。

分页机制存在一个明显的性能问题。即**访问一个内存单元，需要2次内存访问**<small>（没有TLB之前）</small>。

+ 一次用于获取页表项<small>(因为页表本身就是存放在内存中的)</small>
+ 一次用于访问数据<small>(从页表获取到页号具体的页帧后，还需要根据实际物理地址从总线向内存发起数据请求)</small>

再者，页表可能非常大。64位机器理论可以有2<sup>64</sup>Byte的寻址能力，如果只用一级页表，那么光是访问这张表，时间开销就超级大。*<small>（实际上常见的64位操作系统，也没有真的用2<sup>64</sup>Byte大小的虚拟地址，因为没必要，物理内存本身都没有那么大的数量级。）</small>*

为了解决这些问题，就出现了缓存Caching、间接访问等解决方案。而**TLB就是采用了缓存方案，使得页表机制下的内存访问能更快**。

---

![img](https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1596462377005&di=89e4a520e3f96e4b0d9a181145bb40e0&imgtype=0&src=http%3A%2F%2Foenhan.com%2Fwp-content%2Fuploads%2F2013%2F09%2Fpage_table_plus_tlb-1.jpg)

Translation Look-aside Buffer（TLB)，缓存近期访问的页帧转换表项

+ TLB使用associative memoty（关联内存）实现，具备快速访问性能
+ 如果TLB命中，物理页号可以很快被获取
+ 如果TLB未命中，对应的表项被更新到TLB中

前面提到过页表项存在Flags多个状态标识符，其中`resident bit`，判断是否存在 虚拟地址VA 对应的 物理地址PA。

CPU寻址，先看看存储器内的快表TLB是否有页表缓存，没有再取更慢的内存memory中查找页表项。如果连内存的页表也不存在虚拟地址对应的物理地址，那么抛出内存地址访问异常，交由操作系统去处理异常。

根据不同的CPU设计，TLB未命中时，从内存获取页表项并缓存到TLB的这个动作可能由CPU硬件完成，也可能由操作系统OS完成。*<small>(32位x86的CPU能硬件完成该动作，也有别的CPU需要依靠软件，也就是需要操作系统来完成填充TLB表的工作)</small>*

---

![image](http://blog.chinaunix.net/attachment/201112/18/16361381_1324218546w802.jpg)

​	**由于CPU首先接到的是由程序传来的虚拟内存地址，所以CPU必须先到物理内存中取页表，然后对应程序传来的虚拟页面号，在表里找到对应的物理页面 号，最后才能访问实际的物理内存地址，也就是说整个过程中CPU必须访问两次物理内存(实际上访问的次数更多)。因此，为了减少CPU访问物理内存的次 数，引入TLB**。

​	TLB在X86体系的CPU里的实际应用最早是从Intel的486CPU开始的，在X86体系的CPU里边，一般都设有如下4组TLB:

+ 第一组：缓存一般页表（4K字节页面）的指令页表缓存（Instruction-TLB）；

+ 第二组：缓存一般页表（4K字节页面）的数据页表缓存（Data-TLB）；

+ 第三组：缓存大尺寸页表（2M/4M字节页面）的指令页表缓存（Instruction-TLB）；

+ 第四组：缓存大尺寸页表（2M/4M字节页面）的数据页表缓存（Instruction-TLB）；

​	图中可见，当CPU执行机构收到应用程序发来的虚拟地址后，首先到TLB中查找相应的页表数据，如果TLB中正好存放着所需的页表，则称为TLB命中（TLB Hit）,接下来CPU再依次看TLB中页表所对应的物理内存地址中的数据是不是已经在一级、二级缓存里了，若没有则到内存中取相应地址所存放的数据。如果TLB中没有所需的页表，则称为TLB失败（TLB Miss），接下来就必须访问物理内存中存放的页表，同时更新TLB的页表数据。

​	既然说TLB是内存里存放的页表的缓存，那么它里边存放的数据实际上和内存页表区的数据是一致的，在内存的页表区里，每一条记录虚拟页面和物理页框对应关系的记录称之为一个页表条目（Entry），同样地，在TLB里边也缓存了同样大小的页表条目（Entry）。由于页表条目的大小总是固定不变的，所以TLB的容量越大，则它所能存放的页表条目数越多（类似于增大CPU一级、二级缓存容量的作用），这就意味着缓存命中率的增加，这样，就能大大减少CPU直接访问内存的次数，实现了性能提升。

> [TLB是否在多个内核之间共享？(Is the TLB shared between multiple cores?)](https://www.it1352.com/1845896.html)
>
> [多核CPU是有几个TLB？一个核有一个独有的TLB还是多核共享一个TLB？](https://www.zhihu.com/question/313913862/answer/635433592)
>
> [什么是TLB?](https://www.cnblogs.com/linhaostudy/p/10347288.html)
>
> 简言之，每个CPU内核都是有独立的TLB和MMU的。CPU一般用到的缓存就1~3级，L1和L2有TLB，L3是多个内核共享的缓存。
> L1里面还具体分 L1i和L1d，也就是 指令 和 数据的缓存。
>
> **TLB分为指令页表缓存（Instruction-TLB）和数据页表缓存（Data-TLB）**
>
> 一般主流Cache都是物理Cache，即要求访问Cache之前要先访问TLB进行VA到PA的转换。

### 4.3.3 二级/多级页表

![img](https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1596465825786&di=432cb3dfcda3fa3d0cda4a79be9aa42b&imgtype=0&src=http%3A%2F%2Finews.gtimg.com%2Fnewsapp_bt%2F0%2F12010650398%2F641.jpg)

拆分二级页表，那么一级页表存储的值value是二级页表的初始地址；然后二级页表才是具体的页号-页帧（虚拟地址-物理地址）。

这样虽然开销依然很大，但是有个好处，就是一级页表的页表项如果`resident bit`值为0，那么说明不存在该一级页表项-二级页表项的映射关系，那么就可以少创建一个二级页表。*（即理论上一级页表某项表明没有对应的二级页表项时，其二级页表就可以不用创建了。这样就可以省下部分创建页表的空间)*

多级页表同理，就是把原本的页表拆分成更多层次/级别。

```none
#下面都是打比方，位数什么的随便取的
#一级页表
[8位p|8位o] 8位标识页号,8位标识页内偏移

#二级页表
[4位p1|4位p2|8位o] 4位标识一级页表(一级页号-二级页号),4位标识二级页表(二级页号-页帧号)

#三级页表
[2位p1|3位p3|3位p3|8位o]
...
```

### 4.3.4 反向页表

> [反向页表--百度百科]([https://baike.baidu.com/item/%E5%8F%8D%E5%90%91%E9%A1%B5%E8%A1%A8/3565803?fr=aladdin](https://baike.baidu.com/item/反向页表/3565803?fr=aladdin))
>
> 反向页表（ inverted page table ）一般被视为使用正常的系统内存的TLB的片外扩展。与真正的页表不同，它不需要容纳目前所有的映射。
>
> 反向页表对于每个真正的内存页或帧才有一个条目。每个条目包含保存在真正内存位置的页的虚拟地址以及拥有该页的进程的信息。因此，整个系统只有一个页表，对每个物理内存的页只有一条相应的条目。因为系统只有一个页表，而有多个地址空间映射物理内存，所以反向页表的条目中通常需要一个地址空间标识符，以确保一个特定进程的一个逻辑页可以映射到相应的物理帧。
>
> [Linux 匿名页的反向映射](https://www.cnblogs.com/linhaostudy/p/10350326.html)

​	由于虚拟地址范围通常比物理地址范围大，比如64位操作系统，理论虚拟地址范围总大小可以达到2<sup>64</sup>Byte，就算4KB作为页大小，也大概需要5~6级页表才能表示所有的虚拟地址。

​	我们反过来项，不让页表与逻辑地址空间大大小相对应，而是让页表与物理地址空间大小项对应，那么页表就可以缩小好几个数量级。

​	即页表原本(key-页号，value-帧号)变成（key-帧号，value-页号），这就是反向页表了。

*(操作系统要是有使用反向页表机制，那大多也是采用传统页表为主，反向页表为辅的方式。)*

---

基于页寄存器（Page Register）的方案

*<small>（找不到图，就大致说说吧。自己OneNote是有图，但是毕竟不是图床，额。）</small>*

​	进程运行时，CPU像往常一样，需要翻译逻辑地址，才能再去请求获取内存中对应物理地址的数据。这时在页寄存器（Page Register）维护一张特殊的页表（key帧号，value页号），先从页寄存器搜寻看看能不能通过value虚拟地址页号找到对应的key帧号。由于使用帧号做索引，页表的大小就与虚拟地址范围无关，而与物理地址范围有关（更小，同时也没必要硬性要求页寄存器存有所有帧号-页号对应关系，起到缓存作用就好了）

​	使用页寄存器时，每个帧和一个寄存器关联，寄存器内容包括：

+ Residence bit：此帧是否被占用
+ Occupier：对应的页号p
+ Protection bits：保护位

​	举例：

+ 物理内存大小4096\*4096=4K\*4KB=16MB

+ 页面大小：4096bytes=4KB

+ 页帧数：4096=4K

+ 页寄存器使用的空间（假设 8byte/register）：

  8*4096=32KB

+ 页寄存器带来的额外开销：

  32K/16M=0.2%（大约）

+ 虚拟内存的大小：任意

明显，如果采用 帧-页对应关系，需要的页寄存器大小比传统页表小很多，但是需要考虑怎么通过这种数据结构快速地由value页号查找到对应的key帧号。

优点：

+ 转换表的大小相对物理内存来说很小
+ 转换表的大小跟逻辑地址空间的大小无关

缺点：

+ 需要的信息对调了，即根据帧号可找到页号（需要考虑如何加快索引，如何转换结果等，实现更加复杂）

---

基于关联内存（associative memory）的方案

与基于页寄存器的方案类似，不过是把存放反向页表的容器从页寄存器变成了关联内存。这个特殊的存储器也是在CPU内部的，同样不能做得太大，太大成本高+查询速度下降。

在反向页表中搜索一个页对应的帧号

+ 如果帧数较少，页寄存器可以被放置在关联内存中

+ 在关联内存中查找逻辑页号

  + 成功：帧号被提取
  + 失败：页错误异常（page fault）

+ 限制因素：

  大量的关联内存非常昂贵、难以在单个时钟周期内完成、耗电......

---

基于哈希（Hash）查找的方案

根据进程号PID和CPU获取到的虚拟地址页号p，经过特殊的函数`h(PID,p)`计算，得到key，在反向页表中再根据key查找对应的帧号f。

在反向页表中通过哈希算法来搜索一个页对应的帧号

+ 对页号做哈希计算，为了在"帧表"（每帧拥有一个表项）中获取对应的帧号。
+ 页i被放置在表中f(i)位置，其中f是设定的哈希函数
+ 为了查找页i，执行下列操作：
  + 计算哈希函数f(i)，并且使用它作为页寄存器表的索引
  + 获取对应的页寄存器
  + 检查寄存器标签是否包含i，如果包含，则代表成功
  + 否则失败

*<small>（Hash计算的反向表，也是根据物理地址范围大小决定表大小，与虚拟地址无关，这样表占用空间更小。但是这个表同样需要放在内存中，所以还需要配合TLB使用。再者，哈希函数的设计需要硬件集成，和软件系操作系统配合，而且需要考虑Hash碰撞的处理。现在有些高端CPU就有采用基于Hash查找的反向表，能提高CPU寻址的效率。）</small>*

> [反向页表（基于hash表）](https://blog.csdn.net/qq_41841130/article/details/102995118)

# 5. 覆盖技术、交换技术、虚拟技术

